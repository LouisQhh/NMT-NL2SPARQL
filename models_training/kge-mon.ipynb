{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0w2wNk0167DQ"
   },
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1688984516314,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "6ZH1UZrpjtPE",
    "outputId": "18d5defb-f486-404c-c1fb-f1f32990fcc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/nmt\n"
     ]
    }
   ],
   "source": [
    "# Create a directory named 'nmt'\n",
    "!mkdir nmt\n",
    "\n",
    "# Change the current working directory to the newly created 'nmt' directory\n",
    "%cd nmt\n",
    "\n",
    "# Create a subdirectory named 'nmtmodel' inside the 'nmt' directory\n",
    "!mkdir nmtmodel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 111122,
     "status": "ok",
     "timestamp": 1688984631499,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "df6W9IIWmlQL",
    "outputId": "e96f529a-1c88-4ece-a63c-9285052ec85a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchdata 0.6.1 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\n",
      "torchtext 0.15.2 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Install OpenNMT-py along with specific versions of torchvision and torchaudio\n",
    "! pip install OpenNMT-py torchvision==0.14.1 torchaudio==0.13.1 > /dev/null\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1688984641011,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "_3WnsZ-1nUSj",
    "outputId": "3357e7e9-a819-44dd-cbbd-93bb094ca668"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/nmt\n"
     ]
    }
   ],
   "source": [
    "# Print the current working directory\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QypsRuOq7IiR"
   },
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 796,
     "status": "ok",
     "timestamp": 1688984641803,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "Jsc7THqZnYCI",
    "outputId": "3f9a191b-14d4-49d2-ceab-1eaf3750c445"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ./monument.zip\n",
      "   creating: ./monument/\n",
      "  inflating: ./__MACOSX/._monument   \n",
      "  inflating: ./monument/dev.en       \n",
      "  inflating: ./__MACOSX/monument/._dev.en  \n",
      "  inflating: ./monument/dev.sparql   \n",
      "  inflating: ./__MACOSX/monument/._dev.sparql  \n",
      "  inflating: ./monument/.DS_Store    \n",
      "  inflating: ./__MACOSX/monument/._.DS_Store  \n",
      "  inflating: ./monument/train.sparql  \n",
      "  inflating: ./__MACOSX/monument/._train.sparql  \n",
      "  inflating: ./monument/train.en     \n",
      "  inflating: ./__MACOSX/monument/._train.en  \n",
      "  inflating: ./monument/test.sparql  \n",
      "  inflating: ./__MACOSX/monument/._test.sparql  \n",
      "  inflating: ./monument/test.en      \n",
      "  inflating: ./__MACOSX/monument/._test.en  \n"
     ]
    }
   ],
   "source": [
    "# Copy the file 'monument.zip' from '/content/drive/MyDrive/' to the current directory\n",
    "!cp /content/drive/MyDrive/monument.zip ./\n",
    "\n",
    "# Unzip the file 'monument.zip' and extract its contents to the current directory\n",
    "!unzip ./monument.zip -d ./\n",
    "\n",
    "# Remove the original zip file 'monument.zip' from '/content/nmt/'\n",
    "!rm /content/nmt/monument.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1688984641803,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "dbGofKann5xB",
    "outputId": "07d04bf5-3b57-4bc0-b989-4df00de68311"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__MACOSX  monument  nmtmodel\n"
     ]
    }
   ],
   "source": [
    "# List the contents of the current directory\n",
    "!ls\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZZiY1mojsEkl"
   },
   "source": [
    "# Knowledge Graph Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 376048,
     "status": "ok",
     "timestamp": 1688985017847,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "YTD24q1UsEPM"
   },
   "outputs": [],
   "source": [
    "# Create a new directory named \"graph_embedding_dir\" using the mkdir command\n",
    "!mkdir \"graph_embedding_dir\"\n",
    "\n",
    "# Copy the file \"embedding.vec\" from the source directory in Google Drive\n",
    "# to the destination directory \"/content/nmt/graph_embedding_dir\"\n",
    "!cp /content/drive/MyDrive/embedding.vec /content/nmt/graph_embedding_dir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c-Nfw0l77P8e"
   },
   "source": [
    "# Create the Training Configuration File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1688985017847,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "9uBY92Mf8vE6"
   },
   "outputs": [],
   "source": [
    "model_root = '/content/nmt/nmtmodel'\n",
    "\n",
    "# Create a directory named 'nmtmodel' using the model_root path\n",
    "!mkdir -p '{model_root}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1688985017848,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "xAJ686rIvLRn"
   },
   "outputs": [],
   "source": [
    "# Define the configuration as a formatted string\n",
    "config = f'''# config.yaml\n",
    "# GloVe:\n",
    "# this means embeddings will be used for both encoder and decoder sides\n",
    "both_embeddings: /content/nmt/graph_embedding_dir/embedding.vec\n",
    "\n",
    "# supported types: GloVe, word2vec\n",
    "embeddings_type: \"word2vec\"\n",
    "\n",
    "# word_vec_size need to match with the pretrained embeddings dimensions\n",
    "word_vec_size: 300\n",
    "\n",
    "## Where the samples will be written\n",
    "save_data: {model_root}\n",
    "\n",
    "## Where the vocab(s) will be written\n",
    "# Vocabulary files, generated by onmt_build_vocab\n",
    "src_vocab: {model_root}/src.vocab\n",
    "tgt_vocab: {model_root}/src.vocab\n",
    "\n",
    "# Vocabulary size - should be the same as in sentence piece\n",
    "src_vocab_size: 5000\n",
    "tgt_vocab_size: 5000\n",
    "share_vocab: true\n",
    "\n",
    "# Training files\n",
    "data:\n",
    "    train:\n",
    "        path_src: /content/nmt/monument/train.en\n",
    "        path_tgt: /content/nmt/monument/train.sparql\n",
    "    valid:\n",
    "        path_src: /content/nmt/monument/dev.en\n",
    "        path_tgt: /content/nmt/monument/dev.sparql\n",
    "\n",
    "# Where to save the checkpoints\n",
    "save_model: {model_root}/model\n",
    "log_file: {model_root}/train.log\n",
    "save_checkpoint_steps: 100\n",
    "train_steps: 1200\n",
    "valid_steps: 400\n",
    "\n",
    "# Stop training if it does not imporve after n validations\n",
    "early_stopping: 4\n",
    "\n",
    "# To save space, limit checkpoints to last n\n",
    "# keep_checkpoint: 3\n",
    "\n",
    "seed: 4242\n",
    "\n",
    "# Number of GPUs, and IDs of GPUs\n",
    "world_size: 1\n",
    "gpu_ranks: [0]\n",
    "\n",
    "# Batching\n",
    "# queue_size: 100\n",
    "bucket_size: 262144\n",
    "num_workers: 0  # Default: 2, set to 0 when RAM out of memory\n",
    "batch_type: \"tokens\"\n",
    "batch_size: 4096   # Tokens per batch, change when CUDA out of memory\n",
    "valid_batch_size: 2048\n",
    "# world_size: 1\n",
    "max_generator_batches: 2\n",
    "accum_count: [4]\n",
    "accum_steps: [0]\n",
    "\n",
    "# Optimization\n",
    "# model_dtype: \"fp16\"\n",
    "optim: \"adam\"\n",
    "# learning_rate: 2\n",
    "warmup_steps: 500\n",
    "decay_method: \"noam\"\n",
    "adam_beta1: 0.9\n",
    "adam_beta2: 0.98\n",
    "max_grad_norm: 0\n",
    "label_smoothing: 0.1\n",
    "param_init: 0\n",
    "param_init_glorot: true\n",
    "normalization: \"tokens\"\n",
    "\n",
    "# Model\n",
    "encoder_type: transformer\n",
    "decoder_type: transformer\n",
    "position_encoding: true\n",
    "enc_layers: 6\n",
    "dec_layers: 6\n",
    "heads: 8\n",
    "hidden_size: 512\n",
    "word_vec_size: 512\n",
    "transformer_ff: 2048\n",
    "# dropout_steps: [0]\n",
    "dropout: [0.1]\n",
    "attention_dropout: [0.1]\n",
    "'''\n",
    "\n",
    "# Write the configuration to a \"config.yaml\" file\n",
    "with open(\"config.yaml\", \"w+\") as config_yaml:\n",
    "  config_yaml.write(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z1ZGev3N7ao3"
   },
   "source": [
    "# Build Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6139,
     "status": "ok",
     "timestamp": 1688985023983,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "F4jDz0Dr7sne",
    "outputId": "46960abf-00e1-4b2d-9cb9-eef04762067a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus train's weight should be given. We default it to 1 for you.\n",
      "[2023-07-10 10:30:21,221 INFO] Counter vocab from -1 samples.\n",
      "[2023-07-10 10:30:21,221 INFO] n_sample=-1: Build vocab on full datasets.\n",
      "[2023-07-10 10:30:21,530 INFO] Counters src: 2569\n",
      "[2023-07-10 10:30:21,530 INFO] Counters tgt: 2058\n",
      "[2023-07-10 10:30:21,531 INFO] Counters after share:4609\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Check if the source vocabulary file doesn't exist in the 'model_root' directory\n",
    "if not os.path.exists(os.path.join(model_root, 'src.vocab')):\n",
    "    # Build the source vocabulary using the onmt_build_vocab command and the provided config.yaml\n",
    "    # The --n_sample option is used to indicate the number of samples to consider for building the vocabulary\n",
    "    # The \"|| true\" at the end ensures that the command won't stop the script even if there's an error\n",
    "    !onmt_build_vocab -config config.yaml --n_sample -1 || true\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V312rtxK7pd7"
   },
   "source": [
    "# Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1909,
     "status": "ok",
     "timestamp": 1688985025885,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "tJ4dYNPtvQ5Q",
    "outputId": "df279f3e-7b0d-43d3-fe6f-e7ec05f848ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jul 10 10:30:23 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   39C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n",
      "\n",
      "\n",
      "$*****************************************************************************$\n",
      "GPU:\n",
      "GPU 0: Tesla T4 (UUID: GPU-ff58c1c9-b266-a304-efaa-b9def5be64b4)\n",
      "$*****************************************************************************$\n",
      "\n",
      "\n",
      "$*****************************************************************************$\n",
      "True\n",
      "Tesla T4\n",
      "Free GPU memory: 14998.8125 out of: 15101.8125\n",
      "$*****************************************************************************$\n",
      "No LSB modules are available.\n",
      "Distributor ID:\tUbuntu\n",
      "Description:\tUbuntu 20.04.6 LTS\n",
      "Release:\t20.04\n",
      "Codename:\tfocal\n",
      "$*****************************************************************************$\n",
      "5.15.107+\n",
      "$*****************************************************************************$\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2022 NVIDIA Corporation\n",
      "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
      "Cuda compilation tools, release 11.8, V11.8.89\n",
      "Build cuda_11.8.r11.8/compiler.31833905_0\n",
      "$*****************************************************************************$\n",
      "1.13.1+cu117\n",
      "$*****************************************************************************$\n",
      "model name\t: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
      "model name\t: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
      "model name\t: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
      "model name\t: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
      "$*****************************************************************************$\n",
      "MemTotal:       26687700 kB\n"
     ]
    }
   ],
   "source": [
    "# Check NVIDIA GPU information using the 'nvidia-smi' command\n",
    "!nvidia-smi\n",
    "\n",
    "# Print a separator line and heading for the GPU information\n",
    "print('\\n\\n$*****************************************************************************$')\n",
    "print('GPU:')\n",
    "\n",
    "# Check and display the GPU devices using 'nvidia-smi -L'\n",
    "!nvidia-smi -L\n",
    "\n",
    "# Print a separator line\n",
    "print('$*****************************************************************************$')\n",
    "\n",
    "# Print a separator line and heading for GPU-related checks\n",
    "print('\\n\\n$*****************************************************************************$')\n",
    "\n",
    "# Check if CUDA-enabled GPU is available for PyTorch\n",
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "# Print the name of the first CUDA-enabled GPU\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "# Get GPU memory information\n",
    "gpu_memory = torch.cuda.mem_get_info(0)\n",
    "print(\"Free GPU memory:\", gpu_memory[0]/1024**2, \"out of:\", gpu_memory[1]/1024**2)\n",
    "\n",
    "# Print a separator line\n",
    "print('$*****************************************************************************$')\n",
    "\n",
    "# Print system information using 'lsb_release -a'\n",
    "!lsb_release -a\n",
    "\n",
    "# Print a separator line\n",
    "print('$*****************************************************************************$')\n",
    "\n",
    "# Print kernel version using 'uname -r'\n",
    "!uname -r\n",
    "\n",
    "# Print a separator line\n",
    "print('$*****************************************************************************$')\n",
    "\n",
    "# Print NVCC (NVIDIA CUDA Compiler) version using 'nvcc --version'\n",
    "!nvcc --version\n",
    "\n",
    "# Print a separator line\n",
    "print('$*****************************************************************************$')\n",
    "\n",
    "# Check Torch version using Python import\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "\n",
    "# Print a separator line\n",
    "print('$*****************************************************************************$')\n",
    "\n",
    "# Display CPU information using 'cat /proc/cpuinfo | grep model\\ name'\n",
    "!cat /proc/cpuinfo | grep model\\ name\n",
    "\n",
    "# Print a separator line\n",
    "print('$*****************************************************************************$')\n",
    "\n",
    "# Display total memory information using 'cat /proc/meminfo | grep MemTotal'\n",
    "!cat /proc/meminfo | grep MemTotal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hmaMw_sc7gvP"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1975998,
     "status": "ok",
     "timestamp": 1688987001880,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "5iMmswvHvta_",
    "outputId": "0a69f882-8410-4ea5-e13f-849bd108b0f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-10 10:30:26,906 INFO] Missing transforms field for train data, set to default: [].\n",
      "[2023-07-10 10:30:26,906 WARNING] Corpus train's weight should be given. We default it to 1 for you.\n",
      "[2023-07-10 10:30:26,906 INFO] Missing transforms field for valid data, set to default: [].\n",
      "[2023-07-10 10:30:26,906 INFO] Parsed 2 corpora from -data.\n",
      "[2023-07-10 10:30:26,906 INFO] Get special vocabs from Transforms: {'src': [], 'tgt': []}.\n",
      "[2023-07-10 10:30:26,925 INFO] Reading encoder and decoder embeddings from /content/nmt/graph_embedding_dir/embedding.vec\n",
      "[2023-07-10 10:34:05,695 INFO] \tFound 8541203 total vectors in file\n",
      "[2023-07-10 10:34:05,696 INFO] After filtering to vectors in vocab:\n",
      "[2023-07-10 10:34:05,698 INFO] \t* enc: 3522 match, 1094 missing, (76.30%)\n",
      "[2023-07-10 10:34:05,699 INFO] \t* dec: 3522 match, 1094 missing, (76.30%)\n",
      "[2023-07-10 10:34:05,699 INFO] \n",
      "Saving encoder embeddings as:\n",
      "\t* enc: /content/nmt/nmtmodel.enc_embeddings.pt\n",
      "[2023-07-10 10:34:08,889 INFO] \n",
      "Saving decoder embeddings as:\n",
      "\t* dec: /content/nmt/nmtmodel.dec_embeddings.pt\n",
      "[2023-07-10 10:34:12,058 INFO] The first 10 tokens of the vocabs are:['<unk>', '<blank>', '<s>', '</s>', 'var_a', 'where', 'brack_open', 'brack_close', 'select', 'is']\n",
      "[2023-07-10 10:34:12,059 INFO] The decoder start token is: <s>\n",
      "[2023-07-10 10:34:12,059 INFO] Building model...\n",
      "[2023-07-10 10:34:12,715 INFO] Switching model to float32 for amp/apex_amp\n",
      "[2023-07-10 10:34:12,715 INFO] Non quantized layer compute is fp32\n",
      "[2023-07-10 10:34:17,229 INFO] NMTModel(\n",
      "  (encoder): TransformerEncoder(\n",
      "    (embeddings): Embeddings(\n",
      "      (make_embedding): Sequential(\n",
      "        (emb_luts): Elementwise(\n",
      "          (0): Embedding(4616, 512, padding_idx=1)\n",
      "        )\n",
      "        (pe): PositionalEncoding()\n",
      "      )\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): ModuleList(\n",
      "      (0): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (2): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (3): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (4): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (5): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "  )\n",
      "  (decoder): TransformerDecoder(\n",
      "    (embeddings): Embeddings(\n",
      "      (make_embedding): Sequential(\n",
      "        (emb_luts): Elementwise(\n",
      "          (0): Embedding(4616, 512, padding_idx=1)\n",
      "        )\n",
      "        (pe): PositionalEncoding()\n",
      "      )\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "    (transformer_layers): ModuleList(\n",
      "      (0): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (1): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (2): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (3): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (4): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (5): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (generator): Linear(in_features=512, out_features=4616, bias=True)\n",
      ")\n",
      "[2023-07-10 10:34:17,255 INFO] encoder: 21251072\n",
      "[2023-07-10 10:34:17,256 INFO] decoder: 29916680\n",
      "[2023-07-10 10:34:17,256 INFO] * number of parameters: 51167752\n",
      "[2023-07-10 10:34:17,257 INFO] Trainable parameters = {'torch.float32': 51167752, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
      "[2023-07-10 10:34:17,257 INFO] Non trainable parameters = {'torch.float32': 0, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
      "[2023-07-10 10:34:17,257 INFO]  * src vocab size = 4616\n",
      "[2023-07-10 10:34:17,257 INFO]  * tgt vocab size = 4616\n",
      "[2023-07-10 10:34:17,259 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 1\n",
      "[2023-07-10 10:34:17,259 INFO] Starting training on GPU: [0]\n",
      "[2023-07-10 10:34:17,259 INFO] Start training loop and validate every 400 steps...\n",
      "[2023-07-10 10:34:17,260 INFO] Scoring with: TransformPipe()\n",
      "[2023-07-10 10:34:17,551 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 2\n",
      "[2023-07-10 10:34:17,886 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 3\n",
      "[2023-07-10 10:34:18,275 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 4\n",
      "[2023-07-10 10:34:18,474 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 5\n",
      "[2023-07-10 10:34:18,923 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 6\n",
      "[2023-07-10 10:34:19,428 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 7\n",
      "[2023-07-10 10:34:19,627 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 8\n",
      "[2023-07-10 10:34:20,212 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 9\n",
      "[2023-07-10 10:34:20,409 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 10\n",
      "[2023-07-10 10:34:21,098 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 11\n",
      "[2023-07-10 10:34:21,294 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 12\n",
      "[2023-07-10 10:34:21,495 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 13\n",
      "[2023-07-10 10:34:22,319 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 14\n",
      "[2023-07-10 10:34:22,519 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 15\n",
      "[2023-07-10 10:34:22,715 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 16\n",
      "[2023-07-10 10:34:23,689 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 17\n",
      "[2023-07-10 10:34:23,883 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 18\n",
      "[2023-07-10 10:35:41,010 INFO] Step 50/ 1200; acc: 23.6; ppl: 320.6; xent: 5.8; lr: 0.00020; sents:   56850; bsz: 1943/3788/284; 4640/9046 tok/s;     84 sec;\n",
      "[2023-07-10 10:36:48,950 INFO] Step 100/ 1200; acc: 70.9; ppl:  14.3; xent: 2.7; lr: 0.00040; sents:   56940; bsz: 1949/3800/285; 5736/11186 tok/s;    152 sec;\n",
      "[2023-07-10 10:36:48,953 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_100.pt\n",
      "[2023-07-10 10:37:57,966 INFO] Step 150/ 1200; acc: 87.3; ppl:   6.4; xent: 1.9; lr: 0.00060; sents:   54473; bsz: 1916/3812/272; 5552/11047 tok/s;    221 sec;\n",
      "[2023-07-10 10:39:05,706 INFO] Step 200/ 1200; acc: 90.1; ppl:   5.4; xent: 1.7; lr: 0.00079; sents:   54815; bsz: 1899/3808/274; 5608/11244 tok/s;    288 sec;\n",
      "[2023-07-10 10:39:05,708 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_200.pt\n",
      "[2023-07-10 10:39:38,319 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 19\n",
      "[2023-07-10 10:39:38,517 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 20\n",
      "[2023-07-10 10:39:38,714 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 21\n",
      "[2023-07-10 10:39:38,913 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 22\n",
      "[2023-07-10 10:39:39,105 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 23\n",
      "[2023-07-10 10:39:39,307 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 24\n",
      "[2023-07-10 10:39:41,549 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 25\n",
      "[2023-07-10 10:39:41,742 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 26\n",
      "[2023-07-10 10:39:41,934 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 27\n",
      "[2023-07-10 10:39:42,130 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 28\n",
      "[2023-07-10 10:39:42,320 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 29\n",
      "[2023-07-10 10:39:42,512 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 30\n",
      "[2023-07-10 10:39:42,706 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 31\n",
      "[2023-07-10 10:39:45,302 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 32\n",
      "[2023-07-10 10:39:45,503 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 33\n",
      "[2023-07-10 10:39:45,713 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 34\n",
      "[2023-07-10 10:39:45,916 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 35\n",
      "[2023-07-10 10:39:46,128 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 36\n",
      "[2023-07-10 10:40:31,133 INFO] Step 250/ 1200; acc: 93.8; ppl:   4.6; xent: 1.5; lr: 0.00099; sents:   60469; bsz: 2021/3782/302; 4731/8855 tok/s;    374 sec;\n",
      "[2023-07-10 10:41:38,294 INFO] Step 300/ 1200; acc: 96.0; ppl:   4.1; xent: 1.4; lr: 0.00119; sents:   53611; bsz: 1873/3813/268; 5577/11355 tok/s;    441 sec;\n",
      "[2023-07-10 10:41:38,297 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_300.pt\n",
      "[2023-07-10 10:42:47,102 INFO] Step 350/ 1200; acc: 98.3; ppl:   3.6; xent: 1.3; lr: 0.00139; sents:   55022; bsz: 1920/3809/275; 5581/11072 tok/s;    510 sec;\n",
      "[2023-07-10 10:43:54,635 INFO] Step 400/ 1200; acc: 98.9; ppl:   3.5; xent: 1.2; lr: 0.00159; sents:   56225; bsz: 1932/3801/281; 5721/11257 tok/s;    577 sec;\n",
      "[2023-07-10 10:43:54,757 INFO] valid stats calculation and sentences rebuilding\n",
      "                           took: 0.1204686164855957 s.\n",
      "[2023-07-10 10:43:54,758 INFO] Train perplexity: 8.80832\n",
      "[2023-07-10 10:43:54,758 INFO] Train accuracy: 82.4012\n",
      "[2023-07-10 10:43:54,758 INFO] Sentences processed: 448405\n",
      "[2023-07-10 10:43:54,758 INFO] Average bsz: 1932/3802/280\n",
      "[2023-07-10 10:43:54,758 INFO] Validation perplexity: 3.68386\n",
      "[2023-07-10 10:43:54,758 INFO] Validation accuracy: 97.9089\n",
      "[2023-07-10 10:43:54,758 INFO] Model is improving ppl: inf --> 3.68386.\n",
      "[2023-07-10 10:43:54,758 INFO] Model is improving acc: -inf --> 97.9089.\n",
      "[2023-07-10 10:43:54,761 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_400.pt\n",
      "[2023-07-10 10:44:59,720 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 37\n",
      "[2023-07-10 10:44:59,917 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 38\n",
      "[2023-07-10 10:45:02,085 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 39\n",
      "[2023-07-10 10:45:02,306 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 40\n",
      "[2023-07-10 10:45:02,521 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 41\n",
      "[2023-07-10 10:45:02,728 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 42\n",
      "[2023-07-10 10:45:02,933 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 43\n",
      "[2023-07-10 10:45:03,124 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 44\n",
      "[2023-07-10 10:45:05,533 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 45\n",
      "[2023-07-10 10:45:05,713 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 46\n",
      "[2023-07-10 10:45:05,896 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 47\n",
      "[2023-07-10 10:45:06,081 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 48\n",
      "[2023-07-10 10:45:06,264 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 49\n",
      "[2023-07-10 10:45:06,440 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 50\n",
      "[2023-07-10 10:45:06,625 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 51\n",
      "[2023-07-10 10:45:09,420 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 52\n",
      "[2023-07-10 10:45:09,598 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 53\n",
      "[2023-07-10 10:45:09,776 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 54\n",
      "[2023-07-10 10:45:21,990 INFO] Step 450/ 1200; acc: 98.6; ppl:   3.5; xent: 1.3; lr: 0.00178; sents:   57928; bsz: 1979/3786/290; 4532/8668 tok/s;    665 sec;\n",
      "[2023-07-10 10:46:29,644 INFO] Step 500/ 1200; acc: 99.1; ppl:   3.4; xent: 1.2; lr: 0.00197; sents:   57305; bsz: 1946/3798/287; 5752/11227 tok/s;    732 sec;\n",
      "[2023-07-10 10:46:29,647 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_500.pt\n",
      "[2023-07-10 10:47:38,370 INFO] Step 550/ 1200; acc: 99.1; ppl:   3.4; xent: 1.2; lr: 0.00188; sents:   56814; bsz: 1957/3799/284; 5694/11056 tok/s;    801 sec;\n",
      "[2023-07-10 10:48:45,667 INFO] Step 600/ 1200; acc: 99.1; ppl:   3.4; xent: 1.2; lr: 0.00180; sents:   55678; bsz: 1925/3795/278; 5721/11279 tok/s;    868 sec;\n",
      "[2023-07-10 10:48:45,670 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_600.pt\n",
      "[2023-07-10 10:49:54,739 INFO] Step 650/ 1200; acc: 99.4; ppl:   3.4; xent: 1.2; lr: 0.00173; sents:   56737; bsz: 1954/3800/284; 5659/11002 tok/s;    937 sec;\n",
      "[2023-07-10 10:50:21,412 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 55\n",
      "[2023-07-10 10:50:21,619 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 56\n",
      "[2023-07-10 10:50:21,815 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 57\n",
      "[2023-07-10 10:50:22,014 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 58\n",
      "[2023-07-10 10:50:24,458 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 59\n",
      "[2023-07-10 10:50:24,661 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 60\n",
      "[2023-07-10 10:50:24,856 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 61\n",
      "[2023-07-10 10:50:25,053 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 62\n",
      "[2023-07-10 10:50:25,254 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 63\n",
      "[2023-07-10 10:50:25,459 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 64\n",
      "[2023-07-10 10:50:25,648 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 65\n",
      "[2023-07-10 10:50:28,418 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 66\n",
      "[2023-07-10 10:50:28,604 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 67\n",
      "[2023-07-10 10:50:28,796 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 68\n",
      "[2023-07-10 10:50:28,995 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 69\n",
      "[2023-07-10 10:50:29,200 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 70\n",
      "[2023-07-10 10:50:29,390 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 71\n",
      "[2023-07-10 10:50:29,603 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 72\n",
      "[2023-07-10 10:51:21,833 INFO] Step 700/ 1200; acc: 99.5; ppl:   3.3; xent: 1.2; lr: 0.00167; sents:   53930; bsz: 1899/3815/270; 4360/8761 tok/s;   1025 sec;\n",
      "[2023-07-10 10:51:21,836 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_700.pt\n",
      "[2023-07-10 10:52:29,492 INFO] Step 750/ 1200; acc: 99.6; ppl:   3.3; xent: 1.2; lr: 0.00161; sents:   54210; bsz: 1878/3812/271; 5550/11268 tok/s;   1092 sec;\n",
      "[2023-07-10 10:53:37,539 INFO] Step 800/ 1200; acc: 99.7; ppl:   3.3; xent: 1.2; lr: 0.00156; sents:   57850; bsz: 1982/3796/289; 5826/11158 tok/s;   1160 sec;\n",
      "[2023-07-10 10:53:37,617 INFO] valid stats calculation and sentences rebuilding\n",
      "                           took: 0.07701897621154785 s.\n",
      "[2023-07-10 10:53:37,619 INFO] Train perplexity: 5.45817\n",
      "[2023-07-10 10:53:37,619 INFO] Train accuracy: 90.8327\n",
      "[2023-07-10 10:53:37,619 INFO] Sentences processed: 898857\n",
      "[2023-07-10 10:53:37,619 INFO] Average bsz: 1936/3801/281\n",
      "[2023-07-10 10:53:37,619 INFO] Validation perplexity: 3.3849\n",
      "[2023-07-10 10:53:37,619 INFO] Validation accuracy: 99.4025\n",
      "[2023-07-10 10:53:37,619 INFO] Model is improving ppl: 3.68386 --> 3.3849.\n",
      "[2023-07-10 10:53:37,619 INFO] Model is improving acc: 97.9089 --> 99.4025.\n",
      "[2023-07-10 10:53:37,621 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_800.pt\n",
      "[2023-07-10 10:54:46,681 INFO] Step 850/ 1200; acc: 99.6; ppl:   3.3; xent: 1.2; lr: 0.00151; sents:   58361; bsz: 1997/3780/292; 5777/10935 tok/s;   1229 sec;\n",
      "[2023-07-10 10:55:45,635 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 73\n",
      "[2023-07-10 10:55:45,838 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 74\n",
      "[2023-07-10 10:55:46,033 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 75\n",
      "[2023-07-10 10:55:46,227 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 76\n",
      "[2023-07-10 10:55:46,422 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 77\n",
      "[2023-07-10 10:55:46,614 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 78\n",
      "[2023-07-10 10:55:46,812 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 79\n",
      "[2023-07-10 10:55:47,003 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 80\n",
      "[2023-07-10 10:55:47,193 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 81\n",
      "[2023-07-10 10:55:47,389 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 82\n",
      "[2023-07-10 10:55:50,241 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 83\n",
      "[2023-07-10 10:55:50,442 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 84\n",
      "[2023-07-10 10:55:50,650 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 85\n",
      "[2023-07-10 10:55:50,860 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 86\n",
      "[2023-07-10 10:55:51,069 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 87\n",
      "[2023-07-10 10:55:51,281 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 88\n",
      "[2023-07-10 10:55:51,486 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 89\n",
      "[2023-07-10 10:55:51,682 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 90\n",
      "[2023-07-10 10:56:11,511 INFO] Step 900/ 1200; acc: 99.3; ppl:   3.3; xent: 1.2; lr: 0.00147; sents:   55575; bsz: 1896/3806/278; 4471/8972 tok/s;   1314 sec;\n",
      "[2023-07-10 10:56:11,514 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_900.pt\n",
      "[2023-07-10 10:57:20,319 INFO] Step 950/ 1200; acc: 99.6; ppl:   3.3; xent: 1.2; lr: 0.00143; sents:   57348; bsz: 1944/3797/287; 5651/11036 tok/s;   1383 sec;\n",
      "[2023-07-10 10:58:27,548 INFO] Step 1000/ 1200; acc: 99.5; ppl:   3.3; xent: 1.2; lr: 0.00140; sents:   54239; bsz: 1904/3812/271; 5665/11340 tok/s;   1450 sec;\n",
      "[2023-07-10 10:58:27,551 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_1000.pt\n",
      "[2023-07-10 10:59:36,066 INFO] Step 1050/ 1200; acc: 99.7; ppl:   3.3; xent: 1.2; lr: 0.00136; sents:   55960; bsz: 1939/3797/280; 5660/11083 tok/s;   1519 sec;\n",
      "[2023-07-10 11:00:43,664 INFO] Step 1100/ 1200; acc: 99.8; ppl:   3.3; xent: 1.2; lr: 0.00133; sents:   58259; bsz: 1969/3793/291; 5827/11221 tok/s;   1586 sec;\n",
      "[2023-07-10 11:00:43,667 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_1100.pt\n",
      "[2023-07-10 11:01:07,760 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 91\n",
      "[2023-07-10 11:01:07,979 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 92\n",
      "[2023-07-10 11:01:08,199 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 93\n",
      "[2023-07-10 11:01:08,411 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 94\n",
      "[2023-07-10 11:01:08,622 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 95\n",
      "[2023-07-10 11:01:08,827 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 96\n",
      "[2023-07-10 11:01:09,040 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 97\n",
      "[2023-07-10 11:01:09,269 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 98\n",
      "[2023-07-10 11:01:09,477 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 99\n",
      "[2023-07-10 11:01:12,204 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 100\n",
      "[2023-07-10 11:01:12,399 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 101\n",
      "[2023-07-10 11:01:12,589 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 102\n",
      "[2023-07-10 11:01:12,778 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 103\n",
      "[2023-07-10 11:01:12,969 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 104\n",
      "[2023-07-10 11:01:13,166 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 105\n",
      "[2023-07-10 11:01:13,358 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 106\n",
      "[2023-07-10 11:01:16,443 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 107\n",
      "[2023-07-10 11:01:16,636 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 108\n",
      "[2023-07-10 11:02:10,362 INFO] Step 1150/ 1200; acc: 99.7; ppl:   3.3; xent: 1.2; lr: 0.00130; sents:   56355; bsz: 1951/3798/282; 4502/8761 tok/s;   1673 sec;\n",
      "[2023-07-10 11:03:17,667 INFO] Step 1200/ 1200; acc: 99.6; ppl:   3.3; xent: 1.2; lr: 0.00128; sents:   55517; bsz: 1924/3804/278; 5717/11305 tok/s;   1740 sec;\n",
      "[2023-07-10 11:03:17,748 INFO] valid stats calculation and sentences rebuilding\n",
      "                           took: 0.07936573028564453 s.\n",
      "[2023-07-10 11:03:17,749 INFO] Train perplexity: 4.61661\n",
      "[2023-07-10 11:03:17,750 INFO] Train accuracy: 93.7483\n",
      "[2023-07-10 11:03:17,750 INFO] Sentences processed: 1.35047e+06\n",
      "[2023-07-10 11:03:17,750 INFO] Average bsz: 1937/3800/281\n",
      "[2023-07-10 11:03:17,750 INFO] Validation perplexity: 3.38075\n",
      "[2023-07-10 11:03:17,750 INFO] Validation accuracy: 99.5519\n",
      "[2023-07-10 11:03:17,750 INFO] Model is improving ppl: 3.3849 --> 3.38075.\n",
      "[2023-07-10 11:03:17,750 INFO] Model is improving acc: 99.4025 --> 99.5519.\n",
      "[2023-07-10 11:03:17,752 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_1200.pt\n"
     ]
    }
   ],
   "source": [
    "# Train the NMT model using the configuration defined in 'config.yaml'\n",
    "!onmt_train -config config.yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1688987001881,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "ro-21ODLnBNU",
    "outputId": "38610d4e-147a-4efd-af68-0f5924a7bddf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_step_1000.pt  model_step_200.pt  model_step_600.pt  src.vocab\n",
      "model_step_100.pt   model_step_300.pt  model_step_700.pt  train.log\n",
      "model_step_1100.pt  model_step_400.pt  model_step_800.pt\n",
      "model_step_1200.pt  model_step_500.pt  model_step_900.pt\n"
     ]
    }
   ],
   "source": [
    "# List the contents of the 'model_root' directory\n",
    "!ls '{model_root}'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nqRou9WfsDbh"
   },
   "source": [
    "# Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10752,
     "status": "ok",
     "timestamp": 1688987012630,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "tStHVtbNmipI",
    "outputId": "1e1932e7-12dc-4f29-910f-afa6865aa051"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-10 11:03:22,971 INFO] Loading checkpoint from /content/nmt/nmtmodel/model_step_1200.pt\n",
      "[2023-07-10 11:03:23,590 INFO] Loading data into the model\n",
      "[2023-07-10 11:03:31,934 INFO] PRED SCORE: -0.0938, PRED PPL: 1.10 NB SENTENCES: 100\n"
     ]
    }
   ],
   "source": [
    "# Perform translation using the trained NMT model\n",
    "# --model specifies the path to the trained model checkpoint\n",
    "# --src specifies the path to the source text file to be translated\n",
    "# --output specifies the path to save the translated output\n",
    "# -beam_size specifies the beam size for beam search\n",
    "!onmt_translate --model '/content/nmt/nmtmodel/model_step_1200.pt' --src /content/nmt/monument/test.en --output /content/nmt/monument/trans_test.sparql -beam_size 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1688987012631,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "UYszCfIbssof",
    "outputId": "bbaf3c28-539c-4de6-a7f9-7294f999516a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "which is longer los angeles police department memorial for fallen officers or national war memorial\n",
      "how many monument does byk talar have\n",
      "location of mint clock tower\n",
      "how many place does foshan have\n",
      "is ramagrama stupa a monument\n"
     ]
    }
   ],
   "source": [
    "# Display the first 5 lines of the file 'test.en'\n",
    "!head -n 5 /content/nmt/monument/test.en\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 419,
     "status": "ok",
     "timestamp": 1688987013032,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "nnTRp6eas_p7",
    "outputId": "ff79b45b-d78b-47fc-c043-ea195699ba33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select var_a where brack_open var_a dbp_length var_b sep_dot FILTER par_open var_a = dbr_Los_Angeles_Police_Department_Memorial_for_Fallen_Officers || var_a = dbr_National_War_Memorial_ par_open Canada par_close par_close brack_close order by var_b limit 1\n",
      "select count par_open wildcard par_close where brack_open var_a rdf_type dbo_Monument sep_dot var_a dbo_location dbr_Byk_Talar brack_close group by var_a\n",
      "select var_a where brack_open dbr_Mint_Clock_Tower,_Chennai dbo_location var_a brack_close\n",
      "select count par_open wildcard par_close where brack_open var_a rdf_type dbo_Place sep_dot var_a dbo_location dbr_Foshan brack_close group by var_a\n",
      "ask where brack_open dbr_Ramagrama_stupa rdf_type dbo_Monument brack_close\n"
     ]
    }
   ],
   "source": [
    "# Display the first 5 lines of the file 'trans_test.sparql'\n",
    "!head -n 5 /content/nmt/monument/trans_test.sparql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1688987013032,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "azi6x-EstHYN",
    "outputId": "9ced3957-9d04-412e-be26-055b6a33de35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select var_a where brack_open var_a dbp_length var_b sep_dot FILTER par_open var_a = dbr_Los_Angeles_Police_Department_Memorial_for_Fallen_Officers || var_a = dbr_National_War_Memorial_ par_open Canada par_close  par_close  brack_close order by var_b limit 1\n",
      "select count par_open wildcard par_close  where brack_open var_a rdf_type dbo_Monument sep_dot var_a dbo_location dbr_Byk_Talar brack_close group by var_a\n",
      "select var_a where brack_open dbr_Mint_Clock_Tower,_Chennai dbo_location var_a brack_close\n",
      "select count par_open wildcard par_close  where brack_open var_a rdf_type dbo_Place sep_dot var_a dbo_location dbr_Foshan brack_close group by var_a\n",
      "ask where brack_open dbr_Ramagrama_stupa rdf_type dbo_Monument brack_close\n"
     ]
    }
   ],
   "source": [
    "# Display the first 5 lines of the file 'test.sparql'\n",
    "!head -n 5 /content/nmt/monument/test.sparql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vANuMTJUtfUb"
   },
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1688987013032,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "kj1AtrSDtjfq",
    "outputId": "91e4869f-4d97-470f-f618-a1cf31ef54a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/nmt\n"
     ]
    }
   ],
   "source": [
    "# Print the current working directory\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 503,
     "status": "ok",
     "timestamp": 1688987013534,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "9OhvK6N3ecsm",
    "outputId": "1b727516-351d-4e16-e339-c8a434a0f946"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference 1st sentence: select var_a where brack_open var_a dbp_length var_b sep_dot FILTER par_open var_a = dbr_Los_Angeles_Police_Department_Memorial_for_Fallen_Officers || var_a = dbr_National_War_Memorial_ par_open Canada par_close  par_close  brack_close order by var_b limit 1\n",
      "MTed 1st sentence: select var_a where brack_open var_a dbp_length var_b sep_dot FILTER par_open var_a = dbr_Los_Angeles_Police_Department_Memorial_for_Fallen_Officers || var_a = dbr_National_War_Memorial_ par_open Canada par_close par_close brack_close order by var_b limit 1\n",
      "Accuracy:  0.9604200323101777\n"
     ]
    }
   ],
   "source": [
    "# Copy the file \"compute-accuracy.py\" from \"/content/drive/MyDrive/\" to the current directory\n",
    "!cp /content/drive/MyDrive/compute-accuracy.py ./\n",
    "\n",
    "# Evaluate the translation using the provided accuracy computation script\n",
    "# - The first argument is the path to the reference (gold standard) sparql file\n",
    "# - The second argument is the path to the translated sparql file\n",
    "!python compute-accuracy.py /content/nmt/monument/test.sparql /content/nmt/monument/trans_test.sparql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5954,
     "status": "ok",
     "timestamp": 1688987019485,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "CBxRt66trVw5",
    "outputId": "4274bd48-a031-4a18-fad6-123b07b52b14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference 1st sentence: select var_a where brack_open var_a dbp_length var_b sep_dot FILTER par_open var_a = dbr_Los_Angeles_Police_Department_Memorial_for_Fallen_Officers || var_a = dbr_National_War_Memorial_ par_open Canada par_close  par_close  brack_close order by var_b limit 1\n",
      "MTed 1st sentence: select var_a where brack_open var_a dbp_length var_b sep_dot FILTER par_open var_a = dbr_Los_Angeles_Police_Department_Memorial_for_Fallen_Officers || var_a = dbr_National_War_Memorial_ par_open Canada par_close par_close brack_close order by var_b limit 1\n",
      "BLEU:  98.18742831478944\n"
     ]
    }
   ],
   "source": [
    "# Install the sacrebleu library using pip\n",
    "!pip install sacrebleu > /dev/null\n",
    "\n",
    "# Copy the file \"compute-bleu.py\" from \"/content/drive/MyDrive/\" to the current directory\n",
    "!cp /content/drive/MyDrive/compute-bleu.py ./\n",
    "\n",
    "# Evaluate the translation using BLEU score calculation script\n",
    "# - The first argument is the path to the reference (gold standard) sparql file\n",
    "# - The second argument is the path to the translated sparql file\n",
    "!python compute-bleu.py /content/nmt/monument/test.sparql /content/nmt/monument/trans_test.sparql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4639,
     "status": "ok",
     "timestamp": 1688987024114,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "m8OCPRSAxQ_I",
    "outputId": "0761742b-64d1-452c-af31-72b0e08adeb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference 1st sentence: select var_a where brack_open var_a dbp_length var_b sep_dot FILTER par_open var_a = dbr_Los_Angeles_Police_Department_Memorial_for_Fallen_Officers || var_a = dbr_National_War_Memorial_ par_open Canada par_close  par_close  brack_close order by var_b limit 1\n",
      "MTed 1st sentence: select var_a where brack_open var_a dbp_length var_b sep_dot FILTER par_open var_a = dbr_Los_Angeles_Police_Department_Memorial_for_Fallen_Officers || var_a = dbr_National_War_Memorial_ par_open Canada par_close par_close brack_close order by var_b limit 1\n",
      "Rouge-L:  0.9914127404721674\n"
     ]
    }
   ],
   "source": [
    "# Install the rouge library using pip\n",
    "!pip install rouge > /dev/null\n",
    "\n",
    "# Copy the file \"compute-rouge-l.py\" from \"/content/drive/MyDrive/\" to the current directory\n",
    "!cp /content/drive/MyDrive/compute-rouge-l.py ./\n",
    "\n",
    "# Evaluate the translation using Rouge-L score calculation script\n",
    "# - The first argument is the path to the reference (gold standard) sparql file\n",
    "# - The second argument is the path to the translated sparql file\n",
    "!python compute-rouge-l.py /content/nmt/monument/test.sparql /content/nmt/monument/trans_test.sparql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 34102,
     "status": "ok",
     "timestamp": 1688987388358,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "iLKdpy7HfXSN"
   },
   "outputs": [],
   "source": [
    "# Copy the directory 'nmt' and its contents from '/content/nmt' to '/content/drive/MyDrive'\n",
    "!cp -r /content/nmt /content/drive/MyDrive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8L_nKJQMr2nO"
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uu7lspbw1Gxw"
   },
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    ''' ''',\n",
    "    ''' '''\n",
    "]\n",
    "with open('questions.en', 'w') as fp:\n",
    "    t = [''.join(x) for x in sentences]\n",
    "    t = '\\n'.join(t)\n",
    "    fp.write(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! onmt_translate --model '/content/nmt/nmtmodel/model_step_1200.pt' --src questions.en --output pred.sparql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat pred.sparql"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMR6zrDUZfnUBNJejZUoeSd",
   "gpuType": "T4",
   "machine_shape": "hm",
   "mount_file_id": "1kL2iXV4QLLNwfTJbnBk83NU2CBXLdpF2",
   "provenance": [
    {
     "file_id": "1qwBCXsrX0UD96jZU-P9vIhFRTnCZYO6m",
     "timestamp": 1686823688936
    },
    {
     "file_id": "1sYi4GQuLKBmhhiOJvNHDacHYPI39LsG-",
     "timestamp": 1686759059262
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
