{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0w2wNk0167DQ"
   },
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 263,
     "status": "ok",
     "timestamp": 1688997776714,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "6ZH1UZrpjtPE",
    "outputId": "6bfb0531-daff-404d-d6b1-092bbd576957"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/nmt\n"
     ]
    }
   ],
   "source": [
    "# Create a directory named 'nmt'\n",
    "!mkdir nmt\n",
    "\n",
    "# Change the current working directory to the 'nmt' directory\n",
    "%cd nmt\n",
    "\n",
    "# Inside the 'nmt' directory, create a subdirectory named 'nmtmodel'\n",
    "!mkdir nmtmodel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 109599,
     "status": "ok",
     "timestamp": 1688997888347,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "df6W9IIWmlQL",
    "outputId": "55ed58e2-a4f9-4aa7-b087-be0ee0045863"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchdata 0.6.1 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\n",
      "torchtext 0.15.2 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Install the specified versions of OpenNMT-py, torchvision, and torchaudio using pip\n",
    "! pip install OpenNMT-py torchvision==0.14.1 torchaudio==0.13.1 > /dev/null\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1688997888347,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "_3WnsZ-1nUSj",
    "outputId": "42f76f78-a3c4-4a74-89c9-fb9e461d4eda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/nmt\n"
     ]
    }
   ],
   "source": [
    "# Print the current working directory\n",
    "!pwd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QypsRuOq7IiR"
   },
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 532,
     "status": "ok",
     "timestamp": 1688998097379,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "Jsc7THqZnYCI",
    "outputId": "a76873a8-a39a-4a8f-f8a1-a0b7a7665eb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ./monument.zip\n",
      "   creating: ./monument/\n",
      "  inflating: ./__MACOSX/._monument   \n",
      "  inflating: ./monument/dev.en       \n",
      "  inflating: ./__MACOSX/monument/._dev.en  \n",
      "  inflating: ./monument/dev.sparql   \n",
      "  inflating: ./__MACOSX/monument/._dev.sparql  \n",
      "  inflating: ./monument/.DS_Store    \n",
      "  inflating: ./__MACOSX/monument/._.DS_Store  \n",
      "  inflating: ./monument/train.sparql  \n",
      "  inflating: ./__MACOSX/monument/._train.sparql  \n",
      "  inflating: ./monument/train.en     \n",
      "  inflating: ./__MACOSX/monument/._train.en  \n",
      "  inflating: ./monument/test.sparql  \n",
      "  inflating: ./__MACOSX/monument/._test.sparql  \n",
      "  inflating: ./monument/test.en      \n",
      "  inflating: ./__MACOSX/monument/._test.en  \n"
     ]
    }
   ],
   "source": [
    "# Copy the file \"monument.zip\" from \"/content/drive/MyDrive/\" to the current directory\n",
    "!cp /content/drive/MyDrive/monument.zip ./\n",
    "\n",
    "# Unzip the file \"monument.zip\" and extract its contents to the current directory\n",
    "# -d specifies the target directory for extraction\n",
    "!unzip ./monument.zip -d ./\n",
    "\n",
    "# Remove the original zip file \"monument.zip\" from the '/content/nmt/' directory\n",
    "!rm /content/nmt/monument.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 274,
     "status": "ok",
     "timestamp": 1688998103992,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "dbGofKann5xB",
    "outputId": "2acca5a2-ca5e-4da9-b581-fafcd6be8793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__MACOSX  monument  nmtmodel\n"
     ]
    }
   ],
   "source": [
    "# List the contents of the current directory\n",
    "!ls\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZZiY1mojsEkl"
   },
   "source": [
    "# GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 160909,
     "status": "ok",
     "timestamp": 1688998268217,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "YTD24q1UsEPM",
    "outputId": "9149b15e-673b-4faf-d0d8-7150b013e92f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-07-10 14:08:27--  http://nlp.stanford.edu/data/glove.6B.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
      "--2023-07-10 14:08:27--  https://nlp.stanford.edu/data/glove.6B.zip\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
      "--2023-07-10 14:08:27--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 862182613 (822M) [application/zip]\n",
      "Saving to: ‘glove.6B.zip’\n",
      "\n",
      "glove.6B.zip        100%[===================>] 822.24M  4.67MB/s    in 2m 40s  \n",
      "\n",
      "2023-07-10 14:11:07 (5.15 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a directory named 'glove_dir'\n",
    "!mkdir \"glove_dir\"\n",
    "\n",
    "# Download the GloVe embeddings zip file from the specified URL\n",
    "# The --no-check-certificate option is used to bypass SSL certificate validation\n",
    "!wget --no-check-certificate http://nlp.stanford.edu/data/glove.6B.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21090,
     "status": "ok",
     "timestamp": 1688998289300,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "uksk5MCmq1kL",
    "outputId": "824c0eb6-0fbd-4f30-fab5-558af7c87bd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  glove.6B.zip\n",
      "  inflating: glove_dir/glove.6B.50d.txt  \n",
      "  inflating: glove_dir/glove.6B.100d.txt  \n",
      "  inflating: glove_dir/glove.6B.200d.txt  \n",
      "  inflating: glove_dir/glove.6B.300d.txt  \n"
     ]
    }
   ],
   "source": [
    "# Unzip the GloVe embeddings zip file and extract its contents to the 'glove_dir' directory\n",
    "# -d specifies the target directory for extraction\n",
    "!unzip glove.6B.zip -d \"glove_dir\"\n",
    "\n",
    "# Remove the original zip file \"glove.6B.zip\" from the '/content/nmt/' directory\n",
    "!rm /content/nmt/glove.6B.zip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c-Nfw0l77P8e"
   },
   "source": [
    "# Create the Training Configuration File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9uBY92Mf8vE6"
   },
   "outputs": [],
   "source": [
    "# Define the path to the model root directory\n",
    "model_root = '/content/nmt/nmtmodel'\n",
    "\n",
    "# Create the model root directory and any necessary parent directories using 'mkdir -p'\n",
    "!mkdir -p '{model_root}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 234,
     "status": "ok",
     "timestamp": 1689002360185,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "xAJ686rIvLRn"
   },
   "outputs": [],
   "source": [
    "# Define the content for the configuration file 'config.yaml'\n",
    "config = f'''# config.yaml\n",
    "# GloVe:\n",
    "# This means embeddings will be used for both encoder and decoder sides\n",
    "both_embeddings: /content/nmt/glove_dir/glove.6B.300d.txt\n",
    "\n",
    "# Supported types: GloVe, word2vec\n",
    "embeddings_type: \"GloVe\"\n",
    "\n",
    "# word_vec_size needs to match with the pretrained embeddings dimensions\n",
    "word_vec_size: 300\n",
    "\n",
    "## Where the samples will be written\n",
    "save_data: {model_root}\n",
    "\n",
    "## Where the vocab(s) will be written\n",
    "# Vocabulary files, generated by onmt_build_vocab\n",
    "src_vocab: {model_root}/src.vocab\n",
    "tgt_vocab: {model_root}/src.vocab\n",
    "\n",
    "# Vocabulary size - should be the same as in sentence piece\n",
    "src_vocab_size: 5000\n",
    "tgt_vocab_size: 5000\n",
    "share_vocab: true\n",
    "\n",
    "# Training files\n",
    "data:\n",
    "    train:\n",
    "        path_src: /content/nmt/monument/train.en\n",
    "        path_tgt: /content/nmt/monument/train.sparql\n",
    "    valid:\n",
    "        path_src: /content/nmt/monument/dev.en\n",
    "        path_tgt: /content/nmt/monument/dev.sparql\n",
    "\n",
    "# Where to save the checkpoints\n",
    "save_model: {model_root}/model\n",
    "log_file: {model_root}/train.log\n",
    "save_checkpoint_steps: 100\n",
    "train_steps: 1200\n",
    "valid_steps: 400\n",
    "\n",
    "# Stop training if it does not improve after n validations\n",
    "early_stopping: 4\n",
    "\n",
    "# To save space, limit checkpoints to last n\n",
    "# keep_checkpoint: 3\n",
    "\n",
    "seed: 4242\n",
    "\n",
    "# Number of GPUs, and IDs of GPUs\n",
    "world_size: 1\n",
    "gpu_ranks: [0]\n",
    "\n",
    "# Batching\n",
    "# queue_size: 100\n",
    "bucket_size: 262144\n",
    "num_workers: 0  # Default: 2, set to 0 when RAM out of memory\n",
    "batch_type: \"tokens\"\n",
    "batch_size: 4096   # Tokens per batch, change when CUDA out of memory\n",
    "valid_batch_size: 2048\n",
    "# world_size: 1\n",
    "max_generator_batches: 2\n",
    "accum_count: [4]\n",
    "accum_steps: [0]\n",
    "\n",
    "# Optimization\n",
    "# model_dtype: \"fp16\"\n",
    "optim: \"adam\"\n",
    "# learning_rate: 2\n",
    "# warmup_steps: 1000 ######\n",
    "decay_method: \"noam\"\n",
    "adam_beta1: 0.9\n",
    "adam_beta2: 0.98\n",
    "max_grad_norm: 0\n",
    "label_smoothing: 0.1\n",
    "param_init: 0\n",
    "param_init_glorot: true\n",
    "normalization: \"tokens\"\n",
    "\n",
    "# Model\n",
    "encoder_type: transformer\n",
    "decoder_type: transformer\n",
    "position_encoding: true\n",
    "enc_layers: 6\n",
    "dec_layers: 6\n",
    "heads: 8\n",
    "hidden_size: 512\n",
    "word_vec_size: 512\n",
    "transformer_ff: 2048\n",
    "# dropout_steps: [0]\n",
    "dropout: [0.1]\n",
    "attention_dropout: [0.1]\n",
    "'''\n",
    "\n",
    "# Write the configuration content to the 'config.yaml' file\n",
    "with open(\"config.yaml\", \"w+\") as config_yaml:\n",
    "  config_yaml.write(config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z1ZGev3N7ao3"
   },
   "source": [
    "# Build Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 318,
     "status": "ok",
     "timestamp": 1689002363303,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "F4jDz0Dr7sne"
   },
   "outputs": [],
   "source": [
    "# Import the 'os' module for interacting with the operating system\n",
    "import os\n",
    "\n",
    "# Check if the source vocabulary file 'src.vocab' doesn't exist in the model root directory\n",
    "if not os.path.exists(os.path.join(model_root, 'src.vocab')):\n",
    "    # Build the source vocabulary using the onmt_build_vocab command with the specified configuration file\n",
    "    # --n_sample -1: Sample the entire training dataset\n",
    "    # The '|| true' at the end ensures that the command continues even if it encounters an error\n",
    "    !onmt_build_vocab -config config.yaml --n_sample -1 || true\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V312rtxK7pd7"
   },
   "source": [
    "# Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 576,
     "status": "ok",
     "timestamp": 1689002364792,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "tJ4dYNPtvQ5Q",
    "outputId": "3a561d9f-9952-456a-8f1c-6f527e767368"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jul 10 15:19:23 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   73C    P0    33W /  70W |    103MiB / 15360MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n",
      "\n",
      "\n",
      "$*****************************************************************************$\n",
      "GPU:\n",
      "GPU 0: Tesla T4 (UUID: GPU-c69ae79a-9f14-cc21-da71-c05b72975e9d)\n",
      "$*****************************************************************************$\n",
      "\n",
      "\n",
      "$*****************************************************************************$\n",
      "True\n",
      "Tesla T4\n",
      "Free GPU memory: 14998.8125 out of: 15101.8125\n",
      "$*****************************************************************************$\n",
      "No LSB modules are available.\n",
      "Distributor ID:\tUbuntu\n",
      "Description:\tUbuntu 20.04.6 LTS\n",
      "Release:\t20.04\n",
      "Codename:\tfocal\n",
      "$*****************************************************************************$\n",
      "5.15.107+\n",
      "$*****************************************************************************$\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2022 NVIDIA Corporation\n",
      "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
      "Cuda compilation tools, release 11.8, V11.8.89\n",
      "Build cuda_11.8.r11.8/compiler.31833905_0\n",
      "$*****************************************************************************$\n",
      "1.13.1+cu117\n",
      "$*****************************************************************************$\n",
      "model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n",
      "model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n",
      "model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n",
      "model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n",
      "$*****************************************************************************$\n",
      "MemTotal:       26687700 kB\n"
     ]
    }
   ],
   "source": [
    "# Display GPU information using the nvidia-smi command\n",
    "!nvidia-smi\n",
    "\n",
    "# Print a separator line for clarity\n",
    "print('\\n\\n$*****************************************************************************$')\n",
    "\n",
    "# Print \"GPU:\" to indicate GPU-related information\n",
    "print('GPU:')\n",
    "\n",
    "# Display a list of GPUs using the nvidia-smi command with the -L flag\n",
    "!nvidia-smi -L\n",
    "\n",
    "# Print a separator line for clarity\n",
    "print('$*****************************************************************************$')\n",
    "\n",
    "# Print a separator line for clarity\n",
    "print('\\n\\n$*****************************************************************************$')\n",
    "\n",
    "# Check if the GPU is visible and available for PyTorch\n",
    "import torch\n",
    "\n",
    "# Check if CUDA (GPU support for PyTorch) is available\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "# Get the name of the GPU device at index 0\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "# Get GPU memory information using torch.cuda.mem_get_info()\n",
    "gpu_memory = torch.cuda.mem_get_info(0)\n",
    "print(\"Free GPU memory:\", gpu_memory[0]/1024**2, \"out of:\", gpu_memory[1]/1024**2)\n",
    "\n",
    "# Print a separator line for clarity\n",
    "print('$*****************************************************************************$')\n",
    "\n",
    "# Display Linux distribution information using the lsb_release command\n",
    "!lsb_release -a\n",
    "\n",
    "# Print a separator line for clarity\n",
    "print('$*****************************************************************************$')\n",
    "\n",
    "# Display the Linux kernel version using the uname -r command\n",
    "!uname -r\n",
    "\n",
    "# Print a separator line for clarity\n",
    "print('$*****************************************************************************$')\n",
    "\n",
    "# Display the CUDA compiler version using the nvcc --version command\n",
    "!nvcc --version\n",
    "\n",
    "# Print a separator line for clarity\n",
    "print('$*****************************************************************************$')\n",
    "\n",
    "# Display the version of PyTorch using the torch.__version__ attribute\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "\n",
    "# Print a separator line for clarity\n",
    "print('$*****************************************************************************$')\n",
    "\n",
    "# Display CPU information by searching for the \"model name\" in /proc/cpuinfo\n",
    "!cat /proc/cpuinfo | grep model\\ name\n",
    "\n",
    "# Print a separator line for clarity\n",
    "print('$*****************************************************************************$')\n",
    "\n",
    "# Display total memory information using the meminfo file in /proc\n",
    "!cat /proc/meminfo | grep MemTotal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hmaMw_sc7gvP"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1809641,
     "status": "ok",
     "timestamp": 1689004176891,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "5iMmswvHvta_",
    "outputId": "047bd8f3-f262-4704-a601-f225c04934ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-10 15:19:28,641 INFO] Missing transforms field for train data, set to default: [].\n",
      "[2023-07-10 15:19:28,641 WARNING] Corpus train's weight should be given. We default it to 1 for you.\n",
      "[2023-07-10 15:19:28,641 INFO] Missing transforms field for valid data, set to default: [].\n",
      "[2023-07-10 15:19:28,642 INFO] Parsed 2 corpora from -data.\n",
      "[2023-07-10 15:19:28,642 INFO] Get special vocabs from Transforms: {'src': [], 'tgt': []}.\n",
      "[2023-07-10 15:19:28,660 INFO] Reading encoder and decoder embeddings from /content/nmt/glove_dir/glove.6B.300d.txt\n",
      "[2023-07-10 15:19:36,021 INFO] \tFound 400000 total vectors in file\n",
      "[2023-07-10 15:19:36,021 INFO] After filtering to vectors in vocab:\n",
      "[2023-07-10 15:19:36,022 INFO] \t* enc: 2355 match, 2261 missing, (51.02%)\n",
      "[2023-07-10 15:19:36,024 INFO] \t* dec: 2355 match, 2261 missing, (51.02%)\n",
      "[2023-07-10 15:19:36,024 INFO] \n",
      "Saving encoder embeddings as:\n",
      "\t* enc: /content/nmt/nmtmodel.enc_embeddings.pt\n",
      "[2023-07-10 15:19:38,171 INFO] \n",
      "Saving decoder embeddings as:\n",
      "\t* dec: /content/nmt/nmtmodel.dec_embeddings.pt\n",
      "[2023-07-10 15:19:40,322 INFO] The first 10 tokens of the vocabs are:['<unk>', '<blank>', '<s>', '</s>', 'var_a', 'where', 'brack_open', 'brack_close', 'select', 'is']\n",
      "[2023-07-10 15:19:40,322 INFO] The decoder start token is: <s>\n",
      "[2023-07-10 15:19:40,322 INFO] Building model...\n",
      "[2023-07-10 15:19:40,867 INFO] Switching model to float32 for amp/apex_amp\n",
      "[2023-07-10 15:19:40,867 INFO] Non quantized layer compute is fp32\n",
      "[2023-07-10 15:19:42,004 INFO] NMTModel(\n",
      "  (encoder): TransformerEncoder(\n",
      "    (embeddings): Embeddings(\n",
      "      (make_embedding): Sequential(\n",
      "        (emb_luts): Elementwise(\n",
      "          (0): Embedding(4616, 512, padding_idx=1)\n",
      "        )\n",
      "        (pe): PositionalEncoding()\n",
      "      )\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): ModuleList(\n",
      "      (0): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (2): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (3): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (4): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (5): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "  )\n",
      "  (decoder): TransformerDecoder(\n",
      "    (embeddings): Embeddings(\n",
      "      (make_embedding): Sequential(\n",
      "        (emb_luts): Elementwise(\n",
      "          (0): Embedding(4616, 512, padding_idx=1)\n",
      "        )\n",
      "        (pe): PositionalEncoding()\n",
      "      )\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "    (transformer_layers): ModuleList(\n",
      "      (0): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (1): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (2): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (3): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (4): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (5): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (generator): Linear(in_features=512, out_features=4616, bias=True)\n",
      ")\n",
      "[2023-07-10 15:19:42,015 INFO] encoder: 21251072\n",
      "[2023-07-10 15:19:42,015 INFO] decoder: 29916680\n",
      "[2023-07-10 15:19:42,015 INFO] * number of parameters: 51167752\n",
      "[2023-07-10 15:19:42,016 INFO] Trainable parameters = {'torch.float32': 51167752, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
      "[2023-07-10 15:19:42,016 INFO] Non trainable parameters = {'torch.float32': 0, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
      "[2023-07-10 15:19:42,016 INFO]  * src vocab size = 4616\n",
      "[2023-07-10 15:19:42,016 INFO]  * tgt vocab size = 4616\n",
      "[2023-07-10 15:19:42,019 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 1\n",
      "[2023-07-10 15:19:42,019 INFO] Starting training on GPU: [0]\n",
      "[2023-07-10 15:19:42,019 INFO] Start training loop and validate every 400 steps...\n",
      "[2023-07-10 15:19:42,019 INFO] Scoring with: TransformPipe()\n",
      "[2023-07-10 15:19:42,324 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 2\n",
      "[2023-07-10 15:19:42,666 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 3\n",
      "[2023-07-10 15:19:42,875 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 4\n",
      "[2023-07-10 15:19:43,281 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 5\n",
      "[2023-07-10 15:19:43,732 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 6\n",
      "[2023-07-10 15:19:44,276 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 7\n",
      "[2023-07-10 15:19:44,485 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 8\n",
      "[2023-07-10 15:19:45,091 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 9\n",
      "[2023-07-10 15:19:45,302 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 10\n",
      "[2023-07-10 15:19:46,061 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 11\n",
      "[2023-07-10 15:19:46,270 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 12\n",
      "[2023-07-10 15:19:46,482 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 13\n",
      "[2023-07-10 15:19:47,335 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 14\n",
      "[2023-07-10 15:19:47,553 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 15\n",
      "[2023-07-10 15:19:47,763 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 16\n",
      "[2023-07-10 15:19:48,795 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 17\n",
      "[2023-07-10 15:19:49,022 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 18\n",
      "[2023-07-10 15:21:06,359 INFO] Step 50/ 1200; acc: 6.6; ppl: 2961.5; xent: 8.0; lr: 0.00001; sents:   56850; bsz: 1943/3788/284; 4608/8983 tok/s;     84 sec;\n",
      "[2023-07-10 15:22:15,404 INFO] Step 100/ 1200; acc: 24.6; ppl: 535.9; xent: 6.3; lr: 0.00002; sents:   56940; bsz: 1949/3800/285; 5644/11007 tok/s;    153 sec;\n",
      "[2023-07-10 15:22:15,407 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_100.pt\n",
      "[2023-07-10 15:23:27,731 INFO] Step 150/ 1200; acc: 39.2; ppl: 147.6; xent: 5.0; lr: 0.00003; sents:   54473; bsz: 1916/3812/272; 5298/10541 tok/s;    226 sec;\n",
      "[2023-07-10 15:24:36,807 INFO] Step 200/ 1200; acc: 56.0; ppl:  41.2; xent: 3.7; lr: 0.00004; sents:   54815; bsz: 1899/3808/274; 5500/11026 tok/s;    295 sec;\n",
      "[2023-07-10 15:24:36,810 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_200.pt\n",
      "[2023-07-10 15:25:10,371 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 19\n",
      "[2023-07-10 15:25:10,601 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 20\n",
      "[2023-07-10 15:25:10,851 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 21\n",
      "[2023-07-10 15:25:11,106 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 22\n",
      "[2023-07-10 15:25:11,349 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 23\n",
      "[2023-07-10 15:25:11,570 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 24\n",
      "[2023-07-10 15:25:13,959 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 25\n",
      "[2023-07-10 15:25:14,170 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 26\n",
      "[2023-07-10 15:25:14,384 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 27\n",
      "[2023-07-10 15:25:14,600 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 28\n",
      "[2023-07-10 15:25:14,813 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 29\n",
      "[2023-07-10 15:25:15,033 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 30\n",
      "[2023-07-10 15:25:15,240 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 31\n",
      "[2023-07-10 15:25:17,958 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 32\n",
      "[2023-07-10 15:25:18,167 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 33\n",
      "[2023-07-10 15:25:18,379 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 34\n",
      "[2023-07-10 15:25:18,597 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 35\n",
      "[2023-07-10 15:25:18,811 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 36\n",
      "[2023-07-10 15:26:05,553 INFO] Step 250/ 1200; acc: 74.9; ppl:  15.5; xent: 2.7; lr: 0.00004; sents:   60469; bsz: 2021/3782/302; 4554/8524 tok/s;    384 sec;\n",
      "[2023-07-10 15:27:14,100 INFO] Step 300/ 1200; acc: 84.0; ppl:   9.2; xent: 2.2; lr: 0.00005; sents:   53611; bsz: 1873/3813/268; 5464/11126 tok/s;    452 sec;\n",
      "[2023-07-10 15:27:14,102 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_300.pt\n",
      "[2023-07-10 15:28:24,849 INFO] Step 350/ 1200; acc: 88.5; ppl:   6.8; xent: 1.9; lr: 0.00006; sents:   55022; bsz: 1920/3809/275; 5428/10768 tok/s;    523 sec;\n",
      "[2023-07-10 15:29:33,905 INFO] Step 400/ 1200; acc: 89.9; ppl:   5.9; xent: 1.8; lr: 0.00007; sents:   56225; bsz: 1932/3801/281; 5595/11009 tok/s;    592 sec;\n",
      "[2023-07-10 15:29:33,984 INFO] valid stats calculation and sentences rebuilding\n",
      "                           took: 0.07803606986999512 s.\n",
      "[2023-07-10 15:29:33,985 INFO] Train perplexity: 52.0956\n",
      "[2023-07-10 15:29:33,986 INFO] Train accuracy: 57.9826\n",
      "[2023-07-10 15:29:33,986 INFO] Sentences processed: 448405\n",
      "[2023-07-10 15:29:33,986 INFO] Average bsz: 1932/3802/280\n",
      "[2023-07-10 15:29:33,986 INFO] Validation perplexity: 5.79752\n",
      "[2023-07-10 15:29:33,986 INFO] Validation accuracy: 89.8432\n",
      "[2023-07-10 15:29:33,986 INFO] Model is improving ppl: inf --> 5.79752.\n",
      "[2023-07-10 15:29:33,986 INFO] Model is improving acc: -inf --> 89.8432.\n",
      "[2023-07-10 15:29:33,988 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_400.pt\n",
      "[2023-07-10 15:30:40,944 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 37\n",
      "[2023-07-10 15:30:41,155 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 38\n",
      "[2023-07-10 15:30:43,374 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 39\n",
      "[2023-07-10 15:30:43,593 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 40\n",
      "[2023-07-10 15:30:43,806 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 41\n",
      "[2023-07-10 15:30:44,023 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 42\n",
      "[2023-07-10 15:30:44,235 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 43\n",
      "[2023-07-10 15:30:44,458 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 44\n",
      "[2023-07-10 15:30:47,044 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 45\n",
      "[2023-07-10 15:30:47,259 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 46\n",
      "[2023-07-10 15:30:47,454 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 47\n",
      "[2023-07-10 15:30:47,655 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 48\n",
      "[2023-07-10 15:30:47,849 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 49\n",
      "[2023-07-10 15:30:48,045 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 50\n",
      "[2023-07-10 15:30:48,245 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 51\n",
      "[2023-07-10 15:30:51,155 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 52\n",
      "[2023-07-10 15:30:51,347 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 53\n",
      "[2023-07-10 15:30:51,539 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 54\n",
      "[2023-07-10 15:31:04,118 INFO] Step 450/ 1200; acc: 91.0; ppl:   5.4; xent: 1.7; lr: 0.00008; sents:   57928; bsz: 1979/3786/290; 4388/8393 tok/s;    682 sec;\n",
      "[2023-07-10 15:32:14,078 INFO] Step 500/ 1200; acc: 94.0; ppl:   5.0; xent: 1.6; lr: 0.00009; sents:   57305; bsz: 1946/3798/287; 5562/10857 tok/s;    752 sec;\n",
      "[2023-07-10 15:32:14,081 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_500.pt\n",
      "[2023-07-10 15:33:24,833 INFO] Step 550/ 1200; acc: 95.8; ppl:   4.5; xent: 1.5; lr: 0.00010; sents:   56814; bsz: 1957/3799/284; 5531/10739 tok/s;    823 sec;\n",
      "[2023-07-10 15:34:33,945 INFO] Step 600/ 1200; acc: 97.1; ppl:   4.0; xent: 1.4; lr: 0.00010; sents:   55678; bsz: 1925/3795/278; 5571/10983 tok/s;    892 sec;\n",
      "[2023-07-10 15:34:33,948 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_600.pt\n",
      "[2023-07-10 15:35:45,184 INFO] Step 650/ 1200; acc: 97.5; ppl:   3.8; xent: 1.3; lr: 0.00011; sents:   56737; bsz: 1954/3800/284; 5487/10667 tok/s;    963 sec;\n",
      "[2023-07-10 15:36:12,659 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 55\n",
      "[2023-07-10 15:36:12,863 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 56\n",
      "[2023-07-10 15:36:13,068 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 57\n",
      "[2023-07-10 15:36:13,271 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 58\n",
      "[2023-07-10 15:36:15,742 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 59\n",
      "[2023-07-10 15:36:15,946 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 60\n",
      "[2023-07-10 15:36:16,149 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 61\n",
      "[2023-07-10 15:36:16,354 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 62\n",
      "[2023-07-10 15:36:16,565 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 63\n",
      "[2023-07-10 15:36:16,770 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 64\n",
      "[2023-07-10 15:36:16,979 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 65\n",
      "[2023-07-10 15:36:19,815 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 66\n",
      "[2023-07-10 15:36:20,014 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 67\n",
      "[2023-07-10 15:36:20,213 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 68\n",
      "[2023-07-10 15:36:20,423 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 69\n",
      "[2023-07-10 15:36:20,624 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 70\n",
      "[2023-07-10 15:36:20,820 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 71\n",
      "[2023-07-10 15:36:21,031 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 72\n",
      "[2023-07-10 15:37:15,013 INFO] Step 700/ 1200; acc: 97.9; ppl:   3.7; xent: 1.3; lr: 0.00012; sents:   53930; bsz: 1899/3815/270; 4227/8494 tok/s;   1053 sec;\n",
      "[2023-07-10 15:37:15,016 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_700.pt\n",
      "[2023-07-10 15:38:24,592 INFO] Step 750/ 1200; acc: 98.5; ppl:   3.6; xent: 1.3; lr: 0.00013; sents:   54210; bsz: 1878/3812/271; 5397/10957 tok/s;   1123 sec;\n",
      "[2023-07-10 15:39:34,652 INFO] Step 800/ 1200; acc: 99.1; ppl:   3.4; xent: 1.2; lr: 0.00014; sents:   57850; bsz: 1982/3796/289; 5658/10838 tok/s;   1193 sec;\n",
      "[2023-07-10 15:39:34,730 INFO] valid stats calculation and sentences rebuilding\n",
      "                           took: 0.07590317726135254 s.\n",
      "[2023-07-10 15:39:34,731 INFO] Train perplexity: 14.6697\n",
      "[2023-07-10 15:39:34,731 INFO] Train accuracy: 77.169\n",
      "[2023-07-10 15:39:34,731 INFO] Sentences processed: 898857\n",
      "[2023-07-10 15:39:34,731 INFO] Average bsz: 1936/3801/281\n",
      "[2023-07-10 15:39:34,731 INFO] Validation perplexity: 3.46842\n",
      "[2023-07-10 15:39:34,731 INFO] Validation accuracy: 98.8798\n",
      "[2023-07-10 15:39:34,731 INFO] Model is improving ppl: 5.79752 --> 3.46842.\n",
      "[2023-07-10 15:39:34,731 INFO] Model is improving acc: 89.8432 --> 98.8798.\n",
      "[2023-07-10 15:39:34,734 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_800.pt\n",
      "[2023-07-10 15:40:45,990 INFO] Step 850/ 1200; acc: 99.2; ppl:   3.4; xent: 1.2; lr: 0.00015; sents:   58361; bsz: 1997/3780/292; 5599/10599 tok/s;   1264 sec;\n",
      "[2023-07-10 15:41:46,902 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 73\n",
      "[2023-07-10 15:41:47,111 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 74\n",
      "[2023-07-10 15:41:47,319 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 75\n",
      "[2023-07-10 15:41:47,528 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 76\n",
      "[2023-07-10 15:41:47,739 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 77\n",
      "[2023-07-10 15:41:47,949 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 78\n",
      "[2023-07-10 15:41:48,161 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 79\n",
      "[2023-07-10 15:41:48,365 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 80\n",
      "[2023-07-10 15:41:48,574 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 81\n",
      "[2023-07-10 15:41:48,780 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 82\n",
      "[2023-07-10 15:41:51,579 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 83\n",
      "[2023-07-10 15:41:51,781 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 84\n",
      "[2023-07-10 15:41:51,980 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 85\n",
      "[2023-07-10 15:41:52,188 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 86\n",
      "[2023-07-10 15:41:52,394 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 87\n",
      "[2023-07-10 15:41:52,601 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 88\n",
      "[2023-07-10 15:41:52,811 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 89\n",
      "[2023-07-10 15:41:53,009 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 90\n",
      "[2023-07-10 15:42:13,139 INFO] Step 900/ 1200; acc: 99.4; ppl:   3.4; xent: 1.2; lr: 0.00016; sents:   55575; bsz: 1896/3806/278; 4352/8734 tok/s;   1351 sec;\n",
      "[2023-07-10 15:42:13,142 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_900.pt\n",
      "[2023-07-10 15:43:24,639 INFO] Step 950/ 1200; acc: 99.7; ppl:   3.3; xent: 1.2; lr: 0.00017; sents:   57348; bsz: 1944/3797/287; 5438/10621 tok/s;   1423 sec;\n",
      "[2023-07-10 15:44:33,785 INFO] Step 1000/ 1200; acc: 99.7; ppl:   3.3; xent: 1.2; lr: 0.00017; sents:   54239; bsz: 1904/3812/271; 5508/11025 tok/s;   1492 sec;\n",
      "[2023-07-10 15:44:33,788 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_1000.pt\n",
      "[2023-07-10 15:45:44,503 INFO] Step 1050/ 1200; acc: 99.7; ppl:   3.3; xent: 1.2; lr: 0.00018; sents:   55960; bsz: 1939/3797/280; 5484/10738 tok/s;   1562 sec;\n",
      "[2023-07-10 15:46:53,984 INFO] Step 1100/ 1200; acc: 99.7; ppl:   3.3; xent: 1.2; lr: 0.00019; sents:   58259; bsz: 1969/3793/291; 5669/10917 tok/s;   1632 sec;\n",
      "[2023-07-10 15:46:53,987 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_1100.pt\n",
      "[2023-07-10 15:47:18,956 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 91\n",
      "[2023-07-10 15:47:19,168 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 92\n",
      "[2023-07-10 15:47:19,375 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 93\n",
      "[2023-07-10 15:47:19,588 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 94\n",
      "[2023-07-10 15:47:19,794 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 95\n",
      "[2023-07-10 15:47:20,007 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 96\n",
      "[2023-07-10 15:47:20,216 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 97\n",
      "[2023-07-10 15:47:20,431 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 98\n",
      "[2023-07-10 15:47:20,641 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 99\n",
      "[2023-07-10 15:47:23,457 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 100\n",
      "[2023-07-10 15:47:23,664 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 101\n",
      "[2023-07-10 15:47:23,864 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 102\n",
      "[2023-07-10 15:47:24,068 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 103\n",
      "[2023-07-10 15:47:24,278 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 104\n",
      "[2023-07-10 15:47:24,487 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 105\n",
      "[2023-07-10 15:47:24,690 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 106\n",
      "[2023-07-10 15:47:27,922 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 107\n",
      "[2023-07-10 15:47:28,130 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 108\n",
      "[2023-07-10 15:48:24,146 INFO] Step 1150/ 1200; acc: 99.6; ppl:   3.3; xent: 1.2; lr: 0.00020; sents:   56355; bsz: 1951/3798/282; 4329/8424 tok/s;   1722 sec;\n",
      "[2023-07-10 15:49:33,214 INFO] Step 1200/ 1200; acc: 99.8; ppl:   3.3; xent: 1.2; lr: 0.00021; sents:   55517; bsz: 1924/3804/278; 5571/11016 tok/s;   1791 sec;\n",
      "[2023-07-10 15:49:33,295 INFO] valid stats calculation and sentences rebuilding\n",
      "                           took: 0.07912325859069824 s.\n",
      "[2023-07-10 15:49:33,296 INFO] Train perplexity: 8.94519\n",
      "[2023-07-10 15:49:33,296 INFO] Train accuracy: 84.6429\n",
      "[2023-07-10 15:49:33,296 INFO] Sentences processed: 1.35047e+06\n",
      "[2023-07-10 15:49:33,296 INFO] Average bsz: 1937/3800/281\n",
      "[2023-07-10 15:49:33,296 INFO] Validation perplexity: 3.37595\n",
      "[2023-07-10 15:49:33,296 INFO] Validation accuracy: 99.4025\n",
      "[2023-07-10 15:49:33,296 INFO] Model is improving ppl: 3.46842 --> 3.37595.\n",
      "[2023-07-10 15:49:33,296 INFO] Model is improving acc: 98.8798 --> 99.4025.\n",
      "[2023-07-10 15:49:33,299 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_1200.pt\n"
     ]
    }
   ],
   "source": [
    "# Train the neural machine translation (NMT) model using the specified configuration file\n",
    "!onmt_train -config config.yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1689004176892,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "ro-21ODLnBNU",
    "outputId": "51d16784-1857-45bf-b88f-b713e8980626"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_step_1000.pt  model_step_200.pt  model_step_600.pt  src.vocab\n",
      "model_step_100.pt   model_step_300.pt  model_step_700.pt  train.log\n",
      "model_step_1100.pt  model_step_400.pt  model_step_800.pt\n",
      "model_step_1200.pt  model_step_500.pt  model_step_900.pt\n"
     ]
    }
   ],
   "source": [
    "# List the contents of the directory specified by 'model_root'\n",
    "!ls '{model_root}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nqRou9WfsDbh"
   },
   "source": [
    "# Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8369,
     "status": "ok",
     "timestamp": 1689004185259,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "tStHVtbNmipI",
    "outputId": "621e7ed5-5bbd-4de9-a25b-9bf80a8c58e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-10 15:49:37,581 INFO] Loading checkpoint from /content/nmt/nmtmodel/model_step_1200.pt\n",
      "[2023-07-10 15:49:38,236 INFO] Loading data into the model\n",
      "[2023-07-10 15:49:44,596 INFO] PRED SCORE: -0.0807, PRED PPL: 1.08 NB SENTENCES: 100\n"
     ]
    }
   ],
   "source": [
    "# Use the trained NMT model to perform translation on the test data\n",
    "# --model: Path to the trained model checkpoint\n",
    "# --src: Path to the source (input) file for translation\n",
    "# --output: Path to save the translated output\n",
    "# -beam_size: Beam size for beam search decoding\n",
    "!onmt_translate --model '/content/nmt/nmtmodel/model_step_1200.pt' --src /content/nmt/monument/test.en --output /content/nmt/monument/trans_test.sparql -beam_size 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1689004185259,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "UYszCfIbssof",
    "outputId": "6e3172b7-fa18-4f2a-9a8c-15d5472c3594"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "which is longer los angeles police department memorial for fallen officers or national war memorial\n",
      "how many monument does böyük tağlar have\n",
      "location of mint clock tower\n",
      "how many place does foshan have\n",
      "is ramagrama stupa a monument\n"
     ]
    }
   ],
   "source": [
    "# Display the first 5 lines of the 'test.en' file using the 'head' command\n",
    "!head -n 5 /content/nmt/monument/test.en\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 401,
     "status": "ok",
     "timestamp": 1689004185646,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "nnTRp6eas_p7",
    "outputId": "ce0638e3-284c-4ee2-e165-5e9f1e1809d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select var_a where brack_open var_a dbp_length var_b sep_dot FILTER par_open var_a = dbr_Los_Angeles_Police_Department_Memorial_for_Fallen_Officers || var_a = dbr_National_War_Memorial_ par_open Canada par_close par_close brack_close order by var_b limit 1\n",
      "select count par_open wildcard par_close where brack_open var_a rdf_type dbo_Monument sep_dot var_a dbo_location dbr_Böyük_Tağlar brack_close group by var_a\n",
      "select var_a where brack_open dbr_Mint_Clock_Tower,_Chennai dbo_location var_a brack_close\n",
      "select count par_open wildcard par_close where brack_open var_a rdf_type dbo_Place sep_dot var_a dbo_location dbr_Foshan brack_close group by var_a\n",
      "ask where brack_open dbr_Ramagrama_stupa rdf_type dbo_Monument brack_close\n"
     ]
    }
   ],
   "source": [
    "# Display the first 5 lines of the 'trans_test.sparql' file using the 'head' command\n",
    "!head -n 5 /content/nmt/monument/trans_test.sparql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1689004185646,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "azi6x-EstHYN",
    "outputId": "61bb6ff7-b294-46b7-baed-ff98649ac080"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select var_a where brack_open var_a dbp_length var_b sep_dot FILTER par_open var_a = dbr_Los_Angeles_Police_Department_Memorial_for_Fallen_Officers || var_a = dbr_National_War_Memorial_ par_open Canada par_close  par_close  brack_close order by var_b limit 1\n",
      "select count par_open wildcard par_close  where brack_open var_a rdf_type dbo_Monument sep_dot var_a dbo_location dbr_Böyük_Tağlar brack_close group by var_a\n",
      "select var_a where brack_open dbr_Mint_Clock_Tower,_Chennai dbo_location var_a brack_close\n",
      "select count par_open wildcard par_close  where brack_open var_a rdf_type dbo_Place sep_dot var_a dbo_location dbr_Foshan brack_close group by var_a\n",
      "ask where brack_open dbr_Ramagrama_stupa rdf_type dbo_Monument brack_close\n"
     ]
    }
   ],
   "source": [
    "# Display the first 5 lines of the 'test.sparql' file using the 'head' command\n",
    "!head -n 5 /content/nmt/monument/test.sparql\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vANuMTJUtfUb"
   },
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1689004185646,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "kj1AtrSDtjfq",
    "outputId": "abe26f3f-d509-4027-ab7a-69b3e3d857ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/nmt\n"
     ]
    }
   ],
   "source": [
    "# Print the current working directory (current path)\n",
    "!pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 316,
     "status": "ok",
     "timestamp": 1689004358712,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "9OhvK6N3ecsm",
    "outputId": "234dfa34-82ff-45a0-faaf-510950d4ecac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference 1st sentence: select var_a where brack_open var_a dbp_length var_b sep_dot FILTER par_open var_a = dbr_Los_Angeles_Police_Department_Memorial_for_Fallen_Officers || var_a = dbr_National_War_Memorial_ par_open Canada par_close  par_close  brack_close order by var_b limit 1\n",
      "MTed 1st sentence: select var_a where brack_open var_a dbp_length var_b sep_dot FILTER par_open var_a = dbr_Los_Angeles_Police_Department_Memorial_for_Fallen_Officers || var_a = dbr_National_War_Memorial_ par_open Canada par_close par_close brack_close order by var_b limit 1\n",
      "Accuracy:  0.9539579967689822\n"
     ]
    }
   ],
   "source": [
    "# Copy the 'compute-accuracy.py' script from the Google Drive to the current directory\n",
    "!cp /content/drive/MyDrive/compute-accuracy.py ./\n",
    "\n",
    "# Evaluate the translation quality using accuracy\n",
    "# - The script 'compute-accuracy.py' is used to compare the reference translations with the generated translations and compute accuracy.\n",
    "# - It takes the paths of the reference and generated translation files as command-line arguments.\n",
    "!python compute-accuracy.py /content/nmt/monument/test.sparql /content/nmt/monument/trans_test.sparql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4801,
     "status": "ok",
     "timestamp": 1689004366875,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "CBxRt66trVw5",
    "outputId": "4a3169e1-6325-4b79-92d9-f05e64d82002"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference 1st sentence: select var_a where brack_open var_a dbp_length var_b sep_dot FILTER par_open var_a = dbr_Los_Angeles_Police_Department_Memorial_for_Fallen_Officers || var_a = dbr_National_War_Memorial_ par_open Canada par_close  par_close  brack_close order by var_b limit 1\n",
      "MTed 1st sentence: select var_a where brack_open var_a dbp_length var_b sep_dot FILTER par_open var_a = dbr_Los_Angeles_Police_Department_Memorial_for_Fallen_Officers || var_a = dbr_National_War_Memorial_ par_open Canada par_close par_close brack_close order by var_b limit 1\n",
      "BLEU:  97.92929896464074\n"
     ]
    }
   ],
   "source": [
    "# Install the 'sacrebleu' library using pip (with output redirection to /dev/null to suppress output)\n",
    "!pip install sacrebleu > /dev/null\n",
    "\n",
    "# Copy the 'compute-bleu.py' script from Google Drive to the current directory\n",
    "!cp /content/drive/MyDrive/compute-bleu.py ./\n",
    "\n",
    "# Evaluate the translation quality using BLEU\n",
    "# - The script 'compute-bleu.py' is used to compute the BLEU score by comparing the reference translations with the generated translations.\n",
    "# - It takes the paths of the reference and generated translation files as command-line arguments.\n",
    "!python compute-bleu.py /content/nmt/monument/test.sparql /content/nmt/monument/trans_test.sparql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5078,
     "status": "ok",
     "timestamp": 1689004376445,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "m8OCPRSAxQ_I",
    "outputId": "1baf4841-bbf9-43b0-9546-7fa578b4646e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference 1st sentence: select var_a where brack_open var_a dbp_length var_b sep_dot FILTER par_open var_a = dbr_Los_Angeles_Police_Department_Memorial_for_Fallen_Officers || var_a = dbr_National_War_Memorial_ par_open Canada par_close  par_close  brack_close order by var_b limit 1\n",
      "MTed 1st sentence: select var_a where brack_open var_a dbp_length var_b sep_dot FILTER par_open var_a = dbr_Los_Angeles_Police_Department_Memorial_for_Fallen_Officers || var_a = dbr_National_War_Memorial_ par_open Canada par_close par_close brack_close order by var_b limit 1\n",
      "Rouge-L:  0.9911563302157902\n"
     ]
    }
   ],
   "source": [
    "# Install the 'rouge' library using pip (with output redirection to /dev/null to suppress output)\n",
    "!pip install rouge > /dev/null\n",
    "\n",
    "# Copy the 'compute-rouge-l.py' script from Google Drive to the current directory\n",
    "!cp /content/drive/MyDrive/compute-rouge-l.py ./\n",
    "\n",
    "# Evaluate the translation quality using Rouge-L\n",
    "# - The script 'compute-rouge-l.py' is used to compute the Rouge-L score by comparing the reference translations with the generated translations.\n",
    "# - It takes the paths of the reference and generated translation files as command-line arguments.\n",
    "!python compute-rouge-l.py /content/nmt/monument/test.sparql /content/nmt/monument/trans_test.sparql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "executionInfo": {
     "elapsed": 34581,
     "status": "ok",
     "timestamp": 1689004440333,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "oD7LpMzCgaiK"
   },
   "outputs": [],
   "source": [
    "# Copy the trained NMT model directory 'nmtmodel' to a specific directory in Google Drive\n",
    "!cp -r /content/nmt/nmtmodel /content/drive/MyDrive/NMT_models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8L_nKJQMr2nO"
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uu7lspbw1Gxw"
   },
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    ''' ''',\n",
    "    ''' '''\n",
    "]\n",
    "with open('questions.en', 'w') as fp:\n",
    "    t = [''.join(x) for x in sentences]\n",
    "    t = '\\n'.join(t)\n",
    "    fp.write(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! onmt_translate --model '/content/nmt/nmtmodel/model_step_1200.pt' --src questions.en --output pred.sparql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat pred.sparql"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOXNQFRYTWp0aLcRzhPnSq2",
   "gpuType": "T4",
   "machine_shape": "hm",
   "mount_file_id": "1nwB6h_0qecamrABxvBcSrwq_wAZSLGh6",
   "provenance": [
    {
     "file_id": "1qwBCXsrX0UD96jZU-P9vIhFRTnCZYO6m",
     "timestamp": 1686823688936
    },
    {
     "file_id": "1sYi4GQuLKBmhhiOJvNHDacHYPI39LsG-",
     "timestamp": 1686759059262
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
