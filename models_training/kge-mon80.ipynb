{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0w2wNk0167DQ"
   },
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 257,
     "status": "ok",
     "timestamp": 1689174164115,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "6ZH1UZrpjtPE",
    "outputId": "7aa2e788-bf90-4ccc-b59d-eaba7aa6da33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/nmt\n"
     ]
    }
   ],
   "source": [
    "# Create a directory named 'nmt'\n",
    "!mkdir nmt\n",
    "\n",
    "# Change the current working directory to the newly created 'nmt' directory\n",
    "%cd nmt\n",
    "\n",
    "# Create a subdirectory named 'nmtmodel' inside the 'nmt' directory\n",
    "!mkdir nmtmodel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 104860,
     "status": "ok",
     "timestamp": 1689174270972,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "df6W9IIWmlQL",
    "outputId": "ac2afe2a-bf04-425a-d000-92c6330e6d60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchdata 0.6.1 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\n",
      "torchtext 0.15.2 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Install OpenNMT-py along with specific versions of torchvision and torchaudio\n",
    "! pip install OpenNMT-py torchvision==0.14.1 torchaudio==0.13.1 > /dev/null\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1689174270972,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "_3WnsZ-1nUSj",
    "outputId": "16411020-9e4c-4229-8201-de9b6651c325"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/nmt\n"
     ]
    }
   ],
   "source": [
    "# Print the current working directory\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QypsRuOq7IiR"
   },
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 925,
     "status": "ok",
     "timestamp": 1689174271892,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "Jsc7THqZnYCI",
    "outputId": "09ef22a6-c32d-42c3-aeae-af7215291b26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ./monument80.zip\n",
      "   creating: ./monument80/\n",
      "  inflating: ./__MACOSX/._monument80  \n",
      "  inflating: ./monument80/dev.en     \n",
      "  inflating: ./__MACOSX/monument80/._dev.en  \n",
      "  inflating: ./monument80/dev.sparql  \n",
      "  inflating: ./__MACOSX/monument80/._dev.sparql  \n",
      "  inflating: ./monument80/train.sparql  \n",
      "  inflating: ./__MACOSX/monument80/._train.sparql  \n",
      "  inflating: ./monument80/train.en   \n",
      "  inflating: ./__MACOSX/monument80/._train.en  \n",
      "  inflating: ./monument80/test.sparql  \n",
      "  inflating: ./__MACOSX/monument80/._test.sparql  \n",
      "  inflating: ./monument80/test.en    \n",
      "  inflating: ./__MACOSX/monument80/._test.en  \n"
     ]
    }
   ],
   "source": [
    "# Copy the file 'monument80.zip' from '/content/drive/MyDrive/' to the current directory\n",
    "!cp /content/drive/MyDrive/monument80.zip ./\n",
    "\n",
    "# Unzip the file 'monument80.zip' and extract its contents to the current directory\n",
    "!unzip ./monument80.zip -d ./\n",
    "\n",
    "# Remove the original zip file 'monument80.zip' from '/content/nmt/'\n",
    "!rm /content/nmt/monument80.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1689174271892,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "dbGofKann5xB",
    "outputId": "fe330213-7743-44a3-fc21-99c0ec85ea9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__MACOSX  monument80  nmtmodel\n"
     ]
    }
   ],
   "source": [
    "# List the contents of the current directory\n",
    "!ls\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZZiY1mojsEkl"
   },
   "source": [
    "# Knowledge Graph Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 408624,
     "status": "ok",
     "timestamp": 1689174680513,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "YTD24q1UsEPM"
   },
   "outputs": [],
   "source": [
    "# Create a new directory named \"graph_embedding_dir\" using the mkdir command\n",
    "!mkdir \"graph_embedding_dir\"\n",
    "\n",
    "# Copy the file \"embedding.vec\" from the source path in Google Drive\n",
    "# to the destination directory \"/content/nmt/graph_embedding_dir\" in the local file system\n",
    "!cp /content/drive/MyDrive/embedding.vec /content/nmt/graph_embedding_dir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c-Nfw0l77P8e"
   },
   "source": [
    "# Create the Training Configuration File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1689174680514,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "9uBY92Mf8vE6"
   },
   "outputs": [],
   "source": [
    "# Define the root directory path for the NMT model as \"model_root\"\n",
    "model_root = '/content/nmt/nmtmodel'\n",
    "\n",
    "# Create the directory structure for the NMT model using the mkdir command with the -p option\n",
    "# This ensures that the entire directory path is created, including any necessary parent directories\n",
    "!mkdir -p '{model_root}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 246,
     "status": "ok",
     "timestamp": 1689181604004,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "xAJ686rIvLRn"
   },
   "outputs": [],
   "source": [
    "# Define the configuration as a formatted string\n",
    "config = f'''# config.yaml\n",
    "# GloVe:\n",
    "# this means embeddings will be used for both encoder and decoder sides\n",
    "both_embeddings: /content/nmt/graph_embedding_dir/embedding.vec\n",
    "\n",
    "# supported types: GloVe, word2vec\n",
    "embeddings_type: \"word2vec\"\n",
    "\n",
    "# word_vec_size need to match with the pretrained embeddings dimensions\n",
    "word_vec_size: 300\n",
    "\n",
    "## Where the samples will be written\n",
    "save_data: {model_root}\n",
    "\n",
    "## Where the vocab(s) will be written\n",
    "# Vocabulary files, generated by onmt_build_vocab\n",
    "src_vocab: {model_root}/src.vocab\n",
    "tgt_vocab: {model_root}/src.vocab\n",
    "\n",
    "# Vocabulary size - should be the same as in sentence piece\n",
    "src_vocab_size: 5000\n",
    "tgt_vocab_size: 5000\n",
    "share_vocab: true\n",
    "\n",
    "# Training files\n",
    "data:\n",
    "    train:\n",
    "        path_src: /content/nmt/monument80/train.en\n",
    "        path_tgt: /content/nmt/monument80/train.sparql\n",
    "    valid:\n",
    "        path_src: /content/nmt/monument80/dev.en\n",
    "        path_tgt: /content/nmt/monument80/dev.sparql\n",
    "\n",
    "# Where to save the checkpoints\n",
    "save_model: {model_root}/model\n",
    "log_file: {model_root}/train.log\n",
    "save_checkpoint_steps: 100\n",
    "train_steps: 1200\n",
    "valid_steps: 400\n",
    "\n",
    "# Stop training if it does not imporve after n validations\n",
    "early_stopping: 4\n",
    "\n",
    "# To save space, limit checkpoints to last n\n",
    "# keep_checkpoint: 3\n",
    "\n",
    "seed: 43\n",
    "\n",
    "# Number of GPUs, and IDs of GPUs\n",
    "world_size: 1\n",
    "gpu_ranks: [0]\n",
    "\n",
    "# Batching\n",
    "# queue_size: 100\n",
    "bucket_size: 262144\n",
    "num_workers: 0  # Default: 2, set to 0 when RAM out of memory\n",
    "batch_type: \"tokens\"\n",
    "batch_size: 4096   # Tokens per batch, change when CUDA out of memory\n",
    "valid_batch_size: 2048\n",
    "# world_size: 1\n",
    "max_generator_batches: 2\n",
    "accum_count: [4]\n",
    "accum_steps: [0]\n",
    "\n",
    "# Optimization\n",
    "# model_dtype: \"fp16\"\n",
    "optim: \"adam\"\n",
    "# learning_rate: 2\n",
    "warmup_steps: 500\n",
    "decay_method: \"noam\"\n",
    "adam_beta1: 0.9\n",
    "adam_beta2: 0.98\n",
    "max_grad_norm: 0\n",
    "label_smoothing: 0.1\n",
    "param_init: 0\n",
    "param_init_glorot: true\n",
    "normalization: \"tokens\"\n",
    "\n",
    "# Model\n",
    "encoder_type: transformer\n",
    "decoder_type: transformer\n",
    "position_encoding: true\n",
    "enc_layers: 6\n",
    "dec_layers: 6\n",
    "heads: 8\n",
    "hidden_size: 512\n",
    "word_vec_size: 512\n",
    "transformer_ff: 2048\n",
    "# dropout_steps: [0]\n",
    "dropout: [0.1]\n",
    "attention_dropout: [0.1]\n",
    "'''\n",
    "\n",
    "# Write the configuration to a \"config.yaml\" file\n",
    "with open(\"config.yaml\", \"w+\") as config_yaml:\n",
    "  config_yaml.write(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z1ZGev3N7ao3"
   },
   "source": [
    "# Build Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1689181605357,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "F4jDz0Dr7sne"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Check if the source vocabulary file doesn't exist in the 'model_root' directory\n",
    "if not os.path.exists(os.path.join(model_root, 'src.vocab')):\n",
    "    # Build the source vocabulary using the onmt_build_vocab command and the provided config.yaml\n",
    "    # The --n_sample option is used to indicate the number of samples to consider for building the vocabulary\n",
    "    # The \"|| true\" at the end ensures that the command won't stop the script even if there's an error\n",
    "    !onmt_build_vocab -config config.yaml --n_sample -1 || true\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V312rtxK7pd7"
   },
   "source": [
    "# Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 902,
     "status": "ok",
     "timestamp": 1689181607390,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "tJ4dYNPtvQ5Q",
    "outputId": "fb767959-1e13-43ac-8f0e-423337371826"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jul 12 17:06:46 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   71C    P0    32W /  70W |    103MiB / 15360MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n",
      "\n",
      "\n",
      "$*****************************************************************************$\n",
      "GPU:\n",
      "GPU 0: Tesla T4 (UUID: GPU-59e8794a-e121-349d-5463-9962c3f3ea74)\n",
      "$*****************************************************************************$\n",
      "\n",
      "\n",
      "$*****************************************************************************$\n",
      "True\n",
      "Tesla T4\n",
      "Free GPU memory: 14998.8125 out of: 15101.8125\n",
      "$*****************************************************************************$\n",
      "No LSB modules are available.\n",
      "Distributor ID:\tUbuntu\n",
      "Description:\tUbuntu 20.04.6 LTS\n",
      "Release:\t20.04\n",
      "Codename:\tfocal\n",
      "$*****************************************************************************$\n",
      "5.15.107+\n",
      "$*****************************************************************************$\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2022 NVIDIA Corporation\n",
      "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
      "Cuda compilation tools, release 11.8, V11.8.89\n",
      "Build cuda_11.8.r11.8/compiler.31833905_0\n",
      "$*****************************************************************************$\n",
      "1.13.1+cu117\n",
      "$*****************************************************************************$\n",
      "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
      "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
      "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
      "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
      "$*****************************************************************************$\n",
      "MemTotal:       26687700 kB\n"
     ]
    }
   ],
   "source": [
    "# Check NVIDIA GPU information using the 'nvidia-smi' command\n",
    "!nvidia-smi\n",
    "\n",
    "# Print a separator line and heading for the GPU information\n",
    "print('\\n\\n$*****************************************************************************$')\n",
    "print('GPU:')\n",
    "\n",
    "# Check and display the GPU devices using 'nvidia-smi -L'\n",
    "!nvidia-smi -L\n",
    "\n",
    "# Print a separator line\n",
    "print('$*****************************************************************************$')\n",
    "\n",
    "# Print a separator line and heading for GPU-related checks\n",
    "print('\\n\\n$*****************************************************************************$')\n",
    "\n",
    "# Check if CUDA-enabled GPU is available for PyTorch\n",
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "# Print the name of the first CUDA-enabled GPU\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "# Get GPU memory information\n",
    "gpu_memory = torch.cuda.mem_get_info(0)\n",
    "print(\"Free GPU memory:\", gpu_memory[0]/1024**2, \"out of:\", gpu_memory[1]/1024**2)\n",
    "\n",
    "# Print a separator line\n",
    "print('$*****************************************************************************$')\n",
    "\n",
    "# Print system information using 'lsb_release -a'\n",
    "!lsb_release -a\n",
    "\n",
    "# Print a separator line\n",
    "print('$*****************************************************************************$')\n",
    "\n",
    "# Print kernel version using 'uname -r'\n",
    "!uname -r\n",
    "\n",
    "# Print a separator line\n",
    "print('$*****************************************************************************$')\n",
    "\n",
    "# Print NVCC (NVIDIA CUDA Compiler) version using 'nvcc --version'\n",
    "!nvcc --version\n",
    "\n",
    "# Print a separator line\n",
    "print('$*****************************************************************************$')\n",
    "\n",
    "# Check Torch version using Python import\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "\n",
    "# Print a separator line\n",
    "print('$*****************************************************************************$')\n",
    "\n",
    "# Display CPU information using 'cat /proc/cpuinfo | grep model\\ name'\n",
    "!cat /proc/cpuinfo | grep model\\ name\n",
    "\n",
    "# Print a separator line\n",
    "print('$*****************************************************************************$')\n",
    "\n",
    "# Display total memory information using 'cat /proc/meminfo | grep MemTotal'\n",
    "!cat /proc/meminfo | grep MemTotal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hmaMw_sc7gvP"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1912992,
     "status": "ok",
     "timestamp": 1689183521493,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "5iMmswvHvta_",
    "outputId": "34cfdf65-65b6-4dee-ab6a-b5344f74e503"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-12 17:06:49,518 INFO] Missing transforms field for train data, set to default: [].\n",
      "[2023-07-12 17:06:49,518 WARNING] Corpus train's weight should be given. We default it to 1 for you.\n",
      "[2023-07-12 17:06:49,518 INFO] Missing transforms field for valid data, set to default: [].\n",
      "[2023-07-12 17:06:49,518 INFO] Parsed 2 corpora from -data.\n",
      "[2023-07-12 17:06:49,519 INFO] Get special vocabs from Transforms: {'src': [], 'tgt': []}.\n",
      "[2023-07-12 17:06:49,534 INFO] Reading encoder and decoder embeddings from /content/nmt/graph_embedding_dir/embedding.vec\n",
      "[2023-07-12 17:09:53,526 INFO] \tFound 8541203 total vectors in file\n",
      "[2023-07-12 17:09:53,529 INFO] After filtering to vectors in vocab:\n",
      "[2023-07-12 17:09:53,530 INFO] \t* enc: 3265 match, 1023 missing, (76.14%)\n",
      "[2023-07-12 17:09:53,532 INFO] \t* dec: 3265 match, 1023 missing, (76.14%)\n",
      "[2023-07-12 17:09:53,532 INFO] \n",
      "Saving encoder embeddings as:\n",
      "\t* enc: /content/nmt/nmtmodel.enc_embeddings.pt\n",
      "[2023-07-12 17:09:55,984 INFO] \n",
      "Saving decoder embeddings as:\n",
      "\t* dec: /content/nmt/nmtmodel.dec_embeddings.pt\n",
      "[2023-07-12 17:09:58,451 INFO] The first 10 tokens of the vocabs are:['<unk>', '<blank>', '<s>', '</s>', 'var_a', 'where', 'brack_open', 'brack_close', 'select', 'is']\n",
      "[2023-07-12 17:09:58,451 INFO] The decoder start token is: <s>\n",
      "[2023-07-12 17:09:58,451 INFO] Building model...\n",
      "[2023-07-12 17:09:58,923 INFO] Switching model to float32 for amp/apex_amp\n",
      "[2023-07-12 17:09:58,923 INFO] Non quantized layer compute is fp32\n",
      "[2023-07-12 17:10:02,877 INFO] NMTModel(\n",
      "  (encoder): TransformerEncoder(\n",
      "    (embeddings): Embeddings(\n",
      "      (make_embedding): Sequential(\n",
      "        (emb_luts): Elementwise(\n",
      "          (0): Embedding(4288, 512, padding_idx=1)\n",
      "        )\n",
      "        (pe): PositionalEncoding()\n",
      "      )\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): ModuleList(\n",
      "      (0): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (2): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (3): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (4): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (5): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "  )\n",
      "  (decoder): TransformerDecoder(\n",
      "    (embeddings): Embeddings(\n",
      "      (make_embedding): Sequential(\n",
      "        (emb_luts): Elementwise(\n",
      "          (0): Embedding(4288, 512, padding_idx=1)\n",
      "        )\n",
      "        (pe): PositionalEncoding()\n",
      "      )\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "    (transformer_layers): ModuleList(\n",
      "      (0): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (1): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (2): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (3): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (4): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (5): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (generator): Linear(in_features=512, out_features=4288, bias=True)\n",
      ")\n",
      "[2023-07-12 17:10:02,889 INFO] encoder: 21083136\n",
      "[2023-07-12 17:10:02,889 INFO] decoder: 29580480\n",
      "[2023-07-12 17:10:02,889 INFO] * number of parameters: 50663616\n",
      "[2023-07-12 17:10:02,890 INFO] Trainable parameters = {'torch.float32': 50663616, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
      "[2023-07-12 17:10:02,890 INFO] Non trainable parameters = {'torch.float32': 0, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
      "[2023-07-12 17:10:02,890 INFO]  * src vocab size = 4288\n",
      "[2023-07-12 17:10:02,890 INFO]  * tgt vocab size = 4288\n",
      "[2023-07-12 17:10:02,892 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 1\n",
      "[2023-07-12 17:10:02,892 INFO] Starting training on GPU: [0]\n",
      "[2023-07-12 17:10:02,892 INFO] Start training loop and validate every 400 steps...\n",
      "[2023-07-12 17:10:02,892 INFO] Scoring with: TransformPipe()\n",
      "[2023-07-12 17:10:03,038 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 2\n",
      "[2023-07-12 17:10:03,252 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 3\n",
      "[2023-07-12 17:10:03,510 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 4\n",
      "[2023-07-12 17:10:03,847 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 5\n",
      "[2023-07-12 17:10:03,994 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 6\n",
      "[2023-07-12 17:10:04,369 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 7\n",
      "[2023-07-12 17:10:04,826 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 8\n",
      "[2023-07-12 17:10:04,983 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 9\n",
      "[2023-07-12 17:10:05,137 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 10\n",
      "[2023-07-12 17:10:05,679 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 11\n",
      "[2023-07-12 17:10:05,834 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 12\n",
      "[2023-07-12 17:10:06,493 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 13\n",
      "[2023-07-12 17:10:06,650 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 14\n",
      "[2023-07-12 17:10:06,799 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 15\n",
      "[2023-07-12 17:10:06,970 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 16\n",
      "[2023-07-12 17:10:07,770 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 17\n",
      "[2023-07-12 17:10:07,918 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 18\n",
      "[2023-07-12 17:10:08,069 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 19\n",
      "[2023-07-12 17:10:08,213 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 20\n",
      "[2023-07-12 17:10:09,156 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 21\n",
      "[2023-07-12 17:10:09,309 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 22\n",
      "[2023-07-12 17:10:09,461 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 23\n",
      "[2023-07-12 17:11:25,337 INFO] Step 50/ 1200; acc: 26.2; ppl: 304.4; xent: 5.7; lr: 0.00020; sents:   55871; bsz: 1930/3800/279; 4683/9218 tok/s;     82 sec;\n",
      "[2023-07-12 17:12:32,243 INFO] Step 100/ 1200; acc: 73.4; ppl:  12.9; xent: 2.6; lr: 0.00040; sents:   55990; bsz: 1941/3805/280; 5802/11374 tok/s;    149 sec;\n",
      "[2023-07-12 17:12:32,245 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_100.pt\n",
      "[2023-07-12 17:13:40,606 INFO] Step 150/ 1200; acc: 85.8; ppl:   6.6; xent: 1.9; lr: 0.00060; sents:   58345; bsz: 1974/3788/292; 5775/11082 tok/s;    218 sec;\n",
      "[2023-07-12 17:14:46,847 INFO] Step 200/ 1200; acc: 89.1; ppl:   5.5; xent: 1.7; lr: 0.00079; sents:   54318; bsz: 1894/3810/272; 5718/11505 tok/s;    284 sec;\n",
      "[2023-07-12 17:14:46,849 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_200.pt\n",
      "[2023-07-12 17:15:18,948 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 24\n",
      "[2023-07-12 17:15:19,098 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 25\n",
      "[2023-07-12 17:15:19,248 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 26\n",
      "[2023-07-12 17:15:19,397 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 27\n",
      "[2023-07-12 17:15:19,548 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 28\n",
      "[2023-07-12 17:15:19,701 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 29\n",
      "[2023-07-12 17:15:19,851 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 30\n",
      "[2023-07-12 17:15:22,129 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 31\n",
      "[2023-07-12 17:15:22,278 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 32\n",
      "[2023-07-12 17:15:22,422 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 33\n",
      "[2023-07-12 17:15:22,565 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 34\n",
      "[2023-07-12 17:15:22,719 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 35\n",
      "[2023-07-12 17:15:22,864 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 36\n",
      "[2023-07-12 17:15:23,012 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 37\n",
      "[2023-07-12 17:15:23,161 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 38\n",
      "[2023-07-12 17:15:25,751 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 39\n",
      "[2023-07-12 17:15:25,895 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 40\n",
      "[2023-07-12 17:15:26,039 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 41\n",
      "[2023-07-12 17:15:26,184 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 42\n",
      "[2023-07-12 17:15:26,330 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 43\n",
      "[2023-07-12 17:15:26,471 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 44\n",
      "[2023-07-12 17:15:26,615 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 45\n",
      "[2023-07-12 17:16:11,644 INFO] Step 250/ 1200; acc: 92.8; ppl:   4.7; xent: 1.5; lr: 0.00099; sents:   56913; bsz: 1953/3794/285; 4606/8948 tok/s;    369 sec;\n",
      "[2023-07-12 17:17:18,422 INFO] Step 300/ 1200; acc: 96.9; ppl:   3.8; xent: 1.3; lr: 0.00119; sents:   58408; bsz: 1980/3785/292; 5930/11337 tok/s;    436 sec;\n",
      "[2023-07-12 17:17:18,425 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_300.pt\n",
      "[2023-07-12 17:18:25,762 INFO] Step 350/ 1200; acc: 97.1; ppl:   3.8; xent: 1.3; lr: 0.00139; sents:   54523; bsz: 1902/3805/273; 5650/11300 tok/s;    503 sec;\n",
      "[2023-07-12 17:19:32,291 INFO] Step 400/ 1200; acc: 98.7; ppl:   3.5; xent: 1.2; lr: 0.00159; sents:   55546; bsz: 1918/3807/278; 5766/11445 tok/s;    569 sec;\n",
      "[2023-07-12 17:19:33,552 INFO] valid stats calculation and sentences rebuilding\n",
      "                           took: 1.2589993476867676 s.\n",
      "[2023-07-12 17:19:33,553 INFO] Train perplexity: 8.73051\n",
      "[2023-07-12 17:19:33,553 INFO] Train accuracy: 82.4933\n",
      "[2023-07-12 17:19:33,553 INFO] Sentences processed: 449914\n",
      "[2023-07-12 17:19:33,553 INFO] Average bsz: 1937/3799/281\n",
      "[2023-07-12 17:19:33,553 INFO] Validation perplexity: 3.73261\n",
      "[2023-07-12 17:19:33,553 INFO] Validation accuracy: 97.9505\n",
      "[2023-07-12 17:19:33,553 INFO] Model is improving ppl: inf --> 3.73261.\n",
      "[2023-07-12 17:19:33,553 INFO] Model is improving acc: -inf --> 97.9505.\n",
      "[2023-07-12 17:19:33,555 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_400.pt\n",
      "[2023-07-12 17:20:36,298 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 46\n",
      "[2023-07-12 17:20:38,490 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 47\n",
      "[2023-07-12 17:20:38,647 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 48\n",
      "[2023-07-12 17:20:38,812 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 49\n",
      "[2023-07-12 17:20:38,963 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 50\n",
      "[2023-07-12 17:20:39,119 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 51\n",
      "[2023-07-12 17:20:39,263 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 52\n",
      "[2023-07-12 17:20:39,405 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 53\n",
      "[2023-07-12 17:20:39,549 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 54\n",
      "[2023-07-12 17:20:41,950 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 55\n",
      "[2023-07-12 17:20:42,087 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 56\n",
      "[2023-07-12 17:20:42,227 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 57\n",
      "[2023-07-12 17:20:42,363 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 58\n",
      "[2023-07-12 17:20:42,502 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 59\n",
      "[2023-07-12 17:20:42,639 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 60\n",
      "[2023-07-12 17:20:42,779 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 61\n",
      "[2023-07-12 17:20:42,923 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 62\n",
      "[2023-07-12 17:20:43,065 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 63\n",
      "[2023-07-12 17:20:45,908 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 64\n",
      "[2023-07-12 17:20:46,047 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 65\n",
      "[2023-07-12 17:20:46,181 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 66\n",
      "[2023-07-12 17:20:46,323 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 67\n",
      "[2023-07-12 17:20:59,510 INFO] Step 450/ 1200; acc: 99.0; ppl:   3.4; xent: 1.2; lr: 0.00178; sents:   56593; bsz: 1936/3802/283; 4439/8719 tok/s;    657 sec;\n",
      "[2023-07-12 17:22:06,261 INFO] Step 500/ 1200; acc: 98.1; ppl:   3.6; xent: 1.3; lr: 0.00197; sents:   55095; bsz: 1906/3808/275; 5709/11409 tok/s;    723 sec;\n",
      "[2023-07-12 17:22:06,264 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_500.pt\n",
      "[2023-07-12 17:23:14,323 INFO] Step 550/ 1200; acc: 98.4; ppl:   3.5; xent: 1.3; lr: 0.00188; sents:   57221; bsz: 1967/3788/286; 5779/11131 tok/s;    791 sec;\n",
      "[2023-07-12 17:24:20,425 INFO] Step 600/ 1200; acc: 99.3; ppl:   3.3; xent: 1.2; lr: 0.00180; sents:   55655; bsz: 1922/3803/278; 5815/11506 tok/s;    858 sec;\n",
      "[2023-07-12 17:24:20,427 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_600.pt\n",
      "[2023-07-12 17:25:28,072 INFO] Step 650/ 1200; acc: 99.7; ppl:   3.3; xent: 1.2; lr: 0.00173; sents:   57039; bsz: 1960/3800/285; 5794/11235 tok/s;    925 sec;\n",
      "[2023-07-12 17:25:53,074 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 68\n",
      "[2023-07-12 17:25:53,225 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 69\n",
      "[2023-07-12 17:25:53,372 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 70\n",
      "[2023-07-12 17:25:53,519 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 71\n",
      "[2023-07-12 17:25:53,668 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 72\n",
      "[2023-07-12 17:25:56,070 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 73\n",
      "[2023-07-12 17:25:56,216 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 74\n",
      "[2023-07-12 17:25:56,360 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 75\n",
      "[2023-07-12 17:25:56,504 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 76\n",
      "[2023-07-12 17:25:56,647 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 77\n",
      "[2023-07-12 17:25:56,797 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 78\n",
      "[2023-07-12 17:25:56,941 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 79\n",
      "[2023-07-12 17:25:57,081 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 80\n",
      "[2023-07-12 17:25:59,828 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 81\n",
      "[2023-07-12 17:25:59,980 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 82\n",
      "[2023-07-12 17:26:00,127 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 83\n",
      "[2023-07-12 17:26:00,277 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 84\n",
      "[2023-07-12 17:26:00,421 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 85\n",
      "[2023-07-12 17:26:00,559 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 86\n",
      "[2023-07-12 17:26:00,713 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 87\n",
      "[2023-07-12 17:26:00,856 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 88\n",
      "[2023-07-12 17:26:00,995 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 89\n",
      "[2023-07-12 17:26:53,703 INFO] Step 700/ 1200; acc: 99.6; ppl:   3.3; xent: 1.2; lr: 0.00167; sents:   56412; bsz: 1924/3803/282; 4493/8882 tok/s;   1011 sec;\n",
      "[2023-07-12 17:26:53,706 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_700.pt\n",
      "[2023-07-12 17:28:00,729 INFO] Step 750/ 1200; acc: 99.5; ppl:   3.3; xent: 1.2; lr: 0.00161; sents:   55353; bsz: 1908/3808/277; 5693/11363 tok/s;   1078 sec;\n",
      "[2023-07-12 17:29:07,123 INFO] Step 800/ 1200; acc: 99.5; ppl:   3.3; xent: 1.2; lr: 0.00156; sents:   57386; bsz: 1957/3786/287; 5896/11404 tok/s;   1144 sec;\n",
      "[2023-07-12 17:29:08,330 INFO] valid stats calculation and sentences rebuilding\n",
      "                           took: 1.2058689594268799 s.\n",
      "[2023-07-12 17:29:08,331 INFO] Train perplexity: 5.4239\n",
      "[2023-07-12 17:29:08,331 INFO] Train accuracy: 90.8178\n",
      "[2023-07-12 17:29:08,331 INFO] Sentences processed: 900668\n",
      "[2023-07-12 17:29:08,331 INFO] Average bsz: 1936/3799/281\n",
      "[2023-07-12 17:29:08,331 INFO] Validation perplexity: 3.61166\n",
      "[2023-07-12 17:29:08,331 INFO] Validation accuracy: 98.149\n",
      "[2023-07-12 17:29:08,331 INFO] Model is improving ppl: 3.73261 --> 3.61166.\n",
      "[2023-07-12 17:29:08,331 INFO] Model is improving acc: 97.9505 --> 98.149.\n",
      "[2023-07-12 17:29:08,333 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_800.pt\n",
      "[2023-07-12 17:30:15,922 INFO] Step 850/ 1200; acc: 99.5; ppl:   3.3; xent: 1.2; lr: 0.00151; sents:   55702; bsz: 1937/3805/279; 5631/11062 tok/s;   1213 sec;\n",
      "[2023-07-12 17:31:12,661 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 90\n",
      "[2023-07-12 17:31:12,812 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 91\n",
      "[2023-07-12 17:31:12,956 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 92\n",
      "[2023-07-12 17:31:13,102 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 93\n",
      "[2023-07-12 17:31:13,248 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 94\n",
      "[2023-07-12 17:31:13,391 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 95\n",
      "[2023-07-12 17:31:13,535 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 96\n",
      "[2023-07-12 17:31:13,677 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 97\n",
      "[2023-07-12 17:31:13,822 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 98\n",
      "[2023-07-12 17:31:13,965 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 99\n",
      "[2023-07-12 17:31:14,111 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 100\n",
      "[2023-07-12 17:31:16,819 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 101\n",
      "[2023-07-12 17:31:16,961 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 102\n",
      "[2023-07-12 17:31:17,107 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 103\n",
      "[2023-07-12 17:31:17,251 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 104\n",
      "[2023-07-12 17:31:17,393 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 105\n",
      "[2023-07-12 17:31:17,533 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 106\n",
      "[2023-07-12 17:31:17,679 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 107\n",
      "[2023-07-12 17:31:17,824 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 108\n",
      "[2023-07-12 17:31:17,970 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 109\n",
      "[2023-07-12 17:31:18,110 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 110\n",
      "[2023-07-12 17:31:21,237 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 111\n",
      "[2023-07-12 17:31:38,835 INFO] Step 900/ 1200; acc: 99.4; ppl:   3.3; xent: 1.2; lr: 0.00147; sents:   57377; bsz: 1971/3792/287; 4754/9147 tok/s;   1296 sec;\n",
      "[2023-07-12 17:31:38,838 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_900.pt\n",
      "[2023-07-12 17:32:46,867 INFO] Step 950/ 1200; acc: 99.5; ppl:   3.3; xent: 1.2; lr: 0.00143; sents:   56444; bsz: 1939/3797/282; 5699/11163 tok/s;   1364 sec;\n",
      "[2023-07-12 17:33:52,919 INFO] Step 1000/ 1200; acc: 99.4; ppl:   3.3; xent: 1.2; lr: 0.00140; sents:   55872; bsz: 1931/3806/279; 5846/11525 tok/s;   1430 sec;\n",
      "[2023-07-12 17:33:52,922 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_1000.pt\n",
      "[2023-07-12 17:35:00,377 INFO] Step 1050/ 1200; acc: 99.6; ppl:   3.3; xent: 1.2; lr: 0.00136; sents:   57008; bsz: 1953/3795/285; 5790/11253 tok/s;   1497 sec;\n",
      "[2023-07-12 17:36:06,312 INFO] Step 1100/ 1200; acc: 99.7; ppl:   3.3; xent: 1.2; lr: 0.00133; sents:   54888; bsz: 1900/3802/274; 5763/11532 tok/s;   1563 sec;\n",
      "[2023-07-12 17:36:06,314 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_1100.pt\n",
      "[2023-07-12 17:36:28,850 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 112\n",
      "[2023-07-12 17:36:29,004 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 113\n",
      "[2023-07-12 17:36:29,151 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 114\n",
      "[2023-07-12 17:36:29,306 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 115\n",
      "[2023-07-12 17:36:29,452 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 116\n",
      "[2023-07-12 17:36:29,604 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 117\n",
      "[2023-07-12 17:36:29,764 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 118\n",
      "[2023-07-12 17:36:29,926 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 119\n",
      "[2023-07-12 17:36:30,086 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 120\n",
      "[2023-07-12 17:36:30,248 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 121\n",
      "[2023-07-12 17:36:32,996 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 122\n",
      "[2023-07-12 17:36:33,145 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 123\n",
      "[2023-07-12 17:36:33,295 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 124\n",
      "[2023-07-12 17:36:33,437 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 125\n",
      "[2023-07-12 17:36:33,582 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 126\n",
      "[2023-07-12 17:36:33,729 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 127\n",
      "[2023-07-12 17:36:33,872 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 128\n",
      "[2023-07-12 17:36:34,013 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 129\n",
      "[2023-07-12 17:36:34,156 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 130\n",
      "[2023-07-12 17:36:37,198 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 131\n",
      "[2023-07-12 17:36:37,341 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 132\n",
      "[2023-07-12 17:36:37,484 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 133\n",
      "[2023-07-12 17:37:31,453 INFO] Step 1150/ 1200; acc: 99.7; ppl:   3.3; xent: 1.2; lr: 0.00130; sents:   55340; bsz: 1917/3805/277; 4503/8937 tok/s;   1649 sec;\n",
      "[2023-07-12 17:38:37,241 INFO] Step 1200/ 1200; acc: 99.8; ppl:   3.2; xent: 1.2; lr: 0.00128; sents:   58148; bsz: 1951/3794/291; 5932/11534 tok/s;   1714 sec;\n",
      "[2023-07-12 17:38:38,526 INFO] valid stats calculation and sentences rebuilding\n",
      "                           took: 1.2832872867584229 s.\n",
      "[2023-07-12 17:38:38,527 INFO] Train perplexity: 4.59025\n",
      "[2023-07-12 17:38:38,527 INFO] Train accuracy: 93.7352\n",
      "[2023-07-12 17:38:38,527 INFO] Sentences processed: 1.35145e+06\n",
      "[2023-07-12 17:38:38,527 INFO] Average bsz: 1936/3799/282\n",
      "[2023-07-12 17:38:38,527 INFO] Validation perplexity: 3.54883\n",
      "[2023-07-12 17:38:38,527 INFO] Validation accuracy: 98.3723\n",
      "[2023-07-12 17:38:38,527 INFO] Model is improving ppl: 3.61166 --> 3.54883.\n",
      "[2023-07-12 17:38:38,527 INFO] Model is improving acc: 98.149 --> 98.3723.\n",
      "[2023-07-12 17:38:38,529 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_1200.pt\n"
     ]
    }
   ],
   "source": [
    "# Train the NMT model using the configuration defined in 'config.yaml'\n",
    "!onmt_train -config config.yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1689183521493,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "ro-21ODLnBNU",
    "outputId": "8f45269b-04b1-46a2-887b-a618ba53b37b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_step_1000.pt  model_step_200.pt  model_step_600.pt  src.vocab\n",
      "model_step_100.pt   model_step_300.pt  model_step_700.pt  train.log\n",
      "model_step_1100.pt  model_step_400.pt  model_step_800.pt\n",
      "model_step_1200.pt  model_step_500.pt  model_step_900.pt\n"
     ]
    }
   ],
   "source": [
    "# List the contents of the 'model_root' directory\n",
    "!ls '{model_root}'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nqRou9WfsDbh"
   },
   "source": [
    "# Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 86737,
     "status": "ok",
     "timestamp": 1689183608229,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "tStHVtbNmipI",
    "outputId": "5de8c333-15cf-4756-c417-58707ffcce92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-12 17:38:42,631 INFO] Loading checkpoint from /content/nmt/nmtmodel/model_step_1200.pt\n",
      "[2023-07-12 17:38:43,193 INFO] Loading data into the model\n",
      "[2023-07-12 17:40:07,570 INFO] PRED SCORE: -0.0958, PRED PPL: 1.10 NB SENTENCES: 1479\n"
     ]
    }
   ],
   "source": [
    "# Perform translation using the trained NMT model\n",
    "# --model specifies the path to the trained model checkpoint\n",
    "# --src specifies the path to the source text file to be translated\n",
    "# --output specifies the path to save the translated output\n",
    "# -beam_size specifies the beam size for beam search\n",
    "!onmt_translate --model '/content/nmt/nmtmodel/model_step_1200.pt' --src /content/nmt/monument80/test.en --output /content/nmt/monument80/trans_test.sparql -beam_size 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1689183608229,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "UYszCfIbssof",
    "outputId": "155421dc-3ec3-44b1-905d-3b1cbf6cb70c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building date of villa la reine jeanne\n",
      "what do nelson's column and the patchwork girl of oz have in common\n",
      "where can one find rizal monument\n",
      "what's the oldest monument of rzeni\n",
      "how many place are there in kandy\n"
     ]
    }
   ],
   "source": [
    "# Display the first 5 lines of the file 'test.en'\n",
    "!head -n 5 /content/nmt/monument80/test.en\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 450,
     "status": "ok",
     "timestamp": 1689183608676,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "nnTRp6eas_p7",
    "outputId": "b7c3cf5d-8642-4280-9d2e-c325a64b123e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select var_a where brack_open dbr_Villa_La_Reine_Jeanne dbp_complete var_a brack_close\n",
      "select wildcard where brack_open brack_open dbr_Nelson's_Column,_Montreal var_a var_b sep_dot dbr_Economy_of_Uganda var_a var_b brack_close UNION brack_open var_c var_d dbr_Nelson's_Column,_Montreal sep_dot var_c var_d dbr_Economy_of_Uganda brack_close brack_close\n",
      "select var_a where brack_open dbr_Rizal_Monument dbo_location var_a brack_close\n",
      "select var_a where brack_open var_a rdf_type dbo_Monument sep_dot var_a dbo_location dbr_Rzeni sep_dot var_a dbp_complete var_c brack_close order by var_c limit 1\n",
      "select count par_open wildcard par_close where brack_open var_a rdf_type dbo_Place sep_dot var_a dbo_location dbr_Kandy brack_close group by var_a\n"
     ]
    }
   ],
   "source": [
    "# Display the first 5 lines of the file 'trans_test.sparql'\n",
    "!head -n 5 /content/nmt/monument80/trans_test.sparql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1689183608677,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "azi6x-EstHYN",
    "outputId": "06580d1b-0c90-4dd7-d7db-99dc80316699"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select var_a where brack_open dbr_Villa_La_Reine_Jeanne dbp_complete var_a brack_close\n",
      "select wildcard where brack_open brack_open dbr_Nelson's_Column,_Montreal var_a var_b sep_dot dbr_The_Patchwork_Girl_of_Oz var_a var_b brack_close UNION brack_open var_c var_d dbr_Nelson's_Column,_Montreal sep_dot var_c var_d dbr_The_Patchwork_Girl_of_Oz brack_close brack_close\n",
      "select var_a where brack_open dbr_Rizal_Monument_ par_open Calamba par_close  dbo_location var_a brack_close\n",
      "select var_a where brack_open var_a rdf_type dbo_Monument sep_dot var_a dbo_location dbr_Rzeni sep_dot var_a dbp_complete var_c brack_close order by var_c limit 1\n",
      "select count par_open wildcard par_close  where brack_open var_a rdf_type dbo_Place sep_dot var_a dbo_location dbr_Kandy brack_close group by var_a\n"
     ]
    }
   ],
   "source": [
    "# Display the first 5 lines of the file 'test.sparql'\n",
    "!head -n 5 /content/nmt/monument80/test.sparql\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vANuMTJUtfUb"
   },
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 212,
     "status": "ok",
     "timestamp": 1689183616353,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "kj1AtrSDtjfq",
    "outputId": "27a87fce-b28a-4df3-dded-e5a294ced19f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/nmt\n"
     ]
    }
   ],
   "source": [
    "# Print the current working directory\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 622,
     "status": "ok",
     "timestamp": 1689183628109,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "9OhvK6N3ecsm",
    "outputId": "ed15e125-0fb6-4fef-e006-86463b865272"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference 1st sentence: select var_a where brack_open dbr_Villa_La_Reine_Jeanne dbp_complete var_a brack_close\n",
      "MTed 1st sentence: select var_a where brack_open dbr_Villa_La_Reine_Jeanne dbp_complete var_a brack_close\n",
      "Accuracy:  0.9659639043954257\n"
     ]
    }
   ],
   "source": [
    "# Copy the file \"compute-accuracy.py\" from \"/content/drive/MyDrive/\" to the current directory\n",
    "!cp /content/drive/MyDrive/compute-accuracy.py ./\n",
    "\n",
    "# Evaluate the translation using the provided accuracy computation script\n",
    "# - The first argument is the path to the reference (gold standard) sparql file\n",
    "# - The second argument is the path to the translated sparql file\n",
    "!python compute-accuracy.py /content/nmt/monument80/test.sparql /content/nmt/monument80/trans_test.sparql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4469,
     "status": "ok",
     "timestamp": 1689183634292,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "CBxRt66trVw5",
    "outputId": "f9db4bf4-c509-454e-9463-7224cf940f90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference 1st sentence: select var_a where brack_open dbr_Villa_La_Reine_Jeanne dbp_complete var_a brack_close\n",
      "MTed 1st sentence: select var_a where brack_open dbr_Villa_La_Reine_Jeanne dbp_complete var_a brack_close\n",
      "BLEU:  97.62477288577678\n"
     ]
    }
   ],
   "source": [
    "# Install the sacrebleu library using pip\n",
    "!pip install sacrebleu > /dev/null\n",
    "\n",
    "# Copy the file \"compute-bleu.py\" from \"/content/drive/MyDrive/\" to the current directory\n",
    "!cp /content/drive/MyDrive/compute-bleu.py ./\n",
    "\n",
    "# Evaluate the translation using BLEU score calculation script\n",
    "# - The first argument is the path to the reference (gold standard) sparql file\n",
    "# - The second argument is the path to the translated sparql file\n",
    "!python compute-bleu.py /content/nmt/monument80/test.sparql /content/nmt/monument80/trans_test.sparql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4167,
     "status": "ok",
     "timestamp": 1689183675739,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "m8OCPRSAxQ_I",
    "outputId": "270c95ed-5497-4603-d69f-cc5072805d65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference 1st sentence: select var_a where brack_open dbr_Villa_La_Reine_Jeanne dbp_complete var_a brack_close\n",
      "MTed 1st sentence: select var_a where brack_open dbr_Villa_La_Reine_Jeanne dbp_complete var_a brack_close\n",
      "Rouge-L:  0.9882239082254851\n"
     ]
    }
   ],
   "source": [
    "# Install the rouge library using pip\n",
    "!pip install rouge > /dev/null\n",
    "\n",
    "# Copy the file \"compute-rouge-l.py\" from \"/content/drive/MyDrive/\" to the current directory\n",
    "!cp /content/drive/MyDrive/compute-rouge-l.py ./\n",
    "\n",
    "# Evaluate the translation using Rouge-L score calculation script\n",
    "# - The first argument is the path to the reference (gold standard) sparql file\n",
    "# - The second argument is the path to the translated sparql file\n",
    "!python compute-rouge-l.py /content/nmt/monument80/test.sparql /content/nmt/monument80/trans_test.sparql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "executionInfo": {
     "elapsed": 35702,
     "status": "ok",
     "timestamp": 1689183739381,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "A9UinZlnr2Kg"
   },
   "outputs": [],
   "source": [
    "# Copy the directory 'nmt' and its contents from '/content/nmt' to '/content/drive/MyDrive'\n",
    "!cp -r /content/nmt /content/drive/MyDrive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8L_nKJQMr2nO"
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uu7lspbw1Gxw"
   },
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    ''' ''',\n",
    "    ''' '''\n",
    "]\n",
    "with open('questions.en', 'w') as fp:\n",
    "    t = [''.join(x) for x in sentences]\n",
    "    t = '\\n'.join(t)\n",
    "    fp.write(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! onmt_translate --model '/content/nmt/nmtmodel/model_step_1200.pt' --src questions.en --output pred.sparql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat pred.sparql"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPgHsOrTfxicQD2cI4PLYHt",
   "gpuType": "T4",
   "machine_shape": "hm",
   "mount_file_id": "1UtKfPKz88tKwLU7gG8dwRRnh0U4AStBB",
   "provenance": [
    {
     "file_id": "1qwBCXsrX0UD96jZU-P9vIhFRTnCZYO6m",
     "timestamp": 1686823688936
    },
    {
     "file_id": "1sYi4GQuLKBmhhiOJvNHDacHYPI39LsG-",
     "timestamp": 1686759059262
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
