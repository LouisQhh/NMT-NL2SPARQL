{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0w2wNk0167DQ"
   },
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1688987458174,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "6ZH1UZrpjtPE",
    "outputId": "b372bbbb-4af6-4dab-b092-cb6ae49cf911"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/nmt\n"
     ]
    }
   ],
   "source": [
    "# Create a directory named 'nmt'\n",
    "!mkdir nmt\n",
    "\n",
    "# Change the current working directory to the newly created 'nmt' directory\n",
    "%cd nmt\n",
    "\n",
    "# Create a subdirectory named 'nmtmodel' inside the 'nmt' directory\n",
    "!mkdir nmtmodel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 107392,
     "status": "ok",
     "timestamp": 1688987565564,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "df6W9IIWmlQL",
    "outputId": "0c033611-d1a4-4804-a597-9a12d407b608"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchdata 0.6.1 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\n",
      "torchtext 0.15.2 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Install OpenNMT-py along with specific versions of torchvision and torchaudio\n",
    "! pip install OpenNMT-py torchvision==0.14.1 torchaudio==0.13.1 > /dev/null\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 501,
     "status": "ok",
     "timestamp": 1688987566060,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "_3WnsZ-1nUSj",
    "outputId": "379c3ea8-34b6-407d-a5a4-f264e6db7f6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/nmt\n"
     ]
    }
   ],
   "source": [
    "# Print the current working directory\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QypsRuOq7IiR"
   },
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 819,
     "status": "ok",
     "timestamp": 1688987566876,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "Jsc7THqZnYCI",
    "outputId": "9af2e545-81f8-47fa-c533-1a4d8ecc11a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ./monument50.zip\n",
      "   creating: ./monument50/\n",
      "  inflating: ./__MACOSX/._monument50  \n",
      "  inflating: ./monument50/dev.en     \n",
      "  inflating: ./__MACOSX/monument50/._dev.en  \n",
      "  inflating: ./monument50/dev.sparql  \n",
      "  inflating: ./__MACOSX/monument50/._dev.sparql  \n",
      "  inflating: ./monument50/.DS_Store  \n",
      "  inflating: ./__MACOSX/monument50/._.DS_Store  \n",
      "  inflating: ./monument50/train.sparql  \n",
      "  inflating: ./__MACOSX/monument50/._train.sparql  \n",
      "  inflating: ./monument50/train.en   \n",
      "  inflating: ./__MACOSX/monument50/._train.en  \n",
      "  inflating: ./monument50/test.sparql  \n",
      "  inflating: ./__MACOSX/monument50/._test.sparql  \n",
      "  inflating: ./monument50/test.en    \n",
      "  inflating: ./__MACOSX/monument50/._test.en  \n"
     ]
    }
   ],
   "source": [
    "# Copy the file 'monument50.zip' from '/content/drive/MyDrive/' to the current directory\n",
    "!cp /content/drive/MyDrive/monument50.zip ./\n",
    "\n",
    "# Unzip the file 'monument50.zip' and extract its contents to the current directory\n",
    "!unzip ./monument50.zip -d ./\n",
    "\n",
    "# Remove the original zip file 'monument50.zip' from '/content/nmt/'\n",
    "!rm /content/nmt/monument50.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1688987566876,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "dbGofKann5xB",
    "outputId": "46c68084-1e15-4b92-e08c-27c19a4b368c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__MACOSX  monument50  nmtmodel\n"
     ]
    }
   ],
   "source": [
    "# List the contents of the current directory\n",
    "!ls\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZZiY1mojsEkl"
   },
   "source": [
    "# Knowledge Graph Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 339821,
     "status": "ok",
     "timestamp": 1688987906694,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "YTD24q1UsEPM"
   },
   "outputs": [],
   "source": [
    "# Create a new directory named \"graph_embedding_dir\" using the mkdir command\n",
    "!mkdir \"graph_embedding_dir\"\n",
    "\n",
    "# Copy the file \"embedding.vec\" from the source path in Google Drive\n",
    "# to the destination path \"/content/nmt/graph_embedding_dir\" in the local file system\n",
    "!cp /content/drive/MyDrive/embedding.vec /content/nmt/graph_embedding_dir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c-Nfw0l77P8e"
   },
   "source": [
    "# Create the Training Configuration File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1688987906695,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "9uBY92Mf8vE6"
   },
   "outputs": [],
   "source": [
    "# Define the root directory path for the NMT model as \"model_root\"\n",
    "model_root = '/content/nmt/nmtmodel'\n",
    "\n",
    "# Create the directory structure for the NMT model using the mkdir command with the -p option\n",
    "# This ensures that the entire directory path is created, including any necessary parent directories\n",
    "!mkdir -p '{model_root}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1688987906695,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "xAJ686rIvLRn"
   },
   "outputs": [],
   "source": [
    "# Define the configuration as a formatted string\n",
    "config = f'''# config.yaml\n",
    "# GloVe:\n",
    "# this means embeddings will be used for both encoder and decoder sides\n",
    "both_embeddings: /content/nmt/graph_embedding_dir/embedding.vec\n",
    "\n",
    "# supported types: GloVe, word2vec\n",
    "embeddings_type: \"word2vec\"\n",
    "\n",
    "# word_vec_size need to match with the pretrained embeddings dimensions\n",
    "word_vec_size: 300\n",
    "\n",
    "## Where the samples will be written\n",
    "save_data: {model_root}\n",
    "\n",
    "## Where the vocab(s) will be written\n",
    "# Vocabulary files, generated by onmt_build_vocab\n",
    "src_vocab: {model_root}/src.vocab\n",
    "tgt_vocab: {model_root}/src.vocab\n",
    "\n",
    "# Vocabulary size - should be the same as in sentence piece\n",
    "src_vocab_size: 5000\n",
    "tgt_vocab_size: 5000\n",
    "share_vocab: true\n",
    "\n",
    "# Training files\n",
    "data:\n",
    "    train:\n",
    "        path_src: /content/nmt/monument50/train.en\n",
    "        path_tgt: /content/nmt/monument50/train.sparql\n",
    "    valid:\n",
    "        path_src: /content/nmt/monument50/dev.en\n",
    "        path_tgt: /content/nmt/monument50/dev.sparql\n",
    "\n",
    "# Where to save the checkpoints\n",
    "save_model: {model_root}/model\n",
    "log_file: {model_root}/train.log\n",
    "save_checkpoint_steps: 100\n",
    "train_steps: 1200\n",
    "valid_steps: 400\n",
    "\n",
    "# Stop training if it does not imporve after n validations\n",
    "early_stopping: 4\n",
    "\n",
    "# To save space, limit checkpoints to last n\n",
    "# keep_checkpoint: 3\n",
    "\n",
    "seed: 4242\n",
    "\n",
    "# Number of GPUs, and IDs of GPUs\n",
    "world_size: 1\n",
    "gpu_ranks: [0]\n",
    "\n",
    "# Batching\n",
    "# queue_size: 100\n",
    "bucket_size: 262144\n",
    "num_workers: 0  # Default: 2, set to 0 when RAM out of memory\n",
    "batch_type: \"tokens\"\n",
    "batch_size: 4096   # Tokens per batch, change when CUDA out of memory\n",
    "valid_batch_size: 2048\n",
    "# world_size: 1\n",
    "max_generator_batches: 2\n",
    "accum_count: [4]\n",
    "accum_steps: [0]\n",
    "\n",
    "# Optimization\n",
    "# model_dtype: \"fp16\"\n",
    "optim: \"adam\"\n",
    "# learning_rate: 2\n",
    "warmup_steps: 500\n",
    "decay_method: \"noam\"\n",
    "adam_beta1: 0.9\n",
    "adam_beta2: 0.98\n",
    "max_grad_norm: 0\n",
    "label_smoothing: 0.1\n",
    "param_init: 0\n",
    "param_init_glorot: true\n",
    "normalization: \"tokens\"\n",
    "\n",
    "# Model\n",
    "encoder_type: transformer\n",
    "decoder_type: transformer\n",
    "position_encoding: true\n",
    "enc_layers: 6\n",
    "dec_layers: 6\n",
    "heads: 8\n",
    "hidden_size: 512\n",
    "word_vec_size: 512\n",
    "transformer_ff: 2048\n",
    "# dropout_steps: [0]\n",
    "dropout: [0.1]\n",
    "attention_dropout: [0.1]\n",
    "'''\n",
    "\n",
    "# Write the configuration to a \"config.yaml\" file\n",
    "with open(\"config.yaml\", \"w+\") as config_yaml:\n",
    "  config_yaml.write(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z1ZGev3N7ao3"
   },
   "source": [
    "# Build Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5851,
     "status": "ok",
     "timestamp": 1688987912543,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "F4jDz0Dr7sne",
    "outputId": "d0fff7b2-e649-4cd4-9660-87d6288a5f9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus train's weight should be given. We default it to 1 for you.\n",
      "[2023-07-10 11:18:30,222 INFO] Counter vocab from -1 samples.\n",
      "[2023-07-10 11:18:30,222 INFO] n_sample=-1: Build vocab on full datasets.\n",
      "[2023-07-10 11:18:30,386 INFO] Counters src: 2035\n",
      "[2023-07-10 11:18:30,386 INFO] Counters tgt: 1635\n",
      "[2023-07-10 11:18:30,387 INFO] Counters after share:3657\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Check if the source vocabulary file doesn't exist in the 'model_root' directory\n",
    "if not os.path.exists(os.path.join(model_root, 'src.vocab')):\n",
    "    # Build the source vocabulary using the onmt_build_vocab command and the provided config.yaml\n",
    "    # The --n_sample option is used to indicate the number of samples to consider for building the vocabulary\n",
    "    # The \"|| true\" at the end ensures that the command won't stop the script even if there's an error\n",
    "    !onmt_build_vocab -config config.yaml --n_sample -1 || true\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V312rtxK7pd7"
   },
   "source": [
    "# Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2057,
     "status": "ok",
     "timestamp": 1688987914591,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "tJ4dYNPtvQ5Q",
    "outputId": "2288e896-354c-4c5d-8718-85194e06eda7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jul 10 11:18:32 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   36C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n",
      "\n",
      "\n",
      "$*****************************************************************************$\n",
      "GPU:\n",
      "GPU 0: Tesla T4 (UUID: GPU-1e64ed41-f0da-0dc4-e342-3cf95d130083)\n",
      "$*****************************************************************************$\n",
      "\n",
      "\n",
      "$*****************************************************************************$\n",
      "True\n",
      "Tesla T4\n",
      "Free GPU memory: 14998.8125 out of: 15101.8125\n",
      "$*****************************************************************************$\n",
      "No LSB modules are available.\n",
      "Distributor ID:\tUbuntu\n",
      "Description:\tUbuntu 20.04.6 LTS\n",
      "Release:\t20.04\n",
      "Codename:\tfocal\n",
      "$*****************************************************************************$\n",
      "5.15.107+\n",
      "$*****************************************************************************$\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2022 NVIDIA Corporation\n",
      "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
      "Cuda compilation tools, release 11.8, V11.8.89\n",
      "Build cuda_11.8.r11.8/compiler.31833905_0\n",
      "$*****************************************************************************$\n",
      "1.13.1+cu117\n",
      "$*****************************************************************************$\n",
      "model name\t: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
      "model name\t: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
      "model name\t: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
      "model name\t: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
      "$*****************************************************************************$\n",
      "MemTotal:       26687700 kB\n"
     ]
    }
   ],
   "source": [
    "# Check NVIDIA GPU information using the 'nvidia-smi' command\n",
    "!nvidia-smi\n",
    "\n",
    "# Print a separator line and heading for the GPU information\n",
    "print('\\n\\n$*****************************************************************************$')\n",
    "print('GPU:')\n",
    "\n",
    "# Check and display the GPU devices using 'nvidia-smi -L'\n",
    "!nvidia-smi -L\n",
    "\n",
    "# Print a separator line\n",
    "print('$*****************************************************************************$')\n",
    "\n",
    "# Print a separator line and heading for GPU-related checks\n",
    "print('\\n\\n$*****************************************************************************$')\n",
    "\n",
    "# Check if CUDA-enabled GPU is available for PyTorch\n",
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "# Print the name of the first CUDA-enabled GPU\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "# Get GPU memory information\n",
    "gpu_memory = torch.cuda.mem_get_info(0)\n",
    "print(\"Free GPU memory:\", gpu_memory[0]/1024**2, \"out of:\", gpu_memory[1]/1024**2)\n",
    "\n",
    "# Print a separator line\n",
    "print('$*****************************************************************************$')\n",
    "\n",
    "# Print system information using 'lsb_release -a'\n",
    "!lsb_release -a\n",
    "\n",
    "# Print a separator line\n",
    "print('$*****************************************************************************$')\n",
    "\n",
    "# Print kernel version using 'uname -r'\n",
    "!uname -r\n",
    "\n",
    "# Print a separator line\n",
    "print('$*****************************************************************************$')\n",
    "\n",
    "# Print NVCC (NVIDIA CUDA Compiler) version using 'nvcc --version'\n",
    "!nvcc --version\n",
    "\n",
    "# Print a separator line\n",
    "print('$*****************************************************************************$')\n",
    "\n",
    "# Check Torch version using Python import\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "\n",
    "# Print a separator line\n",
    "print('$*****************************************************************************$')\n",
    "\n",
    "# Display CPU information using 'cat /proc/cpuinfo | grep model\\ name'\n",
    "!cat /proc/cpuinfo | grep model\\ name\n",
    "\n",
    "# Print a separator line\n",
    "print('$*****************************************************************************$')\n",
    "\n",
    "# Display total memory information using 'cat /proc/meminfo | grep MemTotal'\n",
    "!cat /proc/meminfo | grep MemTotal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hmaMw_sc7gvP"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1908719,
     "status": "ok",
     "timestamp": 1688989823307,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "5iMmswvHvta_",
    "outputId": "6f055764-825d-4a9b-bd73-1467001a95a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-10 11:18:35,874 INFO] Missing transforms field for train data, set to default: [].\n",
      "[2023-07-10 11:18:35,874 WARNING] Corpus train's weight should be given. We default it to 1 for you.\n",
      "[2023-07-10 11:18:35,874 INFO] Missing transforms field for valid data, set to default: [].\n",
      "[2023-07-10 11:18:35,874 INFO] Parsed 2 corpora from -data.\n",
      "[2023-07-10 11:18:35,874 INFO] Get special vocabs from Transforms: {'src': [], 'tgt': []}.\n",
      "[2023-07-10 11:18:35,888 INFO] Reading encoder and decoder embeddings from /content/nmt/graph_embedding_dir/embedding.vec\n",
      "[2023-07-10 11:21:52,865 INFO] \tFound 8541203 total vectors in file\n",
      "[2023-07-10 11:21:52,869 INFO] After filtering to vectors in vocab:\n",
      "[2023-07-10 11:21:52,871 INFO] \t* enc: 2773 match, 891 missing, (75.68%)\n",
      "[2023-07-10 11:21:52,872 INFO] \t* dec: 2773 match, 891 missing, (75.68%)\n",
      "[2023-07-10 11:21:52,872 INFO] \n",
      "Saving encoder embeddings as:\n",
      "\t* enc: /content/nmt/nmtmodel.enc_embeddings.pt\n",
      "[2023-07-10 11:21:54,818 INFO] \n",
      "Saving decoder embeddings as:\n",
      "\t* dec: /content/nmt/nmtmodel.dec_embeddings.pt\n",
      "[2023-07-10 11:21:56,648 INFO] The first 10 tokens of the vocabs are:['<unk>', '<blank>', '<s>', '</s>', 'var_a', 'where', 'brack_open', 'brack_close', 'select', 'is']\n",
      "[2023-07-10 11:21:56,648 INFO] The decoder start token is: <s>\n",
      "[2023-07-10 11:21:56,648 INFO] Building model...\n",
      "[2023-07-10 11:21:57,255 INFO] Switching model to float32 for amp/apex_amp\n",
      "[2023-07-10 11:21:57,256 INFO] Non quantized layer compute is fp32\n",
      "[2023-07-10 11:22:01,908 INFO] NMTModel(\n",
      "  (encoder): TransformerEncoder(\n",
      "    (embeddings): Embeddings(\n",
      "      (make_embedding): Sequential(\n",
      "        (emb_luts): Elementwise(\n",
      "          (0): Embedding(3664, 512, padding_idx=1)\n",
      "        )\n",
      "        (pe): PositionalEncoding()\n",
      "      )\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): ModuleList(\n",
      "      (0): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (2): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (3): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (4): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (5): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "  )\n",
      "  (decoder): TransformerDecoder(\n",
      "    (embeddings): Embeddings(\n",
      "      (make_embedding): Sequential(\n",
      "        (emb_luts): Elementwise(\n",
      "          (0): Embedding(3664, 512, padding_idx=1)\n",
      "        )\n",
      "        (pe): PositionalEncoding()\n",
      "      )\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "    (transformer_layers): ModuleList(\n",
      "      (0): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (1): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (2): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (3): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (4): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (5): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (generator): Linear(in_features=512, out_features=3664, bias=True)\n",
      ")\n",
      "[2023-07-10 11:22:02,011 INFO] encoder: 20763648\n",
      "[2023-07-10 11:22:02,012 INFO] decoder: 28940880\n",
      "[2023-07-10 11:22:02,012 INFO] * number of parameters: 49704528\n",
      "[2023-07-10 11:22:02,012 INFO] Trainable parameters = {'torch.float32': 49704528, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
      "[2023-07-10 11:22:02,012 INFO] Non trainable parameters = {'torch.float32': 0, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
      "[2023-07-10 11:22:02,013 INFO]  * src vocab size = 3664\n",
      "[2023-07-10 11:22:02,013 INFO]  * tgt vocab size = 3664\n",
      "[2023-07-10 11:22:02,015 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 1\n",
      "[2023-07-10 11:22:02,015 INFO] Starting training on GPU: [0]\n",
      "[2023-07-10 11:22:02,015 INFO] Start training loop and validate every 400 steps...\n",
      "[2023-07-10 11:22:02,015 INFO] Scoring with: TransformPipe()\n",
      "[2023-07-10 11:22:02,116 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 2\n",
      "[2023-07-10 11:22:02,310 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 3\n",
      "[2023-07-10 11:22:02,411 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 4\n",
      "[2023-07-10 11:22:02,652 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 5\n",
      "[2023-07-10 11:22:02,751 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 6\n",
      "[2023-07-10 11:22:03,047 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 7\n",
      "[2023-07-10 11:22:03,144 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 8\n",
      "[2023-07-10 11:22:03,241 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 9\n",
      "[2023-07-10 11:22:03,587 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 10\n",
      "[2023-07-10 11:22:03,691 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 11\n",
      "[2023-07-10 11:22:03,793 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 12\n",
      "[2023-07-10 11:22:04,219 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 13\n",
      "[2023-07-10 11:22:04,330 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 14\n",
      "[2023-07-10 11:22:04,433 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 15\n",
      "[2023-07-10 11:22:04,952 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 16\n",
      "[2023-07-10 11:22:05,047 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 17\n",
      "[2023-07-10 11:22:05,148 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 18\n",
      "[2023-07-10 11:22:05,246 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 19\n",
      "[2023-07-10 11:22:05,339 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 20\n",
      "[2023-07-10 11:22:05,941 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 21\n",
      "[2023-07-10 11:22:06,034 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 22\n",
      "[2023-07-10 11:22:06,132 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 23\n",
      "[2023-07-10 11:22:06,226 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 24\n",
      "[2023-07-10 11:22:06,329 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 25\n",
      "[2023-07-10 11:22:07,051 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 26\n",
      "[2023-07-10 11:22:07,144 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 27\n",
      "[2023-07-10 11:22:07,239 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 28\n",
      "[2023-07-10 11:22:07,334 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 29\n",
      "[2023-07-10 11:22:07,426 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 30\n",
      "[2023-07-10 11:22:07,525 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 31\n",
      "[2023-07-10 11:22:07,624 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 32\n",
      "[2023-07-10 11:22:08,495 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 33\n",
      "[2023-07-10 11:22:08,590 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 34\n",
      "[2023-07-10 11:22:08,683 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 35\n",
      "[2023-07-10 11:22:08,786 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 36\n",
      "[2023-07-10 11:23:21,135 INFO] Step 50/ 1200; acc: 27.9; ppl: 231.9; xent: 5.4; lr: 0.00020; sents:   57891; bsz: 1983/3794/289; 5013/9590 tok/s;     79 sec;\n",
      "[2023-07-10 11:24:24,883 INFO] Step 100/ 1200; acc: 75.7; ppl:  11.3; xent: 2.4; lr: 0.00040; sents:   57624; bsz: 1973/3791/288; 6191/11894 tok/s;    143 sec;\n",
      "[2023-07-10 11:24:24,885 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_100.pt\n",
      "[2023-07-10 11:25:31,504 INFO] Step 150/ 1200; acc: 88.7; ppl:   5.9; xent: 1.8; lr: 0.00060; sents:   57193; bsz: 1987/3788/286; 5965/11371 tok/s;    209 sec;\n",
      "[2023-07-10 11:26:37,978 INFO] Step 200/ 1200; acc: 90.3; ppl:   5.1; xent: 1.6; lr: 0.00079; sents:   57706; bsz: 1957/3793/289; 5888/11411 tok/s;    276 sec;\n",
      "[2023-07-10 11:26:37,981 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_200.pt\n",
      "[2023-07-10 11:26:58,669 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 37\n",
      "[2023-07-10 11:26:58,764 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 38\n",
      "[2023-07-10 11:26:58,860 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 39\n",
      "[2023-07-10 11:26:58,957 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 40\n",
      "[2023-07-10 11:26:59,053 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 41\n",
      "[2023-07-10 11:26:59,150 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 42\n",
      "[2023-07-10 11:26:59,251 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 43\n",
      "[2023-07-10 11:26:59,351 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 44\n",
      "[2023-07-10 11:26:59,449 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 45\n",
      "[2023-07-10 11:26:59,551 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 46\n",
      "[2023-07-10 11:26:59,647 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 47\n",
      "[2023-07-10 11:27:01,894 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 48\n",
      "[2023-07-10 11:27:02,001 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 49\n",
      "[2023-07-10 11:27:02,101 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 50\n",
      "[2023-07-10 11:27:02,201 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 51\n",
      "[2023-07-10 11:27:02,299 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 52\n",
      "[2023-07-10 11:27:02,400 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 53\n",
      "[2023-07-10 11:27:02,500 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 54\n",
      "[2023-07-10 11:27:02,599 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 55\n",
      "[2023-07-10 11:27:02,698 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 56\n",
      "[2023-07-10 11:27:02,795 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 57\n",
      "[2023-07-10 11:27:02,900 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 58\n",
      "[2023-07-10 11:27:02,992 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 59\n",
      "[2023-07-10 11:27:03,099 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 60\n",
      "[2023-07-10 11:27:03,198 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 61\n",
      "[2023-07-10 11:27:05,749 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 62\n",
      "[2023-07-10 11:27:05,838 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 63\n",
      "[2023-07-10 11:27:05,932 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 64\n",
      "[2023-07-10 11:27:06,025 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 65\n",
      "[2023-07-10 11:27:06,120 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 66\n",
      "[2023-07-10 11:27:06,216 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 67\n",
      "[2023-07-10 11:27:06,316 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 68\n",
      "[2023-07-10 11:27:06,413 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 69\n",
      "[2023-07-10 11:27:06,505 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 70\n",
      "[2023-07-10 11:27:06,596 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 71\n",
      "[2023-07-10 11:28:00,700 INFO] Step 250/ 1200; acc: 96.3; ppl:   3.9; xent: 1.4; lr: 0.00099; sents:   58419; bsz: 1978/3792/292; 4783/9167 tok/s;    359 sec;\n",
      "[2023-07-10 11:29:06,712 INFO] Step 300/ 1200; acc: 99.2; ppl:   3.4; xent: 1.2; lr: 0.00119; sents:   54768; bsz: 1913/3807/274; 5797/11536 tok/s;    425 sec;\n",
      "[2023-07-10 11:29:06,714 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_300.pt\n",
      "[2023-07-10 11:30:14,005 INFO] Step 350/ 1200; acc: 99.8; ppl:   3.2; xent: 1.2; lr: 0.00139; sents:   58697; bsz: 1991/3790/293; 5918/11263 tok/s;    492 sec;\n",
      "[2023-07-10 11:31:20,715 INFO] Step 400/ 1200; acc: 95.9; ppl:   4.0; xent: 1.4; lr: 0.00159; sents:   58350; bsz: 1992/3787/292; 5972/11355 tok/s;    559 sec;\n",
      "[2023-07-10 11:31:21,969 INFO] valid stats calculation and sentences rebuilding\n",
      "                           took: 1.253281593322754 s.\n",
      "[2023-07-10 11:31:21,970 INFO] Train perplexity: 7.76856\n",
      "[2023-07-10 11:31:21,971 INFO] Train accuracy: 84.2413\n",
      "[2023-07-10 11:31:21,971 INFO] Sentences processed: 460648\n",
      "[2023-07-10 11:31:21,971 INFO] Average bsz: 1972/3793/288\n",
      "[2023-07-10 11:31:21,971 INFO] Validation perplexity: 4.07406\n",
      "[2023-07-10 11:31:21,971 INFO] Validation accuracy: 96.5716\n",
      "[2023-07-10 11:31:21,971 INFO] Model is improving ppl: inf --> 4.07406.\n",
      "[2023-07-10 11:31:21,971 INFO] Model is improving acc: -inf --> 96.5716.\n",
      "[2023-07-10 11:31:21,973 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_400.pt\n",
      "[2023-07-10 11:32:02,774 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 72\n",
      "[2023-07-10 11:32:02,867 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 73\n",
      "[2023-07-10 11:32:02,961 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 74\n",
      "[2023-07-10 11:32:05,041 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 75\n",
      "[2023-07-10 11:32:05,135 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 76\n",
      "[2023-07-10 11:32:05,230 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 77\n",
      "[2023-07-10 11:32:05,327 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 78\n",
      "[2023-07-10 11:32:05,419 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 79\n",
      "[2023-07-10 11:32:05,515 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 80\n",
      "[2023-07-10 11:32:05,607 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 81\n",
      "[2023-07-10 11:32:05,695 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 82\n",
      "[2023-07-10 11:32:05,783 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 83\n",
      "[2023-07-10 11:32:05,870 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 84\n",
      "[2023-07-10 11:32:05,965 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 85\n",
      "[2023-07-10 11:32:08,327 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 86\n",
      "[2023-07-10 11:32:08,414 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 87\n",
      "[2023-07-10 11:32:08,502 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 88\n",
      "[2023-07-10 11:32:08,591 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 89\n",
      "[2023-07-10 11:32:08,679 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 90\n",
      "[2023-07-10 11:32:08,764 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 91\n",
      "[2023-07-10 11:32:08,869 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 92\n",
      "[2023-07-10 11:32:08,963 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 93\n",
      "[2023-07-10 11:32:09,050 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 94\n",
      "[2023-07-10 11:32:09,135 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 95\n",
      "[2023-07-10 11:32:09,222 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 96\n",
      "[2023-07-10 11:32:09,310 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 97\n",
      "[2023-07-10 11:32:09,395 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 98\n",
      "[2023-07-10 11:32:09,482 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 99\n",
      "[2023-07-10 11:32:09,569 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 100\n",
      "[2023-07-10 11:32:12,317 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 101\n",
      "[2023-07-10 11:32:12,402 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 102\n",
      "[2023-07-10 11:32:12,488 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 103\n",
      "[2023-07-10 11:32:12,583 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 104\n",
      "[2023-07-10 11:32:12,675 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 105\n",
      "[2023-07-10 11:32:12,763 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 106\n",
      "[2023-07-10 11:32:12,852 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 107\n",
      "[2023-07-10 11:32:47,187 INFO] Step 450/ 1200; acc: 99.3; ppl:   3.3; xent: 1.2; lr: 0.00178; sents:   57158; bsz: 1975/3792/286; 4568/8770 tok/s;    645 sec;\n",
      "[2023-07-10 11:33:53,119 INFO] Step 500/ 1200; acc: 99.9; ppl:   3.2; xent: 1.2; lr: 0.00197; sents:   58368; bsz: 1970/3793/292; 5977/11506 tok/s;    711 sec;\n",
      "[2023-07-10 11:33:53,122 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_500.pt\n",
      "[2023-07-10 11:35:00,335 INFO] Step 550/ 1200; acc: 99.8; ppl:   3.2; xent: 1.2; lr: 0.00188; sents:   57909; bsz: 1984/3794/290; 5904/11289 tok/s;    778 sec;\n",
      "[2023-07-10 11:36:06,338 INFO] Step 600/ 1200; acc: 98.9; ppl:   3.3; xent: 1.2; lr: 0.00180; sents:   57514; bsz: 1981/3795/288; 6003/11500 tok/s;    844 sec;\n",
      "[2023-07-10 11:36:06,341 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_600.pt\n",
      "[2023-07-10 11:37:06,822 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 108\n",
      "[2023-07-10 11:37:06,910 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 109\n",
      "[2023-07-10 11:37:07,003 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 110\n",
      "[2023-07-10 11:37:07,096 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 111\n",
      "[2023-07-10 11:37:07,188 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 112\n",
      "[2023-07-10 11:37:07,281 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 113\n",
      "[2023-07-10 11:37:07,373 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 114\n",
      "[2023-07-10 11:37:07,464 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 115\n",
      "[2023-07-10 11:37:09,811 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 116\n",
      "[2023-07-10 11:37:09,903 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 117\n",
      "[2023-07-10 11:37:10,001 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 118\n",
      "[2023-07-10 11:37:10,098 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 119\n",
      "[2023-07-10 11:37:10,195 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 120\n",
      "[2023-07-10 11:37:10,291 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 121\n",
      "[2023-07-10 11:37:10,385 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 122\n",
      "[2023-07-10 11:37:10,482 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 123\n",
      "[2023-07-10 11:37:10,583 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 124\n",
      "[2023-07-10 11:37:10,682 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 125\n",
      "[2023-07-10 11:37:10,780 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 126\n",
      "[2023-07-10 11:37:10,872 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 127\n",
      "[2023-07-10 11:37:10,962 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 128\n",
      "[2023-07-10 11:37:13,697 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 129\n",
      "[2023-07-10 11:37:13,781 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 130\n",
      "[2023-07-10 11:37:13,868 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 131\n",
      "[2023-07-10 11:37:13,956 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 132\n",
      "[2023-07-10 11:37:14,042 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 133\n",
      "[2023-07-10 11:37:14,129 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 134\n",
      "[2023-07-10 11:37:14,223 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 135\n",
      "[2023-07-10 11:37:14,309 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 136\n",
      "[2023-07-10 11:37:14,397 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 137\n",
      "[2023-07-10 11:37:14,484 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 138\n",
      "[2023-07-10 11:37:14,573 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 139\n",
      "[2023-07-10 11:37:14,666 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 140\n",
      "[2023-07-10 11:37:14,752 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 141\n",
      "[2023-07-10 11:37:14,841 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 142\n",
      "[2023-07-10 11:37:32,230 INFO] Step 650/ 1200; acc: 98.6; ppl:   3.4; xent: 1.2; lr: 0.00173; sents:   56631; bsz: 1955/3790/283; 4552/8825 tok/s;    930 sec;\n",
      "[2023-07-10 11:38:38,110 INFO] Step 700/ 1200; acc: 99.8; ppl:   3.2; xent: 1.2; lr: 0.00167; sents:   56032; bsz: 1926/3803/280; 5848/11547 tok/s;    996 sec;\n",
      "[2023-07-10 11:38:38,113 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_700.pt\n",
      "[2023-07-10 11:39:44,963 INFO] Step 750/ 1200; acc: 99.8; ppl:   3.2; xent: 1.2; lr: 0.00161; sents:   56717; bsz: 1954/3798/284; 5846/11362 tok/s;   1063 sec;\n",
      "[2023-07-10 11:40:50,930 INFO] Step 800/ 1200; acc: 99.6; ppl:   3.2; xent: 1.2; lr: 0.00156; sents:   59533; bsz: 2023/3776/298; 6134/11448 tok/s;   1129 sec;\n",
      "[2023-07-10 11:40:52,123 INFO] valid stats calculation and sentences rebuilding\n",
      "                           took: 1.191603422164917 s.\n",
      "[2023-07-10 11:40:52,124 INFO] Train perplexity: 5.04324\n",
      "[2023-07-10 11:40:52,124 INFO] Train accuracy: 91.8465\n",
      "[2023-07-10 11:40:52,124 INFO] Sentences processed: 920510\n",
      "[2023-07-10 11:40:52,124 INFO] Average bsz: 1971/3793/288\n",
      "[2023-07-10 11:40:52,124 INFO] Validation perplexity: 3.73733\n",
      "[2023-07-10 11:40:52,124 INFO] Validation accuracy: 97.1586\n",
      "[2023-07-10 11:40:52,124 INFO] Model is improving ppl: 4.07406 --> 3.73733.\n",
      "[2023-07-10 11:40:52,124 INFO] Model is improving acc: 96.5716 --> 97.1586.\n",
      "[2023-07-10 11:40:52,126 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_800.pt\n",
      "[2023-07-10 11:41:59,559 INFO] Step 850/ 1200; acc: 99.6; ppl:   3.3; xent: 1.2; lr: 0.00151; sents:   58878; bsz: 2013/3787/294; 5867/11036 tok/s;   1198 sec;\n",
      "[2023-07-10 11:42:12,502 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 143\n",
      "[2023-07-10 11:42:12,610 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 144\n",
      "[2023-07-10 11:42:12,708 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 145\n",
      "[2023-07-10 11:42:12,804 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 146\n",
      "[2023-07-10 11:42:12,900 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 147\n",
      "[2023-07-10 11:42:12,997 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 148\n",
      "[2023-07-10 11:42:13,090 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 149\n",
      "[2023-07-10 11:42:13,184 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 150\n",
      "[2023-07-10 11:42:13,278 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 151\n",
      "[2023-07-10 11:42:13,372 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 152\n",
      "[2023-07-10 11:42:13,466 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 153\n",
      "[2023-07-10 11:42:13,560 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 154\n",
      "[2023-07-10 11:42:13,656 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 155\n",
      "[2023-07-10 11:42:13,747 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 156\n",
      "[2023-07-10 11:42:13,841 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 157\n",
      "[2023-07-10 11:42:13,934 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 158\n",
      "[2023-07-10 11:42:14,033 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 159\n",
      "[2023-07-10 11:42:14,127 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 160\n",
      "[2023-07-10 11:42:14,226 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 161\n",
      "[2023-07-10 11:42:16,896 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 162\n",
      "[2023-07-10 11:42:16,988 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 163\n",
      "[2023-07-10 11:42:17,077 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 164\n",
      "[2023-07-10 11:42:17,172 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 165\n",
      "[2023-07-10 11:42:17,266 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 166\n",
      "[2023-07-10 11:42:17,356 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 167\n",
      "[2023-07-10 11:42:17,448 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 168\n",
      "[2023-07-10 11:42:17,541 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 169\n",
      "[2023-07-10 11:42:17,632 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 170\n",
      "[2023-07-10 11:42:17,727 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 171\n",
      "[2023-07-10 11:42:17,821 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 172\n",
      "[2023-07-10 11:42:17,913 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 173\n",
      "[2023-07-10 11:42:18,008 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 174\n",
      "[2023-07-10 11:42:18,100 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 175\n",
      "[2023-07-10 11:42:18,193 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 176\n",
      "[2023-07-10 11:42:21,241 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 177\n",
      "[2023-07-10 11:42:21,336 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 178\n",
      "[2023-07-10 11:43:23,004 INFO] Step 900/ 1200; acc: 99.6; ppl:   3.2; xent: 1.2; lr: 0.00147; sents:   58333; bsz: 1965/3784/292; 4710/9069 tok/s;   1281 sec;\n",
      "[2023-07-10 11:43:23,007 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_900.pt\n",
      "[2023-07-10 11:44:29,261 INFO] Step 950/ 1200; acc: 99.8; ppl:   3.2; xent: 1.2; lr: 0.00143; sents:   57007; bsz: 1959/3794/285; 5912/11452 tok/s;   1347 sec;\n",
      "[2023-07-10 11:45:34,959 INFO] Step 1000/ 1200; acc: 99.7; ppl:   3.2; xent: 1.2; lr: 0.00140; sents:   55715; bsz: 1934/3804/279; 5888/11580 tok/s;   1413 sec;\n",
      "[2023-07-10 11:45:34,961 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_1000.pt\n",
      "[2023-07-10 11:46:41,714 INFO] Step 1050/ 1200; acc: 99.6; ppl:   3.2; xent: 1.2; lr: 0.00136; sents:   57253; bsz: 1973/3795/286; 5913/11371 tok/s;   1480 sec;\n",
      "[2023-07-10 11:47:16,406 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 179\n",
      "[2023-07-10 11:47:16,496 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 180\n",
      "[2023-07-10 11:47:16,595 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 181\n",
      "[2023-07-10 11:47:16,699 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 182\n",
      "[2023-07-10 11:47:16,800 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 183\n",
      "[2023-07-10 11:47:16,900 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 184\n",
      "[2023-07-10 11:47:17,000 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 185\n",
      "[2023-07-10 11:47:17,097 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 186\n",
      "[2023-07-10 11:47:17,194 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 187\n",
      "[2023-07-10 11:47:17,289 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 188\n",
      "[2023-07-10 11:47:17,381 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 189\n",
      "[2023-07-10 11:47:17,472 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 190\n",
      "[2023-07-10 11:47:17,569 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 191\n",
      "[2023-07-10 11:47:17,659 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 192\n",
      "[2023-07-10 11:47:17,752 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 193\n",
      "[2023-07-10 11:47:17,844 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 194\n",
      "[2023-07-10 11:47:20,540 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 195\n",
      "[2023-07-10 11:47:20,637 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 196\n",
      "[2023-07-10 11:47:20,734 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 197\n",
      "[2023-07-10 11:47:20,831 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 198\n",
      "[2023-07-10 11:47:20,930 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 199\n",
      "[2023-07-10 11:47:21,033 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 200\n",
      "[2023-07-10 11:47:21,126 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 201\n",
      "[2023-07-10 11:47:21,229 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 202\n",
      "[2023-07-10 11:47:21,333 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 203\n",
      "[2023-07-10 11:47:21,432 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 204\n",
      "[2023-07-10 11:47:21,527 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 205\n",
      "[2023-07-10 11:47:21,631 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 206\n",
      "[2023-07-10 11:47:21,726 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 207\n",
      "[2023-07-10 11:47:21,825 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 208\n",
      "[2023-07-10 11:47:21,925 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 209\n",
      "[2023-07-10 11:47:24,953 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 210\n",
      "[2023-07-10 11:47:25,043 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 211\n",
      "[2023-07-10 11:47:25,136 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 212\n",
      "[2023-07-10 11:47:25,229 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 213\n",
      "[2023-07-10 11:48:05,522 INFO] Step 1100/ 1200; acc: 99.9; ppl:   3.2; xent: 1.2; lr: 0.00133; sents:   59798; bsz: 2032/3785/299; 4850/9033 tok/s;   1564 sec;\n",
      "[2023-07-10 11:48:05,525 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_1100.pt\n",
      "[2023-07-10 11:49:12,684 INFO] Step 1150/ 1200; acc: 99.8; ppl:   3.2; xent: 1.2; lr: 0.00130; sents:   58505; bsz: 1996/3787/293; 5943/11276 tok/s;   1631 sec;\n",
      "[2023-07-10 11:50:18,049 INFO] Step 1200/ 1200; acc: 99.9; ppl:   3.2; xent: 1.2; lr: 0.00128; sents:   56748; bsz: 1953/3801/284; 5975/11630 tok/s;   1696 sec;\n",
      "[2023-07-10 11:50:19,310 INFO] valid stats calculation and sentences rebuilding\n",
      "                           took: 1.2599842548370361 s.\n",
      "[2023-07-10 11:50:19,311 INFO] Train perplexity: 4.33824\n",
      "[2023-07-10 11:50:19,311 INFO] Train accuracy: 94.479\n",
      "[2023-07-10 11:50:19,311 INFO] Sentences processed: 1.38275e+06\n",
      "[2023-07-10 11:50:19,311 INFO] Average bsz: 1974/3792/288\n",
      "[2023-07-10 11:50:19,311 INFO] Validation perplexity: 3.64144\n",
      "[2023-07-10 11:50:19,311 INFO] Validation accuracy: 97.5582\n",
      "[2023-07-10 11:50:19,311 INFO] Model is improving ppl: 3.73733 --> 3.64144.\n",
      "[2023-07-10 11:50:19,311 INFO] Model is improving acc: 97.1586 --> 97.5582.\n",
      "[2023-07-10 11:50:19,314 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_1200.pt\n"
     ]
    }
   ],
   "source": [
    "# Train the NMT model using the configuration defined in 'config.yaml'\n",
    "!onmt_train -config config.yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1688989823308,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "ro-21ODLnBNU",
    "outputId": "63e0c1a6-8a4a-4a3e-ca11-edbb95a3c053"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_step_1000.pt  model_step_200.pt  model_step_600.pt  src.vocab\n",
      "model_step_100.pt   model_step_300.pt  model_step_700.pt  train.log\n",
      "model_step_1100.pt  model_step_400.pt  model_step_800.pt\n",
      "model_step_1200.pt  model_step_500.pt  model_step_900.pt\n"
     ]
    }
   ],
   "source": [
    "# List the contents of the 'model_root' directory\n",
    "!ls '{model_root}'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nqRou9WfsDbh"
   },
   "source": [
    "# Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 365573,
     "status": "ok",
     "timestamp": 1688990188877,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "tStHVtbNmipI",
    "outputId": "f91fbe3b-1d90-4538-c515-49580be4a9bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-10 11:50:24,416 INFO] Loading checkpoint from /content/nmt/nmtmodel/model_step_1200.pt\n",
      "[2023-07-10 11:50:24,947 INFO] Loading data into the model\n",
      "[2023-07-10 11:56:28,208 INFO] PRED SCORE: -0.0994, PRED PPL: 1.10 NB SENTENCES: 5916\n"
     ]
    }
   ],
   "source": [
    "# Perform translation using the trained NMT model\n",
    "# --model specifies the path to the trained model checkpoint\n",
    "# --src specifies the path to the source text file to be translated\n",
    "# --output specifies the path to save the translated output\n",
    "# -beam_size specifies the beam size for beam search\n",
    "!onmt_translate --model '/content/nmt/nmtmodel/model_step_1200.pt' --src /content/nmt/monument50/test.en --output /content/nmt/monument50/trans_test.sparql -beam_size 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1688990188877,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "UYszCfIbssof",
    "outputId": "bb9373a7-9370-4114-c275-8a1cf6c6cde4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what's the tallest cristo del otero\n",
      "latitude of hagia sophia\n",
      "what do nelson's column and charaxes sidamo have in common\n",
      "what do nelson's column and historic centre of cienfuegos have in common\n",
      "where is bourguiba mausoleum located in\n"
     ]
    }
   ],
   "source": [
    "# Display the first 5 lines of the file 'test.en'\n",
    "!head -n 5 /content/nmt/monument50/test.en\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 471,
     "status": "ok",
     "timestamp": 1688990189338,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "nnTRp6eas_p7",
    "outputId": "35c0a917-006b-4257-98a7-77bb43268d75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select var_a where brack_open var_a rdf_type dbo_Monument sep_dot var_a dbo_location dbr_Cristo_del_Otero sep_dot var_a dbp_complete var_c brack_close order by desc par_open var_c par_close limit 1\n",
      "select var_a where brack_open dbr_Hagia_Sophia geo_lat var_a brack_close\n",
      "select wildcard where brack_open brack_open dbr_Nelson's_Column,_Montreal var_a var_b sep_dot dbr_430 var_a var_b brack_close UNION brack_open var_c var_d dbr_Nelson's_Column,_Montreal sep_dot var_c var_d dbr_Nelson's_Column,_Montreal sep_dot brack_close\n",
      "select wildcard where brack_open brack_open dbr_Nelson's_Column,_Montreal var_a var_b sep_dot dbr_Cienfuegos_Bay var_a var_b brack_close UNION brack_open var_c var_d dbr_Nelson's_Column,_Montreal sep_dot var_c var_d dbr_Cienfuegos_Bay brack_close brack_close\n",
      "select var_a where brack_open dbr_Bourguiba_mausoleum dbo_location var_a brack_close\n"
     ]
    }
   ],
   "source": [
    "# Display the first 5 lines of the file 'trans_test.sparql'\n",
    "!head -n 5 /content/nmt/monument50/trans_test.sparql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1688990189338,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "azi6x-EstHYN",
    "outputId": "1b57eb6b-eeae-4419-8bf3-6187db22e788"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select var_a where brack_open var_a rdf_type dbr_Cristo_del_Otero sep_dot var_a dbp_height var_b brack_close order by desc par_open var_b par_close  limit 1\n",
      "select var_a where brack_open dbr_Hagia_Sophia geo_lat var_a brack_close\n",
      "select wildcard where brack_open brack_open dbr_Nelson's_Column,_Montreal var_a var_b sep_dot dbr_Charaxes_sidamo var_a var_b brack_close UNION brack_open var_c var_d dbr_Nelson's_Column,_Montreal sep_dot var_c var_d dbr_Charaxes_sidamo brack_close brack_close\n",
      "select wildcard where brack_open brack_open dbr_Nelson's_Column,_Montreal var_a var_b sep_dot dbr_Historic_Centre_of_Cienfuegos var_a var_b brack_close UNION brack_open var_c var_d dbr_Nelson's_Column,_Montreal sep_dot var_c var_d dbr_Historic_Centre_of_Cienfuegos brack_close brack_close\n",
      "select var_a where brack_open dbr_Bourguiba_mausoleum dbo_location var_a brack_close\n"
     ]
    }
   ],
   "source": [
    "# Display the first 5 lines of the file 'test.sparql'\n",
    "!head -n 5 /content/nmt/monument50/test.sparql\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vANuMTJUtfUb"
   },
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1688990189338,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "kj1AtrSDtjfq",
    "outputId": "f70e18f5-fc8e-4ce3-c859-ea5567dc85cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/nmt\n"
     ]
    }
   ],
   "source": [
    "# Print the current working directory\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 348,
     "status": "ok",
     "timestamp": 1688990189684,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "9OhvK6N3ecsm",
    "outputId": "7b217335-c42c-4f72-dc4f-13dcfd51b9ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference 1st sentence: select var_a where brack_open var_a rdf_type dbr_Cristo_del_Otero sep_dot var_a dbp_height var_b brack_close order by desc par_open var_b par_close  limit 1\n",
      "MTed 1st sentence: select var_a where brack_open var_a rdf_type dbo_Monument sep_dot var_a dbo_location dbr_Cristo_del_Otero sep_dot var_a dbp_complete var_c brack_close order by desc par_open var_c par_close limit 1\n",
      "Accuracy:  0.933440629946396\n"
     ]
    }
   ],
   "source": [
    "# Copy the file \"compute-accuracy.py\" from \"/content/drive/MyDrive/\" to the current directory\n",
    "!cp /content/drive/MyDrive/compute-accuracy.py ./\n",
    "\n",
    "# Evaluate the translation using the provided accuracy computation script\n",
    "# - The first argument is the path to the reference (gold standard) sparql file\n",
    "# - The second argument is the path to the translated sparql file\n",
    "!python compute-accuracy.py /content/nmt/monument50/test.sparql /content/nmt/monument50/trans_test.sparql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6759,
     "status": "ok",
     "timestamp": 1688990196441,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "CBxRt66trVw5",
    "outputId": "a4c1e3bf-81f5-4124-8b93-814d7387dc67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference 1st sentence: select var_a where brack_open var_a rdf_type dbr_Cristo_del_Otero sep_dot var_a dbp_height var_b brack_close order by desc par_open var_b par_close  limit 1\n",
      "MTed 1st sentence: select var_a where brack_open var_a rdf_type dbo_Monument sep_dot var_a dbo_location dbr_Cristo_del_Otero sep_dot var_a dbp_complete var_c brack_close order by desc par_open var_c par_close limit 1\n",
      "BLEU:  96.32045806386762\n"
     ]
    }
   ],
   "source": [
    "# Install the sacrebleu library using pip\n",
    "!pip install sacrebleu > /dev/null\n",
    "\n",
    "# Copy the file \"compute-bleu.py\" from \"/content/drive/MyDrive/\" to the current directory\n",
    "!cp /content/drive/MyDrive/compute-bleu.py ./\n",
    "\n",
    "# Evaluate the translation using BLEU score calculation script\n",
    "# - The first argument is the path to the reference (gold standard) sparql file\n",
    "# - The second argument is the path to the translated sparql file\n",
    "!python compute-bleu.py /content/nmt/monument50/test.sparql /content/nmt/monument50/trans_test.sparql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5241,
     "status": "ok",
     "timestamp": 1688990201670,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "m8OCPRSAxQ_I",
    "outputId": "ad2f519a-920e-45f8-f278-2abdadfb12e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference 1st sentence: select var_a where brack_open var_a rdf_type dbr_Cristo_del_Otero sep_dot var_a dbp_height var_b brack_close order by desc par_open var_b par_close  limit 1\n",
      "MTed 1st sentence: select var_a where brack_open var_a rdf_type dbo_Monument sep_dot var_a dbo_location dbr_Cristo_del_Otero sep_dot var_a dbp_complete var_c brack_close order by desc par_open var_c par_close limit 1\n",
      "Rouge-L:  0.9854606160904149\n"
     ]
    }
   ],
   "source": [
    "# Install the rouge library using pip\n",
    "!pip install rouge > /dev/null\n",
    "\n",
    "# Copy the file \"compute-rouge-l.py\" from \"/content/drive/MyDrive/\" to the current directory\n",
    "!cp /content/drive/MyDrive/compute-rouge-l.py ./\n",
    "\n",
    "# Evaluate the translation using Rouge-L score calculation script\n",
    "# - The first argument is the path to the reference (gold standard) sparql file\n",
    "# - The second argument is the path to the translated sparql file\n",
    "!python compute-rouge-l.py /content/nmt/monument50/test.sparql /content/nmt/monument50/trans_test.sparql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 34141,
     "status": "ok",
     "timestamp": 1688990236380,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "FCpNQH9DgAl6"
   },
   "outputs": [],
   "source": [
    "# Copy the directory 'nmt' and its contents from '/content/nmt' to '/content/drive/MyDrive'\n",
    "!cp -r /content/nmt /content/drive/MyDrive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8L_nKJQMr2nO"
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uu7lspbw1Gxw"
   },
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    ''' ''',\n",
    "    ''' '''\n",
    "]\n",
    "with open('questions.en', 'w') as fp:\n",
    "    t = [''.join(x) for x in sentences]\n",
    "    t = '\\n'.join(t)\n",
    "    fp.write(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! onmt_translate --model '/content/nmt/nmtmodel/model_step_1200.pt' --src questions.en --output pred.sparql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat pred.sparql"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyP4pDDzk7Q3zX6t5//KFEmM",
   "gpuType": "T4",
   "machine_shape": "hm",
   "mount_file_id": "1lD8Bv0Ahn18JvgRgh7lHk4GSRJbirnfT",
   "provenance": [
    {
     "file_id": "1qwBCXsrX0UD96jZU-P9vIhFRTnCZYO6m",
     "timestamp": 1686823688936
    },
    {
     "file_id": "1sYi4GQuLKBmhhiOJvNHDacHYPI39LsG-",
     "timestamp": 1686759059262
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
