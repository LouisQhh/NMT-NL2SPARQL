{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0w2wNk0167DQ"
   },
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 457,
     "status": "ok",
     "timestamp": 1689009448657,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "6ZH1UZrpjtPE",
    "outputId": "1f3a571c-90f3-43b0-d7b7-2521184ba43a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/nmt\n"
     ]
    }
   ],
   "source": [
    "# Create a new directory named \"nmt\"\n",
    "!mkdir nmt\n",
    "\n",
    "# Change the current working directory to the newly created \"nmt\" directory\n",
    "%cd nmt\n",
    "\n",
    "# Create a subdirectory named \"nmtmodel\" within the \"nmt\" directory\n",
    "!mkdir nmtmodel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 111018,
     "status": "ok",
     "timestamp": 1689009561204,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "df6W9IIWmlQL",
    "outputId": "890011a6-1999-46f1-96f6-25fc5c1a3a5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchdata 0.6.1 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\n",
      "torchtext 0.15.2 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Install the required Python packages\n",
    "# This command uses pip to install OpenNMT-py and specific versions of torchvision and torchaudio\n",
    "# The \"> /dev/null\" part is used to suppress the output and keep the installation process clean\n",
    "!pip install OpenNMT-py torchvision==0.14.1 torchaudio==0.13.1 > /dev/null\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1689009561204,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "_3WnsZ-1nUSj",
    "outputId": "54a626a5-ad31-4572-f47e-a1624cb36fbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/nmt\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QypsRuOq7IiR"
   },
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 940,
     "status": "ok",
     "timestamp": 1689009562142,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "Jsc7THqZnYCI",
    "outputId": "2bae6397-f572-4863-8d83-44227dc7788d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ./monument80.zip\n",
      "   creating: ./monument80/\n",
      "  inflating: ./__MACOSX/._monument80  \n",
      "  inflating: ./monument80/dev.en     \n",
      "  inflating: ./__MACOSX/monument80/._dev.en  \n",
      "  inflating: ./monument80/dev.sparql  \n",
      "  inflating: ./__MACOSX/monument80/._dev.sparql  \n",
      "  inflating: ./monument80/train.sparql  \n",
      "  inflating: ./__MACOSX/monument80/._train.sparql  \n",
      "  inflating: ./monument80/train.en   \n",
      "  inflating: ./__MACOSX/monument80/._train.en  \n",
      "  inflating: ./monument80/test.sparql  \n",
      "  inflating: ./__MACOSX/monument80/._test.sparql  \n",
      "  inflating: ./monument80/test.en    \n",
      "  inflating: ./__MACOSX/monument80/._test.en  \n"
     ]
    }
   ],
   "source": [
    "# Copy the file \"monument80.zip\" from a specific directory on Google Drive to the current directory\n",
    "!cp /content/drive/MyDrive/monument80.zip ./\n",
    "\n",
    "# Unzip the \"monument80.zip\" file and extract its contents to the current directory\n",
    "# The \"-d\" flag specifies the directory where the contents will be extracted\n",
    "!unzip ./monument80.zip -d ./\n",
    "\n",
    "# Remove the original \"monument80.zip\" file from the source directory\n",
    "!rm /content/nmt/monument80.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1689009562143,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "dbGofKann5xB",
    "outputId": "9348de1c-22c1-497f-eb10-e938c2cf9ca3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__MACOSX  monument80  nmtmodel\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZZiY1mojsEkl"
   },
   "source": [
    "# GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 165484,
     "status": "ok",
     "timestamp": 1689009727624,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "YTD24q1UsEPM",
    "outputId": "19b1c49f-dce2-41a1-f5a1-f60b766ec1bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-07-10 17:19:21--  http://nlp.stanford.edu/data/glove.6B.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
      "--2023-07-10 17:19:22--  https://nlp.stanford.edu/data/glove.6B.zip\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
      "--2023-07-10 17:19:22--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 862182613 (822M) [application/zip]\n",
      "Saving to: ‘glove.6B.zip’\n",
      "\n",
      "glove.6B.zip        100%[===================>] 822.24M  4.93MB/s    in 2m 44s  \n",
      "\n",
      "2023-07-10 17:22:07 (5.03 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a new directory named \"glove_dir\"\n",
    "!mkdir \"glove_dir\"\n",
    "\n",
    "# Use wget to download the \"glove.6B.zip\" file from the specified URL\n",
    "# The \"--no-check-certificate\" flag is used to bypass SSL certificate verification\n",
    "# This ensures that wget doesn't refuse to download due to invalid SSL certificates\n",
    "!wget --no-check-certificate http://nlp.stanford.edu/data/glove.6B.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20986,
     "status": "ok",
     "timestamp": 1689009748591,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "uksk5MCmq1kL",
    "outputId": "b4efd622-c88b-4698-ab12-47d60c81ef65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  glove.6B.zip\n",
      "  inflating: glove_dir/glove.6B.50d.txt  \n",
      "  inflating: glove_dir/glove.6B.100d.txt  \n",
      "  inflating: glove_dir/glove.6B.200d.txt  \n",
      "  inflating: glove_dir/glove.6B.300d.txt  \n"
     ]
    }
   ],
   "source": [
    "# Use the unzip command to extract the contents of \"glove.6B.zip\" into the \"glove_dir\" directory\n",
    "# The \"-d\" flag specifies the destination directory for extraction\n",
    "!unzip glove.6B.zip -d \"glove_dir\"\n",
    "\n",
    "# Remove the original \"glove.6B.zip\" file from the \"/content/nmt/\" directory\n",
    "# This is done using the rm (remove) command\n",
    "!rm /content/nmt/glove.6B.zip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c-Nfw0l77P8e"
   },
   "source": [
    "# Create the Training Configuration File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1689009748591,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "9uBY92Mf8vE6"
   },
   "outputs": [],
   "source": [
    "model_root = '/content/nmt/nmtmodel'\n",
    "\n",
    "# Create a directory named 'nmtmodel' using the model_root path\n",
    "!mkdir -p '{model_root}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 513,
     "status": "ok",
     "timestamp": 1689009749102,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "xAJ686rIvLRn"
   },
   "outputs": [],
   "source": [
    "# Define the configuration as a formatted string\n",
    "config = f'''# config.yaml\n",
    "# GloVe:\n",
    "# this means embeddings will be used for both encoder and decoder sides\n",
    "both_embeddings: /content/nmt/glove_dir/glove.6B.300d.txt\n",
    "\n",
    "# supported types: GloVe, word2vec\n",
    "embeddings_type: \"GloVe\"\n",
    "\n",
    "# word_vec_size need to match with the pretrained embeddings dimensions\n",
    "word_vec_size: 300\n",
    "\n",
    "## Where the samples will be written\n",
    "save_data: {model_root}\n",
    "\n",
    "## Where the vocab(s) will be written\n",
    "# Vocabulary files, generated by onmt_build_vocab\n",
    "src_vocab: {model_root}/src.vocab\n",
    "tgt_vocab: {model_root}/src.vocab\n",
    "\n",
    "# Vocabulary size - should be the same as in sentence piece\n",
    "src_vocab_size: 5000\n",
    "tgt_vocab_size: 5000\n",
    "share_vocab: true\n",
    "\n",
    "# Training files\n",
    "data:\n",
    "    train:\n",
    "        path_src: /content/nmt/monument80/train.en\n",
    "        path_tgt: /content/nmt/monument80/train.sparql\n",
    "    valid:\n",
    "        path_src: /content/nmt/monument80/dev.en\n",
    "        path_tgt: /content/nmt/monument80/dev.sparql\n",
    "\n",
    "# Where to save the checkpoints\n",
    "save_model: {model_root}/model\n",
    "log_file: {model_root}/train.log\n",
    "save_checkpoint_steps: 100\n",
    "train_steps: 1200\n",
    "valid_steps: 400\n",
    "\n",
    "# Stop training if it does not imporve after n validations\n",
    "early_stopping: 4\n",
    "\n",
    "# To save space, limit checkpoints to last n\n",
    "# keep_checkpoint: 3\n",
    "\n",
    "seed: 4242\n",
    "\n",
    "# Number of GPUs, and IDs of GPUs\n",
    "world_size: 1\n",
    "gpu_ranks: [0]\n",
    "\n",
    "# Batching\n",
    "# queue_size: 100\n",
    "bucket_size: 262144\n",
    "num_workers: 0  # Default: 2, set to 0 when RAM out of memory\n",
    "batch_type: \"tokens\"\n",
    "batch_size: 4096   # Tokens per batch, change when CUDA out of memory\n",
    "valid_batch_size: 2048\n",
    "# world_size: 1\n",
    "max_generator_batches: 2\n",
    "accum_count: [4]\n",
    "accum_steps: [0]\n",
    "\n",
    "# Optimization\n",
    "# model_dtype: \"fp16\"\n",
    "optim: \"adam\"\n",
    "# learning_rate: 2\n",
    "warmup_steps: 500 ######\n",
    "decay_method: \"noam\"\n",
    "adam_beta1: 0.9\n",
    "adam_beta2: 0.98\n",
    "max_grad_norm: 0\n",
    "label_smoothing: 0.1\n",
    "param_init: 0\n",
    "param_init_glorot: true\n",
    "normalization: \"tokens\"\n",
    "\n",
    "# Model\n",
    "encoder_type: transformer\n",
    "decoder_type: transformer\n",
    "position_encoding: true\n",
    "enc_layers: 6\n",
    "dec_layers: 6\n",
    "heads: 8\n",
    "hidden_size: 512\n",
    "word_vec_size: 512\n",
    "transformer_ff: 2048\n",
    "# dropout_steps: [0]\n",
    "dropout: [0.1]\n",
    "attention_dropout: [0.1]\n",
    "'''\n",
    "\n",
    "# Write the configuration to a \"config.yaml\" file\n",
    "with open(\"config.yaml\", \"w+\") as config_yaml:\n",
    "  config_yaml.write(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z1ZGev3N7ao3"
   },
   "source": [
    "# Build Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2667,
     "status": "ok",
     "timestamp": 1689009751767,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "F4jDz0Dr7sne",
    "outputId": "53448ec7-4580-4899-b660-72d74b9c1a4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus train's weight should be given. We default it to 1 for you.\n",
      "[2023-07-10 17:22:29,927 INFO] Counter vocab from -1 samples.\n",
      "[2023-07-10 17:22:29,927 INFO] n_sample=-1: Build vocab on full datasets.\n",
      "[2023-07-10 17:22:30,169 INFO] Counters src: 2388\n",
      "[2023-07-10 17:22:30,169 INFO] Counters tgt: 1910\n",
      "[2023-07-10 17:22:30,170 INFO] Counters after share:4282\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Check if the source vocabulary file doesn't exist in the 'model_root' directory\n",
    "if not os.path.exists(os.path.join(model_root, 'src.vocab')):\n",
    "    # Build the source vocabulary using the onmt_build_vocab command and the provided config.yaml\n",
    "    # The --n_sample option is used to indicate the number of samples to consider for building the vocabulary\n",
    "    # The \"|| true\" at the end ensures that the command won't stop the script even if there's an error\n",
    "    !onmt_build_vocab -config config.yaml --n_sample -1 || true\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V312rtxK7pd7"
   },
   "source": [
    "# Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1921,
     "status": "ok",
     "timestamp": 1689009753683,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "tJ4dYNPtvQ5Q",
    "outputId": "56397e90-3cc0-45a5-9094-accb9e7f777c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jul 10 17:22:31 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   42C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n",
      "\n",
      "\n",
      "$*****************************************************************************$\n",
      "GPU:\n",
      "GPU 0: Tesla T4 (UUID: GPU-5392c3f9-8bdc-a3ad-dead-9feb479cb1a4)\n",
      "$*****************************************************************************$\n",
      "\n",
      "\n",
      "$*****************************************************************************$\n",
      "True\n",
      "Tesla T4\n",
      "Free GPU memory: 14998.8125 out of: 15101.8125\n",
      "$*****************************************************************************$\n",
      "No LSB modules are available.\n",
      "Distributor ID:\tUbuntu\n",
      "Description:\tUbuntu 20.04.6 LTS\n",
      "Release:\t20.04\n",
      "Codename:\tfocal\n",
      "$*****************************************************************************$\n",
      "5.15.107+\n",
      "$*****************************************************************************$\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2022 NVIDIA Corporation\n",
      "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
      "Cuda compilation tools, release 11.8, V11.8.89\n",
      "Build cuda_11.8.r11.8/compiler.31833905_0\n",
      "$*****************************************************************************$\n",
      "1.13.1+cu117\n",
      "$*****************************************************************************$\n",
      "model name\t: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
      "model name\t: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
      "model name\t: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
      "model name\t: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
      "$*****************************************************************************$\n",
      "MemTotal:       26687700 kB\n"
     ]
    }
   ],
   "source": [
    "# Check NVIDIA GPU information using the 'nvidia-smi' command\n",
    "!nvidia-smi\n",
    "\n",
    "# Print a separator line and heading for the GPU information\n",
    "print('\\n\\n$*****************************************************************************$')\n",
    "print('GPU:')\n",
    "\n",
    "# Check and display the GPU devices using 'nvidia-smi -L'\n",
    "!nvidia-smi -L\n",
    "\n",
    "# Print a separator line\n",
    "print('$*****************************************************************************$')\n",
    "\n",
    "# Print a separator line and heading for GPU-related checks\n",
    "print('\\n\\n$*****************************************************************************$')\n",
    "\n",
    "# Check if CUDA-enabled GPU is available for PyTorch\n",
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "# Print the name of the first CUDA-enabled GPU\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "# Get GPU memory information\n",
    "gpu_memory = torch.cuda.mem_get_info(0)\n",
    "print(\"Free GPU memory:\", gpu_memory[0]/1024**2, \"out of:\", gpu_memory[1]/1024**2)\n",
    "\n",
    "# Print a separator line\n",
    "print('$*****************************************************************************$')\n",
    "\n",
    "# Print system information using 'lsb_release -a'\n",
    "!lsb_release -a\n",
    "\n",
    "# Print a separator line\n",
    "print('$*****************************************************************************$')\n",
    "\n",
    "# Print kernel version using 'uname -r'\n",
    "!uname -r\n",
    "\n",
    "# Print a separator line\n",
    "print('$*****************************************************************************$')\n",
    "\n",
    "# Print NVCC (NVIDIA CUDA Compiler) version using 'nvcc --version'\n",
    "!nvcc --version\n",
    "\n",
    "# Print a separator line\n",
    "print('$*****************************************************************************$')\n",
    "\n",
    "# Check Torch version using Python import\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "\n",
    "# Print a separator line\n",
    "print('$*****************************************************************************$')\n",
    "\n",
    "# Display CPU information using 'cat /proc/cpuinfo | grep model\\ name'\n",
    "!cat /proc/cpuinfo | grep model\\ name\n",
    "\n",
    "# Print a separator line\n",
    "print('$*****************************************************************************$')\n",
    "\n",
    "# Display total memory information using 'cat /proc/meminfo | grep MemTotal'\n",
    "!cat /proc/meminfo | grep MemTotal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hmaMw_sc7gvP"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1781027,
     "status": "ok",
     "timestamp": 1689011534707,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "5iMmswvHvta_",
    "outputId": "40554ce1-217f-4ec0-8a3b-94e614881bdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-10 17:22:34,659 INFO] Missing transforms field for train data, set to default: [].\n",
      "[2023-07-10 17:22:34,659 WARNING] Corpus train's weight should be given. We default it to 1 for you.\n",
      "[2023-07-10 17:22:34,659 INFO] Missing transforms field for valid data, set to default: [].\n",
      "[2023-07-10 17:22:34,659 INFO] Parsed 2 corpora from -data.\n",
      "[2023-07-10 17:22:34,660 INFO] Get special vocabs from Transforms: {'src': [], 'tgt': []}.\n",
      "[2023-07-10 17:22:34,674 INFO] Reading encoder and decoder embeddings from /content/nmt/glove_dir/glove.6B.300d.txt\n",
      "[2023-07-10 17:22:41,102 INFO] \tFound 400000 total vectors in file\n",
      "[2023-07-10 17:22:41,103 INFO] After filtering to vectors in vocab:\n",
      "[2023-07-10 17:22:41,104 INFO] \t* enc: 2179 match, 2109 missing, (50.82%)\n",
      "[2023-07-10 17:22:41,105 INFO] \t* dec: 2179 match, 2109 missing, (50.82%)\n",
      "[2023-07-10 17:22:41,105 INFO] \n",
      "Saving encoder embeddings as:\n",
      "\t* enc: /content/nmt/nmtmodel.enc_embeddings.pt\n",
      "[2023-07-10 17:22:42,772 INFO] \n",
      "Saving decoder embeddings as:\n",
      "\t* dec: /content/nmt/nmtmodel.dec_embeddings.pt\n",
      "[2023-07-10 17:22:44,554 INFO] The first 10 tokens of the vocabs are:['<unk>', '<blank>', '<s>', '</s>', 'var_a', 'where', 'brack_open', 'brack_close', 'select', 'is']\n",
      "[2023-07-10 17:22:44,554 INFO] The decoder start token is: <s>\n",
      "[2023-07-10 17:22:44,555 INFO] Building model...\n",
      "[2023-07-10 17:22:45,132 INFO] Switching model to float32 for amp/apex_amp\n",
      "[2023-07-10 17:22:45,132 INFO] Non quantized layer compute is fp32\n",
      "[2023-07-10 17:22:46,346 INFO] NMTModel(\n",
      "  (encoder): TransformerEncoder(\n",
      "    (embeddings): Embeddings(\n",
      "      (make_embedding): Sequential(\n",
      "        (emb_luts): Elementwise(\n",
      "          (0): Embedding(4288, 512, padding_idx=1)\n",
      "        )\n",
      "        (pe): PositionalEncoding()\n",
      "      )\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): ModuleList(\n",
      "      (0): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (2): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (3): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (4): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (5): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "  )\n",
      "  (decoder): TransformerDecoder(\n",
      "    (embeddings): Embeddings(\n",
      "      (make_embedding): Sequential(\n",
      "        (emb_luts): Elementwise(\n",
      "          (0): Embedding(4288, 512, padding_idx=1)\n",
      "        )\n",
      "        (pe): PositionalEncoding()\n",
      "      )\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "    (transformer_layers): ModuleList(\n",
      "      (0): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (1): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (2): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (3): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (4): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (5): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (generator): Linear(in_features=512, out_features=4288, bias=True)\n",
      ")\n",
      "[2023-07-10 17:22:46,436 INFO] encoder: 21083136\n",
      "[2023-07-10 17:22:46,436 INFO] decoder: 29580480\n",
      "[2023-07-10 17:22:46,436 INFO] * number of parameters: 50663616\n",
      "[2023-07-10 17:22:46,437 INFO] Trainable parameters = {'torch.float32': 50663616, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
      "[2023-07-10 17:22:46,437 INFO] Non trainable parameters = {'torch.float32': 0, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
      "[2023-07-10 17:22:46,437 INFO]  * src vocab size = 4288\n",
      "[2023-07-10 17:22:46,437 INFO]  * tgt vocab size = 4288\n",
      "[2023-07-10 17:22:46,441 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 1\n",
      "[2023-07-10 17:22:46,441 INFO] Starting training on GPU: [0]\n",
      "[2023-07-10 17:22:46,441 INFO] Start training loop and validate every 400 steps...\n",
      "[2023-07-10 17:22:46,441 INFO] Scoring with: TransformPipe()\n",
      "[2023-07-10 17:22:46,629 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 2\n",
      "[2023-07-10 17:22:46,874 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 3\n",
      "[2023-07-10 17:22:47,211 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 4\n",
      "[2023-07-10 17:22:47,670 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 5\n",
      "[2023-07-10 17:22:47,925 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 6\n",
      "[2023-07-10 17:22:48,344 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 7\n",
      "[2023-07-10 17:22:48,808 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 8\n",
      "[2023-07-10 17:22:48,977 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 9\n",
      "[2023-07-10 17:22:49,149 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 10\n",
      "[2023-07-10 17:22:49,681 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 11\n",
      "[2023-07-10 17:22:49,833 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 12\n",
      "[2023-07-10 17:22:50,453 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 13\n",
      "[2023-07-10 17:22:50,603 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 14\n",
      "[2023-07-10 17:22:50,752 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 15\n",
      "[2023-07-10 17:22:50,905 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 16\n",
      "[2023-07-10 17:22:51,660 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 17\n",
      "[2023-07-10 17:22:51,816 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 18\n",
      "[2023-07-10 17:22:51,970 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 19\n",
      "[2023-07-10 17:22:52,149 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 20\n",
      "[2023-07-10 17:22:53,049 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 21\n",
      "[2023-07-10 17:22:53,207 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 22\n",
      "[2023-07-10 17:22:53,356 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 23\n",
      "[2023-07-10 17:24:06,463 INFO] Step 50/ 1200; acc: 30.8; ppl: 253.8; xent: 5.5; lr: 0.00020; sents:   56941; bsz: 1935/3799/285; 4837/9495 tok/s;     80 sec;\n",
      "[2023-07-10 17:25:16,074 INFO] Step 100/ 1200; acc: 79.1; ppl:   9.8; xent: 2.3; lr: 0.00040; sents:   57122; bsz: 1953/3794/286; 5611/10899 tok/s;    150 sec;\n",
      "[2023-07-10 17:25:16,077 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_100.pt\n",
      "[2023-07-10 17:26:26,468 INFO] Step 150/ 1200; acc: 91.3; ppl:   5.3; xent: 1.7; lr: 0.00060; sents:   54396; bsz: 1911/3810/272; 5430/10826 tok/s;    220 sec;\n",
      "[2023-07-10 17:27:36,167 INFO] Step 200/ 1200; acc: 96.9; ppl:   3.9; xent: 1.4; lr: 0.00079; sents:   54250; bsz: 1888/3804/271; 5418/10917 tok/s;    290 sec;\n",
      "[2023-07-10 17:27:36,169 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_200.pt\n",
      "[2023-07-10 17:28:09,592 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 24\n",
      "[2023-07-10 17:28:09,744 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 25\n",
      "[2023-07-10 17:28:09,900 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 26\n",
      "[2023-07-10 17:28:10,056 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 27\n",
      "[2023-07-10 17:28:10,210 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 28\n",
      "[2023-07-10 17:28:10,362 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 29\n",
      "[2023-07-10 17:28:10,519 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 30\n",
      "[2023-07-10 17:28:12,632 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 31\n",
      "[2023-07-10 17:28:12,787 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 32\n",
      "[2023-07-10 17:28:12,966 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 33\n",
      "[2023-07-10 17:28:13,141 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 34\n",
      "[2023-07-10 17:28:13,302 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 35\n",
      "[2023-07-10 17:28:13,464 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 36\n",
      "[2023-07-10 17:28:13,620 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 37\n",
      "[2023-07-10 17:28:13,788 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 38\n",
      "[2023-07-10 17:28:16,240 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 39\n",
      "[2023-07-10 17:28:16,400 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 40\n",
      "[2023-07-10 17:28:16,571 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 41\n",
      "[2023-07-10 17:28:16,719 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 42\n",
      "[2023-07-10 17:28:16,871 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 43\n",
      "[2023-07-10 17:28:17,026 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 44\n",
      "[2023-07-10 17:28:17,186 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 45\n",
      "[2023-07-10 17:29:03,322 INFO] Step 250/ 1200; acc: 97.7; ppl:   3.6; xent: 1.3; lr: 0.00099; sents:   60722; bsz: 2038/3782/304; 4678/8680 tok/s;    377 sec;\n",
      "[2023-07-10 17:30:11,927 INFO] Step 300/ 1200; acc: 98.4; ppl:   3.5; xent: 1.3; lr: 0.00119; sents:   53801; bsz: 1882/3802/269; 5485/11084 tok/s;    445 sec;\n",
      "[2023-07-10 17:30:11,930 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_300.pt\n",
      "[2023-07-10 17:31:22,350 INFO] Step 350/ 1200; acc: 99.3; ppl:   3.3; xent: 1.2; lr: 0.00139; sents:   55317; bsz: 1916/3806/277; 5442/10808 tok/s;    516 sec;\n",
      "[2023-07-10 17:32:31,348 INFO] Step 400/ 1200; acc: 99.4; ppl:   3.3; xent: 1.2; lr: 0.00159; sents:   56307; bsz: 1941/3801/282; 5628/11018 tok/s;    585 sec;\n",
      "[2023-07-10 17:32:32,595 INFO] valid stats calculation and sentences rebuilding\n",
      "                           took: 1.2460763454437256 s.\n",
      "[2023-07-10 17:32:32,596 INFO] Train perplexity: 7.21546\n",
      "[2023-07-10 17:32:32,596 INFO] Train accuracy: 86.6024\n",
      "[2023-07-10 17:32:32,596 INFO] Sentences processed: 448856\n",
      "[2023-07-10 17:32:32,596 INFO] Average bsz: 1933/3800/281\n",
      "[2023-07-10 17:32:32,596 INFO] Validation perplexity: 3.7976\n",
      "[2023-07-10 17:32:32,596 INFO] Validation accuracy: 97.2309\n",
      "[2023-07-10 17:32:32,596 INFO] Model is improving ppl: inf --> 3.7976.\n",
      "[2023-07-10 17:32:32,596 INFO] Model is improving acc: -inf --> 97.2309.\n",
      "[2023-07-10 17:32:32,598 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_400.pt\n",
      "[2023-07-10 17:33:37,658 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 46\n",
      "[2023-07-10 17:33:39,581 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 47\n",
      "[2023-07-10 17:33:39,730 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 48\n",
      "[2023-07-10 17:33:39,883 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 49\n",
      "[2023-07-10 17:33:40,033 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 50\n",
      "[2023-07-10 17:33:40,184 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 51\n",
      "[2023-07-10 17:33:40,328 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 52\n",
      "[2023-07-10 17:33:40,468 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 53\n",
      "[2023-07-10 17:33:40,613 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 54\n",
      "[2023-07-10 17:33:42,908 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 55\n",
      "[2023-07-10 17:33:43,061 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 56\n",
      "[2023-07-10 17:33:43,219 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 57\n",
      "[2023-07-10 17:33:43,364 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 58\n",
      "[2023-07-10 17:33:43,518 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 59\n",
      "[2023-07-10 17:33:43,674 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 60\n",
      "[2023-07-10 17:33:43,834 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 61\n",
      "[2023-07-10 17:33:43,986 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 62\n",
      "[2023-07-10 17:33:44,166 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 63\n",
      "[2023-07-10 17:33:46,790 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 64\n",
      "[2023-07-10 17:33:46,929 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 65\n",
      "[2023-07-10 17:33:47,077 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 66\n",
      "[2023-07-10 17:33:47,221 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 67\n",
      "[2023-07-10 17:34:00,144 INFO] Step 450/ 1200; acc: 98.6; ppl:   3.5; xent: 1.2; lr: 0.00178; sents:   57149; bsz: 1958/3800/286; 4411/8559 tok/s;    674 sec;\n",
      "[2023-07-10 17:35:09,177 INFO] Step 500/ 1200; acc: 99.4; ppl:   3.3; xent: 1.2; lr: 0.00197; sents:   56271; bsz: 1920/3804/281; 5561/11021 tok/s;    743 sec;\n",
      "[2023-07-10 17:35:09,179 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_500.pt\n",
      "[2023-07-10 17:36:19,386 INFO] Step 550/ 1200; acc: 99.6; ppl:   3.3; xent: 1.2; lr: 0.00188; sents:   56890; bsz: 1953/3799/284; 5562/10822 tok/s;    813 sec;\n",
      "[2023-07-10 17:37:28,257 INFO] Step 600/ 1200; acc: 99.4; ppl:   3.3; xent: 1.2; lr: 0.00180; sents:   57514; bsz: 1967/3791/288; 5711/11009 tok/s;    882 sec;\n",
      "[2023-07-10 17:37:28,259 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_600.pt\n",
      "[2023-07-10 17:38:37,969 INFO] Step 650/ 1200; acc: 99.6; ppl:   3.3; xent: 1.2; lr: 0.00173; sents:   54810; bsz: 1916/3804/274; 5498/10914 tok/s;    952 sec;\n",
      "[2023-07-10 17:39:04,187 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 68\n",
      "[2023-07-10 17:39:04,330 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 69\n",
      "[2023-07-10 17:39:04,483 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 70\n",
      "[2023-07-10 17:39:04,630 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 71\n",
      "[2023-07-10 17:39:04,779 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 72\n",
      "[2023-07-10 17:39:06,903 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 73\n",
      "[2023-07-10 17:39:07,051 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 74\n",
      "[2023-07-10 17:39:07,198 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 75\n",
      "[2023-07-10 17:39:07,344 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 76\n",
      "[2023-07-10 17:39:07,494 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 77\n",
      "[2023-07-10 17:39:07,661 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 78\n",
      "[2023-07-10 17:39:07,820 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 79\n",
      "[2023-07-10 17:39:07,972 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 80\n",
      "[2023-07-10 17:39:10,439 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 81\n",
      "[2023-07-10 17:39:10,590 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 82\n",
      "[2023-07-10 17:39:10,732 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 83\n",
      "[2023-07-10 17:39:10,883 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 84\n",
      "[2023-07-10 17:39:11,039 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 85\n",
      "[2023-07-10 17:39:11,189 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 86\n",
      "[2023-07-10 17:39:11,327 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 87\n",
      "[2023-07-10 17:39:11,478 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 88\n",
      "[2023-07-10 17:39:11,625 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 89\n",
      "[2023-07-10 17:40:05,590 INFO] Step 700/ 1200; acc: 99.6; ppl:   3.3; xent: 1.2; lr: 0.00167; sents:   55406; bsz: 1933/3801/277; 4412/8677 tok/s;   1039 sec;\n",
      "[2023-07-10 17:40:05,592 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_700.pt\n",
      "[2023-07-10 17:41:13,680 INFO] Step 750/ 1200; acc: 99.6; ppl:   3.3; xent: 1.2; lr: 0.00161; sents:   54379; bsz: 1879/3802/272; 5521/11168 tok/s;   1107 sec;\n",
      "[2023-07-10 17:42:22,417 INFO] Step 800/ 1200; acc: 99.7; ppl:   3.3; xent: 1.2; lr: 0.00156; sents:   57703; bsz: 1971/3795/289; 5736/11043 tok/s;   1176 sec;\n",
      "[2023-07-10 17:42:23,663 INFO] valid stats calculation and sentences rebuilding\n",
      "                           took: 1.2444195747375488 s.\n",
      "[2023-07-10 17:42:23,664 INFO] Train perplexity: 4.8863\n",
      "[2023-07-10 17:42:23,664 INFO] Train accuracy: 93.0194\n",
      "[2023-07-10 17:42:23,665 INFO] Sentences processed: 898978\n",
      "[2023-07-10 17:42:23,665 INFO] Average bsz: 1935/3800/281\n",
      "[2023-07-10 17:42:23,665 INFO] Validation perplexity: 3.58483\n",
      "[2023-07-10 17:42:23,665 INFO] Validation accuracy: 98.0299\n",
      "[2023-07-10 17:42:23,665 INFO] Model is improving ppl: 3.7976 --> 3.58483.\n",
      "[2023-07-10 17:42:23,665 INFO] Model is improving acc: 97.2309 --> 98.0299.\n",
      "[2023-07-10 17:42:23,667 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_800.pt\n",
      "[2023-07-10 17:43:33,730 INFO] Step 850/ 1200; acc: 99.6; ppl:   3.3; xent: 1.2; lr: 0.00151; sents:   59050; bsz: 1997/3789/295; 5602/10625 tok/s;   1247 sec;\n",
      "[2023-07-10 17:44:33,004 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 90\n",
      "[2023-07-10 17:44:33,152 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 91\n",
      "[2023-07-10 17:44:33,302 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 92\n",
      "[2023-07-10 17:44:33,448 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 93\n",
      "[2023-07-10 17:44:33,599 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 94\n",
      "[2023-07-10 17:44:33,765 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 95\n",
      "[2023-07-10 17:44:33,915 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 96\n",
      "[2023-07-10 17:44:34,061 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 97\n",
      "[2023-07-10 17:44:34,213 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 98\n",
      "[2023-07-10 17:44:34,360 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 99\n",
      "[2023-07-10 17:44:34,511 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 100\n",
      "[2023-07-10 17:44:34,656 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 101\n",
      "[2023-07-10 17:44:37,160 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 102\n",
      "[2023-07-10 17:44:37,305 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 103\n",
      "[2023-07-10 17:44:37,449 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 104\n",
      "[2023-07-10 17:44:37,601 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 105\n",
      "[2023-07-10 17:44:37,750 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 106\n",
      "[2023-07-10 17:44:37,906 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 107\n",
      "[2023-07-10 17:44:38,053 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 108\n",
      "[2023-07-10 17:44:38,200 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 109\n",
      "[2023-07-10 17:44:38,345 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 110\n",
      "[2023-07-10 17:44:41,138 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 111\n",
      "[2023-07-10 17:44:58,353 INFO] Step 900/ 1200; acc: 99.4; ppl:   3.3; xent: 1.2; lr: 0.00147; sents:   54718; bsz: 1895/3810/274; 4479/9006 tok/s;   1332 sec;\n",
      "[2023-07-10 17:44:58,356 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_900.pt\n",
      "[2023-07-10 17:46:08,773 INFO] Step 950/ 1200; acc: 99.6; ppl:   3.3; xent: 1.2; lr: 0.00143; sents:   57849; bsz: 1961/3793/289; 5570/10774 tok/s;   1402 sec;\n",
      "[2023-07-10 17:47:16,671 INFO] Step 1000/ 1200; acc: 99.7; ppl:   3.3; xent: 1.2; lr: 0.00140; sents:   54021; bsz: 1887/3814/270; 5560/11234 tok/s;   1470 sec;\n",
      "[2023-07-10 17:47:16,674 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_1000.pt\n",
      "[2023-07-10 17:48:26,638 INFO] Step 1050/ 1200; acc: 99.5; ppl:   3.3; xent: 1.2; lr: 0.00136; sents:   56873; bsz: 1958/3795/284; 5596/10847 tok/s;   1540 sec;\n",
      "[2023-07-10 17:49:35,739 INFO] Step 1100/ 1200; acc: 99.8; ppl:   3.2; xent: 1.2; lr: 0.00133; sents:   56492; bsz: 1944/3801/282; 5626/11002 tok/s;   1609 sec;\n",
      "[2023-07-10 17:49:35,741 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_1100.pt\n",
      "[2023-07-10 17:49:58,716 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 112\n",
      "[2023-07-10 17:49:58,882 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 113\n",
      "[2023-07-10 17:49:59,043 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 114\n",
      "[2023-07-10 17:49:59,200 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 115\n",
      "[2023-07-10 17:49:59,363 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 116\n",
      "[2023-07-10 17:49:59,529 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 117\n",
      "[2023-07-10 17:49:59,699 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 118\n",
      "[2023-07-10 17:49:59,875 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 119\n",
      "[2023-07-10 17:50:00,038 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 120\n",
      "[2023-07-10 17:50:00,195 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 121\n",
      "[2023-07-10 17:50:02,658 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 122\n",
      "[2023-07-10 17:50:02,810 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 123\n",
      "[2023-07-10 17:50:02,966 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 124\n",
      "[2023-07-10 17:50:03,118 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 125\n",
      "[2023-07-10 17:50:03,265 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 126\n",
      "[2023-07-10 17:50:03,411 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 127\n",
      "[2023-07-10 17:50:03,557 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 128\n",
      "[2023-07-10 17:50:03,704 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 129\n",
      "[2023-07-10 17:50:03,851 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 130\n",
      "[2023-07-10 17:50:04,000 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 131\n",
      "[2023-07-10 17:50:06,751 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 132\n",
      "[2023-07-10 17:50:06,899 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 133\n",
      "[2023-07-10 17:51:02,946 INFO] Step 1150/ 1200; acc: 99.8; ppl:   3.2; xent: 1.2; lr: 0.00130; sents:   57461; bsz: 1970/3788/287; 4518/8687 tok/s;   1697 sec;\n",
      "[2023-07-10 17:52:10,606 INFO] Step 1200/ 1200; acc: 99.8; ppl:   3.2; xent: 1.2; lr: 0.00128; sents:   54991; bsz: 1898/3793/275; 5612/11212 tok/s;   1764 sec;\n",
      "[2023-07-10 17:52:11,888 INFO] valid stats calculation and sentences rebuilding\n",
      "                           took: 1.2807507514953613 s.\n",
      "[2023-07-10 17:52:11,889 INFO] Train perplexity: 4.26846\n",
      "[2023-07-10 17:52:11,889 INFO] Train accuracy: 95.2271\n",
      "[2023-07-10 17:52:11,889 INFO] Sentences processed: 1.35043e+06\n",
      "[2023-07-10 17:52:11,889 INFO] Average bsz: 1936/3799/281\n",
      "[2023-07-10 17:52:11,889 INFO] Validation perplexity: 3.56081\n",
      "[2023-07-10 17:52:11,889 INFO] Validation accuracy: 98.3127\n",
      "[2023-07-10 17:52:11,889 INFO] Model is improving ppl: 3.58483 --> 3.56081.\n",
      "[2023-07-10 17:52:11,889 INFO] Model is improving acc: 98.0299 --> 98.3127.\n",
      "[2023-07-10 17:52:11,891 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_1200.pt\n"
     ]
    }
   ],
   "source": [
    "# Train the NMT model using the configuration defined in 'config.yaml'\n",
    "!onmt_train -config config.yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1689011534707,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "ro-21ODLnBNU",
    "outputId": "98d4ab08-83f0-41d3-84ef-63933e1a87cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_step_1000.pt  model_step_200.pt  model_step_600.pt  src.vocab\n",
      "model_step_100.pt   model_step_300.pt  model_step_700.pt  train.log\n",
      "model_step_1100.pt  model_step_400.pt  model_step_800.pt\n",
      "model_step_1200.pt  model_step_500.pt  model_step_900.pt\n"
     ]
    }
   ],
   "source": [
    "# List the contents of the 'model_root' directory\n",
    "!ls '{model_root}'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nqRou9WfsDbh"
   },
   "source": [
    "# Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 91863,
     "status": "ok",
     "timestamp": 1689011626569,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "tStHVtbNmipI",
    "outputId": "29d3aca0-1a1a-4e03-c37f-66327f17f356"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-10 17:52:15,445 INFO] Loading checkpoint from /content/nmt/nmtmodel/model_step_1200.pt\n",
      "[2023-07-10 17:52:15,999 INFO] Loading data into the model\n",
      "[2023-07-10 17:53:45,616 INFO] PRED SCORE: -0.0998, PRED PPL: 1.10 NB SENTENCES: 1479\n"
     ]
    }
   ],
   "source": [
    "# Perform translation using the trained NMT model\n",
    "# --model specifies the path to the trained model checkpoint\n",
    "# --src specifies the path to the source text file to be translated\n",
    "# --output specifies the path to save the translated output\n",
    "# -beam_size specifies the beam size for beam search\n",
    "!onmt_translate --model '/content/nmt/nmtmodel/model_step_1200.pt' --src /content/nmt/monument80/test.en --output /content/nmt/monument80/trans_test.sparql -beam_size 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1689011626570,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "UYszCfIbssof",
    "outputId": "d02cc06e-8c3a-435a-c017-6cfdbb5edea9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building date of villa la reine jeanne\n",
      "what do nelson's column and the patchwork girl of oz have in common\n",
      "where can one find rizal monument\n",
      "what's the oldest monument of răzeni\n",
      "how many place are there in kandy\n"
     ]
    }
   ],
   "source": [
    "# Display the first 5 lines of the file 'test.en'\n",
    "!head -n 5 /content/nmt/monument80/test.en\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1689011626570,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "nnTRp6eas_p7",
    "outputId": "d1f4fee9-a3f4-4f64-c1d8-e3ca4bd8ed85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select var_a where brack_open dbr_Villa_La_Reine_Jeanne dbp_complete var_a brack_close\n",
      "select wildcard where brack_open brack_open dbr_Nelson's_Column,_Montreal var_a var_b sep_dot dbr_Vladimir_Atlasov var_a var_b brack_close UNION brack_open var_c var_d dbr_Nelson's_Column,_Montreal sep_dot var_c var_d dbr_Vladimir_Atlasov brack_close brack_close\n",
      "select var_a where brack_open dbr_Rizal_Monument_ par_open Calamba par_close dbo_location var_a brack_close\n",
      "select var_a where brack_open var_a rdf_type dbo_Monument sep_dot var_a dbo_location dbr_Răzeni sep_dot var_a dbp_complete var_c brack_close order by var_c limit 1\n",
      "select count par_open wildcard par_close where brack_open var_a rdf_type dbo_Place sep_dot var_a dbo_location dbr_Kandy brack_close group by var_a\n"
     ]
    }
   ],
   "source": [
    "# Display the first 5 lines of the file 'test.en'\n",
    "!head -n 5 /content/nmt/monument80/trans_test.sparql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1689011626570,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "azi6x-EstHYN",
    "outputId": "231b5187-7cec-4cb5-ba4c-7397c14e35ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select var_a where brack_open dbr_Villa_La_Reine_Jeanne dbp_complete var_a brack_close\n",
      "select wildcard where brack_open brack_open dbr_Nelson's_Column,_Montreal var_a var_b sep_dot dbr_The_Patchwork_Girl_of_Oz var_a var_b brack_close UNION brack_open var_c var_d dbr_Nelson's_Column,_Montreal sep_dot var_c var_d dbr_The_Patchwork_Girl_of_Oz brack_close brack_close\n",
      "select var_a where brack_open dbr_Rizal_Monument_ par_open Calamba par_close  dbo_location var_a brack_close\n",
      "select var_a where brack_open var_a rdf_type dbo_Monument sep_dot var_a dbo_location dbr_Răzeni sep_dot var_a dbp_complete var_c brack_close order by var_c limit 1\n",
      "select count par_open wildcard par_close  where brack_open var_a rdf_type dbo_Place sep_dot var_a dbo_location dbr_Kandy brack_close group by var_a\n"
     ]
    }
   ],
   "source": [
    "# Display the first 5 lines of the file 'test.sparql'\n",
    "!head -n 5 /content/nmt/monument80/test.sparql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vANuMTJUtfUb"
   },
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1689011626570,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "kj1AtrSDtjfq",
    "outputId": "b571d709-e073-4aa4-a61f-d0e64216223d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/nmt\n"
     ]
    }
   ],
   "source": [
    "# Print the current working directory\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 710,
     "status": "ok",
     "timestamp": 1689011636279,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "9OhvK6N3ecsm",
    "outputId": "2371dea5-f0e0-4cb5-c58d-80185708b775"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference 1st sentence: select var_a where brack_open dbr_Villa_La_Reine_Jeanne dbp_complete var_a brack_close\n",
      "MTed 1st sentence: select var_a where brack_open dbr_Villa_La_Reine_Jeanne dbp_complete var_a brack_close\n",
      "Accuracy:  0.9626578505230069\n"
     ]
    }
   ],
   "source": [
    "# Copy the file \"compute-accuracy.py\" from \"/content/drive/MyDrive/\" to the current directory\n",
    "!cp /content/drive/MyDrive/compute-accuracy.py ./\n",
    "\n",
    "# Evaluate the translation using the provided accuracy computation script\n",
    "# - The first argument is the path to the reference (gold standard) sparql file\n",
    "# - The second argument is the path to the translated sparql file\n",
    "!python compute-accuracy.py /content/nmt/monument80/test.sparql /content/nmt/monument80/trans_test.sparql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5767,
     "status": "ok",
     "timestamp": 1689011643992,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "CBxRt66trVw5",
    "outputId": "3f5928ad-3b84-4686-f2d6-f94e29e53421"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference 1st sentence: select var_a where brack_open dbr_Villa_La_Reine_Jeanne dbp_complete var_a brack_close\n",
      "MTed 1st sentence: select var_a where brack_open dbr_Villa_La_Reine_Jeanne dbp_complete var_a brack_close\n",
      "BLEU:  97.76084846468864\n"
     ]
    }
   ],
   "source": [
    "# Install the sacrebleu library using pip\n",
    "!pip install sacrebleu > /dev/null\n",
    "\n",
    "# Copy the file \"compute-bleu.py\" from \"/content/drive/MyDrive/\" to the current directory\n",
    "!cp /content/drive/MyDrive/compute-bleu.py ./\n",
    "\n",
    "# Evaluate the translation using BLEU score calculation script\n",
    "# - The first argument is the path to the reference (gold standard) sparql file\n",
    "# - The second argument is the path to the translated sparql file\n",
    "!python compute-bleu.py /content/nmt/monument80/test.sparql /content/nmt/monument80/trans_test.sparql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4953,
     "status": "ok",
     "timestamp": 1689011650433,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "m8OCPRSAxQ_I",
    "outputId": "aa2d85ba-26d0-4ad7-9b0a-ba028be33c9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference 1st sentence: select var_a where brack_open dbr_Villa_La_Reine_Jeanne dbp_complete var_a brack_close\n",
      "MTed 1st sentence: select var_a where brack_open dbr_Villa_La_Reine_Jeanne dbp_complete var_a brack_close\n",
      "Rouge-L:  0.9872806081210852\n"
     ]
    }
   ],
   "source": [
    "# Install the rouge library using pip\n",
    "!pip install rouge > /dev/null\n",
    "\n",
    "# Copy the file \"compute-rouge-l.py\" from \"/content/drive/MyDrive/\" to the current directory\n",
    "!cp /content/drive/MyDrive/compute-rouge-l.py ./\n",
    "\n",
    "# Evaluate the translation using Rouge-L score calculation script\n",
    "# - The first argument is the path to the reference (gold standard) sparql file\n",
    "# - The second argument is the path to the translated sparql file\n",
    "!python compute-rouge-l.py /content/nmt/monument80/test.sparql /content/nmt/monument80/trans_test.sparql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 32058,
     "status": "ok",
     "timestamp": 1689011732777,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "ex1iEnMU8QCH"
   },
   "outputs": [],
   "source": [
    "# Copy the directory 'nmt' and its contents from '/content/nmt' to '/content/drive/MyDrive'\n",
    "!cp -r /content/nmt/nmtmodel /content/drive/MyDrive/NMT_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8L_nKJQMr2nO"
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uu7lspbw1Gxw"
   },
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    ''' ''',\n",
    "    ''' '''\n",
    "]\n",
    "with open('questions.en', 'w') as fp:\n",
    "    t = [''.join(x) for x in sentences]\n",
    "    t = '\\n'.join(t)\n",
    "    fp.write(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! onmt_translate --model '/content/nmt/nmtmodel/model_step_1200.pt' --src questions.en --output pred.sparql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat pred.sparql"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOFjHDBL3o1wtQKwuWcyUUC",
   "gpuType": "T4",
   "machine_shape": "hm",
   "mount_file_id": "1y_qgJNJAn26lX1Bi3gJsvdUOe-WSnS6o",
   "provenance": [
    {
     "file_id": "1qwBCXsrX0UD96jZU-P9vIhFRTnCZYO6m",
     "timestamp": 1686823688936
    },
    {
     "file_id": "1sYi4GQuLKBmhhiOJvNHDacHYPI39LsG-",
     "timestamp": 1686759059262
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
