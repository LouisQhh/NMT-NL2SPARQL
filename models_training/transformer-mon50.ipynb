{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0w2wNk0167DQ"
   },
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1688918703935,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "6ZH1UZrpjtPE",
    "outputId": "2e5a3df6-3fe5-441f-dd62-27e67df99850"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/nmt\n"
     ]
    }
   ],
   "source": [
    "# Create a directory named 'nmt'\n",
    "!mkdir nmt\n",
    "\n",
    "# Change the current working directory to the newly created 'nmt' directory\n",
    "%cd nmt\n",
    "\n",
    "# Inside the 'nmt' directory, create another directory named 'nmtmodel'\n",
    "!mkdir nmtmodel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 131325,
     "status": "ok",
     "timestamp": 1688918859837,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "df6W9IIWmlQL",
    "outputId": "6cdcff75-3bce-42e5-954f-d6bcc29441db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchdata 0.6.1 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\n",
      "torchtext 0.15.2 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Install specific versions of OpenNMT-py, torchvision, and torchaudio using pip\n",
    "# The output of the installation process is redirected to /dev/null to suppress output\n",
    "!pip install OpenNMT-py torchvision==0.14.1 torchaudio==0.13.1 > /dev/null\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1688918859838,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "_3WnsZ-1nUSj",
    "outputId": "bf44f65c-b70e-426f-f2cc-384a18180657"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/nmt\n"
     ]
    }
   ],
   "source": [
    "# Print the current working directory (current path)\n",
    "!pwd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QypsRuOq7IiR"
   },
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 770,
     "status": "ok",
     "timestamp": 1688918860602,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "Jsc7THqZnYCI",
    "outputId": "e9c01bd1-8f4d-4c0a-91ec-33d61fa05b24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ./monument50.zip\n",
      "   creating: ./monument50/\n",
      "  inflating: ./__MACOSX/._monument50  \n",
      "  inflating: ./monument50/dev.en     \n",
      "  inflating: ./__MACOSX/monument50/._dev.en  \n",
      "  inflating: ./monument50/dev.sparql  \n",
      "  inflating: ./__MACOSX/monument50/._dev.sparql  \n",
      "  inflating: ./monument50/.DS_Store  \n",
      "  inflating: ./__MACOSX/monument50/._.DS_Store  \n",
      "  inflating: ./monument50/train.sparql  \n",
      "  inflating: ./__MACOSX/monument50/._train.sparql  \n",
      "  inflating: ./monument50/train.en   \n",
      "  inflating: ./__MACOSX/monument50/._train.en  \n",
      "  inflating: ./monument50/test.sparql  \n",
      "  inflating: ./__MACOSX/monument50/._test.sparql  \n",
      "  inflating: ./monument50/test.en    \n",
      "  inflating: ./__MACOSX/monument50/._test.en  \n"
     ]
    }
   ],
   "source": [
    "# Copy the 'monument50.zip' file from Google Drive to the current directory\n",
    "!cp /content/drive/MyDrive/monument50.zip ./\n",
    "\n",
    "# Unzip the contents of the 'monument50.zip' file into the current directory\n",
    "# The '-d' flag specifies the destination directory for the extracted files\n",
    "!unzip ./monument50.zip -d ./\n",
    "\n",
    "# Remove the original 'monument50.zip' file from the 'nmt' directory\n",
    "!rm /content/nmt/monument50.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dbGofKann5xB"
   },
   "outputs": [],
   "source": [
    "# List the contents of the current directory using the 'ls' command\n",
    "!ls\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c-Nfw0l77P8e"
   },
   "source": [
    "# Create the Training Configuration File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 176,
     "status": "ok",
     "timestamp": 1688918864937,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "9uBY92Mf8vE6"
   },
   "outputs": [],
   "source": [
    "# Define the path for the model root directory\n",
    "model_root = '/content/nmt/nmtmodel'\n",
    "\n",
    "# Create the model root directory if it doesn't exist\n",
    "# The '-p' flag ensures that intermediate directories are also created if needed\n",
    "!mkdir -p '{model_root}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 272,
     "status": "ok",
     "timestamp": 1688918868323,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "xAJ686rIvLRn"
   },
   "outputs": [],
   "source": [
    "# Define the content of the configuration file as a formatted string\n",
    "config = f'''# config.yaml\n",
    "## Where the samples will be written\n",
    "save_data: {model_root}\n",
    "\n",
    "## Where the vocab(s) will be written\n",
    "# Vocabulary files, generated by onmt_build_vocab\n",
    "src_vocab: {model_root}/src.vocab\n",
    "tgt_vocab: {model_root}/src.vocab\n",
    "\n",
    "# Vocabulary size - should be the same as in sentence piece\n",
    "src_vocab_size: 5000\n",
    "tgt_vocab_size: 5000\n",
    "share_vocab: true\n",
    "\n",
    "# Training files\n",
    "data:\n",
    "    train:\n",
    "        path_src: /content/nmt/monument50/train.en\n",
    "        path_tgt: /content/nmt/monument50/train.sparql\n",
    "    valid:\n",
    "        path_src: /content/nmt/monument50/dev.en\n",
    "        path_tgt: /content/nmt/monument50/dev.sparql\n",
    "\n",
    "# Where to save the checkpoints\n",
    "save_model: {model_root}/model\n",
    "log_file: {model_root}/train.log\n",
    "save_checkpoint_steps: 100\n",
    "train_steps: 1200\n",
    "valid_steps: 400\n",
    "\n",
    "# Stop training if it does not imporve after n validations\n",
    "early_stopping: 4\n",
    "\n",
    "# To save space, limit checkpoints to last n\n",
    "# keep_checkpoint: 3\n",
    "\n",
    "seed: 4242\n",
    "\n",
    "# Number of GPUs, and IDs of GPUs\n",
    "world_size: 1\n",
    "gpu_ranks: [0]\n",
    "\n",
    "# Batching\n",
    "# queue_size: 100\n",
    "bucket_size: 262144\n",
    "num_workers: 0  # Default: 2, set to 0 when RAM out of memory\n",
    "batch_type: \"tokens\"\n",
    "batch_size: 4096   # Tokens per batch, change when CUDA out of memory\n",
    "valid_batch_size: 2048\n",
    "# world_size: 1\n",
    "max_generator_batches: 2\n",
    "accum_count: [4]\n",
    "accum_steps: [0]\n",
    "\n",
    "# Optimization\n",
    "# model_dtype: \"fp16\"\n",
    "optim: \"adam\"\n",
    "# learning_rate: 2\n",
    "warmup_steps: 500\n",
    "decay_method: \"noam\"\n",
    "adam_beta1: 0.9\n",
    "adam_beta2: 0.98\n",
    "max_grad_norm: 0\n",
    "label_smoothing: 0.1\n",
    "param_init: 0\n",
    "param_init_glorot: true\n",
    "normalization: \"tokens\"\n",
    "\n",
    "# Model\n",
    "encoder_type: transformer\n",
    "decoder_type: transformer\n",
    "position_encoding: true\n",
    "enc_layers: 6\n",
    "dec_layers: 6\n",
    "heads: 8\n",
    "hidden_size: 512\n",
    "word_vec_size: 512\n",
    "transformer_ff: 2048\n",
    "# dropout_steps: [0]\n",
    "dropout: [0.1]\n",
    "attention_dropout: [0.1]\n",
    "'''\n",
    "\n",
    "# Write the configuration string to a file named \"config.yaml\"\n",
    "with open(\"config.yaml\", \"w+\") as config_yaml:\n",
    "  config_yaml.write(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z1ZGev3N7ao3"
   },
   "source": [
    "# Build Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3114,
     "status": "ok",
     "timestamp": 1688918874937,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "F4jDz0Dr7sne",
    "outputId": "d3dc90aa-0485-439f-83f3-8a42cd73f596"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus train's weight should be given. We default it to 1 for you.\n",
      "[2023-07-09 16:07:53,437 INFO] Counter vocab from -1 samples.\n",
      "[2023-07-09 16:07:53,437 INFO] n_sample=-1: Build vocab on full datasets.\n",
      "[2023-07-09 16:07:53,725 INFO] Counters src: 2035\n",
      "[2023-07-09 16:07:53,725 INFO] Counters tgt: 1635\n",
      "[2023-07-09 16:07:53,726 INFO] Counters after share:3657\n"
     ]
    }
   ],
   "source": [
    "# Import the 'os' module to interact with the operating system\n",
    "import os\n",
    "\n",
    "# Check if the source vocabulary file does not exist in the model root directory\n",
    "if not os.path.exists(os.path.join(model_root, 'src.vocab')):\n",
    "    # Use the 'onmt_build_vocab' command to generate vocabulary files\n",
    "    # The '-config' flag specifies the configuration file\n",
    "    # The '--n_sample -1' flag ensures that all training data samples are used\n",
    "    # The '|| true' part ensures that the command continues running even if it encounters an error\n",
    "    ! onmt_build_vocab -config config.yaml --n_sample -1 || true\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V312rtxK7pd7"
   },
   "source": [
    "# Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2233,
     "status": "ok",
     "timestamp": 1688918877166,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "tJ4dYNPtvQ5Q",
    "outputId": "ae37d09c-cc6e-4f56-e267-8a22f127cfa0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jul  9 16:07:54 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   46C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n",
      "\n",
      "\n",
      "$*****************************************************************************$\n",
      "GPU:\n",
      "GPU 0: Tesla T4 (UUID: GPU-ee61fa42-ec9f-9396-3eb9-c89ff7f9de2b)\n",
      "$*****************************************************************************$\n",
      "\n",
      "\n",
      "$*****************************************************************************$\n",
      "True\n",
      "Tesla T4\n",
      "Free GPU memory: 14998.8125 out of: 15101.8125\n",
      "$*****************************************************************************$\n"
     ]
    }
   ],
   "source": [
    "# Display GPU information using the 'nvidia-smi' command\n",
    "!nvidia-smi\n",
    "\n",
    "# Print a separator for better readability\n",
    "print('\\n\\n$*****************************************************************************$')\n",
    "\n",
    "# Display information about the available GPUs using the 'nvidia-smi -L' command\n",
    "print('GPU:')\n",
    "!nvidia-smi -L\n",
    "\n",
    "# Print a separator for better readability\n",
    "print('$*****************************************************************************$')\n",
    "\n",
    "# Check if the GPU is available for PyTorch by importing the 'torch' module\n",
    "import torch\n",
    "\n",
    "# Print whether CUDA (GPU support) is available\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "# Print the name of the GPU device (if available)\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "# Get GPU memory information\n",
    "gpu_memory = torch.cuda.mem_get_info(0)\n",
    "print(\"Free GPU memory:\", gpu_memory[0]/1024**2, \"out of:\", gpu_memory[1]/1024**2)\n",
    "\n",
    "# Print a separator for better readability\n",
    "print('$*****************************************************************************$')\n",
    "\n",
    "# Display information about the Linux distribution using 'lsb_release -a'\n",
    "!lsb_release -a\n",
    "\n",
    "# Print a separator for better readability\n",
    "print('$*****************************************************************************$')\n",
    "\n",
    "# Display the Linux kernel version using 'uname -r'\n",
    "!uname -r\n",
    "\n",
    "# Print a separator for better readability\n",
    "print('$*****************************************************************************$')\n",
    "\n",
    "# Display the version information for the CUDA toolkit using 'nvcc --version'\n",
    "!nvcc --version\n",
    "\n",
    "# Print a separator for better readability\n",
    "print('$*****************************************************************************$')\n",
    "\n",
    "# Display the version information for PyTorch using 'torch.__version__'\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "\n",
    "# Print a separator for better readability\n",
    "print('$*****************************************************************************$')\n",
    "\n",
    "# Display CPU information using 'cat /proc/cpuinfo | grep model\\ name'\n",
    "!cat /proc/cpuinfo | grep model\\ name\n",
    "\n",
    "# Print a separator for better readability\n",
    "print('$*****************************************************************************$')\n",
    "\n",
    "# Display total system memory information using 'cat /proc/meminfo | grep MemTotal'\n",
    "!cat /proc/meminfo | grep MemTotal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hmaMw_sc7gvP"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1721015,
     "status": "ok",
     "timestamp": 1688920598179,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "5iMmswvHvta_",
    "outputId": "3596d456-7f95-4d15-fd8d-5d6ec7f28dc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-09 16:07:58,501 INFO] Missing transforms field for train data, set to default: [].\n",
      "[2023-07-09 16:07:58,502 WARNING] Corpus train's weight should be given. We default it to 1 for you.\n",
      "[2023-07-09 16:07:58,502 INFO] Missing transforms field for valid data, set to default: [].\n",
      "[2023-07-09 16:07:58,502 INFO] Parsed 2 corpora from -data.\n",
      "[2023-07-09 16:07:58,502 INFO] Get special vocabs from Transforms: {'src': [], 'tgt': []}.\n",
      "[2023-07-09 16:07:58,519 INFO] The first 10 tokens of the vocabs are:['<unk>', '<blank>', '<s>', '</s>', 'var_a', 'where', 'brack_open', 'brack_close', 'select', 'is']\n",
      "[2023-07-09 16:07:58,519 INFO] The decoder start token is: <s>\n",
      "[2023-07-09 16:07:58,519 INFO] Building model...\n",
      "[2023-07-09 16:07:58,996 INFO] Switching model to float32 for amp/apex_amp\n",
      "[2023-07-09 16:07:58,996 INFO] Non quantized layer compute is fp32\n",
      "[2023-07-09 16:07:59,990 INFO] NMTModel(\n",
      "  (encoder): TransformerEncoder(\n",
      "    (embeddings): Embeddings(\n",
      "      (make_embedding): Sequential(\n",
      "        (emb_luts): Elementwise(\n",
      "          (0): Embedding(3664, 512, padding_idx=1)\n",
      "        )\n",
      "        (pe): PositionalEncoding()\n",
      "      )\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): ModuleList(\n",
      "      (0): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (2): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (3): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (4): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (5): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "  )\n",
      "  (decoder): TransformerDecoder(\n",
      "    (embeddings): Embeddings(\n",
      "      (make_embedding): Sequential(\n",
      "        (emb_luts): Elementwise(\n",
      "          (0): Embedding(3664, 512, padding_idx=1)\n",
      "        )\n",
      "        (pe): PositionalEncoding()\n",
      "      )\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "    (transformer_layers): ModuleList(\n",
      "      (0): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (1): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (2): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (3): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (4): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (5): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (generator): Linear(in_features=512, out_features=3664, bias=True)\n",
      ")\n",
      "[2023-07-09 16:08:00,002 INFO] encoder: 20763648\n",
      "[2023-07-09 16:08:00,002 INFO] decoder: 28940880\n",
      "[2023-07-09 16:08:00,002 INFO] * number of parameters: 49704528\n",
      "[2023-07-09 16:08:00,003 INFO] Trainable parameters = {'torch.float32': 49704528, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
      "[2023-07-09 16:08:00,003 INFO] Non trainable parameters = {'torch.float32': 0, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
      "[2023-07-09 16:08:00,003 INFO]  * src vocab size = 3664\n",
      "[2023-07-09 16:08:00,003 INFO]  * tgt vocab size = 3664\n",
      "[2023-07-09 16:08:00,006 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 1\n",
      "[2023-07-09 16:08:00,007 INFO] Starting training on GPU: [0]\n",
      "[2023-07-09 16:08:00,007 INFO] Start training loop and validate every 400 steps...\n",
      "[2023-07-09 16:08:00,007 INFO] Scoring with: TransformPipe()\n",
      "[2023-07-09 16:08:00,104 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 2\n",
      "[2023-07-09 16:08:00,262 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 3\n",
      "[2023-07-09 16:08:00,351 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 4\n",
      "[2023-07-09 16:08:00,580 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 5\n",
      "[2023-07-09 16:08:00,669 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 6\n",
      "[2023-07-09 16:08:00,918 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 7\n",
      "[2023-07-09 16:08:01,012 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 8\n",
      "[2023-07-09 16:08:01,101 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 9\n",
      "[2023-07-09 16:08:01,404 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 10\n",
      "[2023-07-09 16:08:01,506 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 11\n",
      "[2023-07-09 16:08:01,600 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 12\n",
      "[2023-07-09 16:08:01,974 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 13\n",
      "[2023-07-09 16:08:02,069 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 14\n",
      "[2023-07-09 16:08:02,173 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 15\n",
      "[2023-07-09 16:08:02,633 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 16\n",
      "[2023-07-09 16:08:02,722 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 17\n",
      "[2023-07-09 16:08:02,813 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 18\n",
      "[2023-07-09 16:08:02,904 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 19\n",
      "[2023-07-09 16:08:03,006 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 20\n",
      "[2023-07-09 16:08:03,570 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 21\n",
      "[2023-07-09 16:08:03,659 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 22\n",
      "[2023-07-09 16:08:03,752 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 23\n",
      "[2023-07-09 16:08:03,846 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 24\n",
      "[2023-07-09 16:08:03,936 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 25\n",
      "[2023-07-09 16:08:04,029 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 26\n",
      "[2023-07-09 16:08:04,709 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 27\n",
      "[2023-07-09 16:08:04,803 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 28\n",
      "[2023-07-09 16:08:04,891 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 29\n",
      "[2023-07-09 16:08:04,985 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 30\n",
      "[2023-07-09 16:08:05,078 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 31\n",
      "[2023-07-09 16:08:05,172 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 32\n",
      "[2023-07-09 16:08:05,266 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 33\n",
      "[2023-07-09 16:08:06,180 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 34\n",
      "[2023-07-09 16:08:06,327 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 35\n",
      "[2023-07-09 16:08:06,470 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 36\n",
      "[2023-07-09 16:09:19,916 INFO] Step 50/ 1200; acc: 30.8; ppl: 200.3; xent: 5.3; lr: 0.00020; sents:   57891; bsz: 1983/3794/289; 4963/9495 tok/s;     80 sec;\n",
      "[2023-07-09 16:10:26,043 INFO] Step 100/ 1200; acc: 78.4; ppl:   9.8; xent: 2.3; lr: 0.00040; sents:   57624; bsz: 1973/3791/288; 5968/11466 tok/s;    146 sec;\n",
      "[2023-07-09 16:10:26,045 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_100.pt\n",
      "[2023-07-09 16:11:33,641 INFO] Step 150/ 1200; acc: 88.6; ppl:   5.8; xent: 1.8; lr: 0.00060; sents:   57193; bsz: 1987/3788/286; 5879/11207 tok/s;    214 sec;\n",
      "[2023-07-09 16:12:39,516 INFO] Step 200/ 1200; acc: 87.7; ppl:   5.8; xent: 1.8; lr: 0.00079; sents:   57706; bsz: 1957/3793/289; 5941/11515 tok/s;    280 sec;\n",
      "[2023-07-09 16:12:39,518 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_200.pt\n",
      "[2023-07-09 16:13:00,883 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 37\n",
      "[2023-07-09 16:13:01,045 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 38\n",
      "[2023-07-09 16:13:01,207 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 39\n",
      "[2023-07-09 16:13:01,370 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 40\n",
      "[2023-07-09 16:13:01,530 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 41\n",
      "[2023-07-09 16:13:01,689 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 42\n",
      "[2023-07-09 16:13:01,854 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 43\n",
      "[2023-07-09 16:13:02,014 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 44\n",
      "[2023-07-09 16:13:02,181 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 45\n",
      "[2023-07-09 16:13:02,340 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 46\n",
      "[2023-07-09 16:13:02,509 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 47\n",
      "[2023-07-09 16:13:02,673 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 48\n",
      "[2023-07-09 16:13:05,078 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 49\n",
      "[2023-07-09 16:13:05,168 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 50\n",
      "[2023-07-09 16:13:05,260 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 51\n",
      "[2023-07-09 16:13:05,354 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 52\n",
      "[2023-07-09 16:13:05,447 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 53\n",
      "[2023-07-09 16:13:05,538 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 54\n",
      "[2023-07-09 16:13:05,643 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 55\n",
      "[2023-07-09 16:13:05,741 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 56\n",
      "[2023-07-09 16:13:05,830 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 57\n",
      "[2023-07-09 16:13:05,934 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 58\n",
      "[2023-07-09 16:13:06,028 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 59\n",
      "[2023-07-09 16:13:06,127 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 60\n",
      "[2023-07-09 16:13:06,225 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 61\n",
      "[2023-07-09 16:13:06,319 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 62\n",
      "[2023-07-09 16:13:06,419 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 63\n",
      "[2023-07-09 16:13:08,746 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 64\n",
      "[2023-07-09 16:13:08,851 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 65\n",
      "[2023-07-09 16:13:08,955 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 66\n",
      "[2023-07-09 16:13:09,057 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 67\n",
      "[2023-07-09 16:13:09,148 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 68\n",
      "[2023-07-09 16:13:09,247 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 69\n",
      "[2023-07-09 16:13:09,339 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 70\n",
      "[2023-07-09 16:13:09,435 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 71\n",
      "[2023-07-09 16:14:04,832 INFO] Step 250/ 1200; acc: 93.2; ppl:   4.5; xent: 1.5; lr: 0.00099; sents:   58419; bsz: 1978/3792/292; 4637/8889 tok/s;    365 sec;\n",
      "[2023-07-09 16:15:10,069 INFO] Step 300/ 1200; acc: 97.9; ppl:   3.6; xent: 1.3; lr: 0.00119; sents:   54768; bsz: 1913/3807/274; 5866/11673 tok/s;    430 sec;\n",
      "[2023-07-09 16:15:10,071 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_300.pt\n",
      "[2023-07-09 16:16:18,072 INFO] Step 350/ 1200; acc: 99.7; ppl:   3.3; xent: 1.2; lr: 0.00139; sents:   58697; bsz: 1991/3790/293; 5856/11145 tok/s;    498 sec;\n",
      "[2023-07-09 16:17:23,992 INFO] Step 400/ 1200; acc: 97.6; ppl:   3.7; xent: 1.3; lr: 0.00159; sents:   58350; bsz: 1992/3787/292; 6043/11491 tok/s;    564 sec;\n",
      "[2023-07-09 16:17:25,167 INFO] valid stats calculation and sentences rebuilding\n",
      "                           took: 1.1740047931671143 s.\n",
      "[2023-07-09 16:17:25,168 INFO] Train perplexity: 7.72746\n",
      "[2023-07-09 16:17:25,168 INFO] Train accuracy: 84.2399\n",
      "[2023-07-09 16:17:25,168 INFO] Sentences processed: 460648\n",
      "[2023-07-09 16:17:25,168 INFO] Average bsz: 1972/3793/288\n",
      "[2023-07-09 16:17:25,168 INFO] Validation perplexity: 4.12991\n",
      "[2023-07-09 16:17:25,168 INFO] Validation accuracy: 96.69\n",
      "[2023-07-09 16:17:25,168 INFO] Model is improving ppl: inf --> 4.12991.\n",
      "[2023-07-09 16:17:25,168 INFO] Model is improving acc: -inf --> 96.69.\n",
      "[2023-07-09 16:17:25,170 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_400.pt\n",
      "[2023-07-09 16:18:06,571 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 72\n",
      "[2023-07-09 16:18:06,684 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 73\n",
      "[2023-07-09 16:18:06,771 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 74\n",
      "[2023-07-09 16:18:06,869 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 75\n",
      "[2023-07-09 16:18:06,958 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 76\n",
      "[2023-07-09 16:18:08,867 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 77\n",
      "[2023-07-09 16:18:08,957 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 78\n",
      "[2023-07-09 16:18:09,049 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 79\n",
      "[2023-07-09 16:18:09,139 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 80\n",
      "[2023-07-09 16:18:09,232 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 81\n",
      "[2023-07-09 16:18:09,317 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 82\n",
      "[2023-07-09 16:18:09,401 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 83\n",
      "[2023-07-09 16:18:09,497 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 84\n",
      "[2023-07-09 16:18:09,581 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 85\n",
      "[2023-07-09 16:18:09,672 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 86\n",
      "[2023-07-09 16:18:09,758 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 87\n",
      "[2023-07-09 16:18:09,845 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 88\n",
      "[2023-07-09 16:18:12,000 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 89\n",
      "[2023-07-09 16:18:12,086 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 90\n",
      "[2023-07-09 16:18:12,174 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 91\n",
      "[2023-07-09 16:18:12,258 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 92\n",
      "[2023-07-09 16:18:12,347 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 93\n",
      "[2023-07-09 16:18:12,430 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 94\n",
      "[2023-07-09 16:18:12,529 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 95\n",
      "[2023-07-09 16:18:12,614 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 96\n",
      "[2023-07-09 16:18:12,703 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 97\n",
      "[2023-07-09 16:18:12,793 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 98\n",
      "[2023-07-09 16:18:12,886 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 99\n",
      "[2023-07-09 16:18:12,977 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 100\n",
      "[2023-07-09 16:18:13,062 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 101\n",
      "[2023-07-09 16:18:13,150 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 102\n",
      "[2023-07-09 16:18:13,238 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 103\n",
      "[2023-07-09 16:18:15,832 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 104\n",
      "[2023-07-09 16:18:15,917 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 105\n",
      "[2023-07-09 16:18:16,001 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 106\n",
      "[2023-07-09 16:18:16,084 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 107\n",
      "[2023-07-09 16:18:51,409 INFO] Step 450/ 1200; acc: 99.4; ppl:   3.3; xent: 1.2; lr: 0.00178; sents:   57158; bsz: 1975/3792/286; 4519/8675 tok/s;    651 sec;\n",
      "[2023-07-09 16:19:57,112 INFO] Step 500/ 1200; acc: 99.8; ppl:   3.2; xent: 1.2; lr: 0.00197; sents:   58368; bsz: 1970/3793/292; 5998/11546 tok/s;    717 sec;\n",
      "[2023-07-09 16:19:57,114 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_500.pt\n",
      "[2023-07-09 16:21:05,046 INFO] Step 550/ 1200; acc: 98.8; ppl:   3.4; xent: 1.2; lr: 0.00188; sents:   57909; bsz: 1984/3794/290; 5841/11170 tok/s;    785 sec;\n",
      "[2023-07-09 16:22:10,262 INFO] Step 600/ 1200; acc: 99.4; ppl:   3.3; xent: 1.2; lr: 0.00180; sents:   57514; bsz: 1981/3795/288; 6075/11639 tok/s;    850 sec;\n",
      "[2023-07-09 16:22:10,265 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_600.pt\n",
      "[2023-07-09 16:23:11,919 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 108\n",
      "[2023-07-09 16:23:12,009 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 109\n",
      "[2023-07-09 16:23:12,097 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 110\n",
      "[2023-07-09 16:23:12,187 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 111\n",
      "[2023-07-09 16:23:12,287 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 112\n",
      "[2023-07-09 16:23:12,375 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 113\n",
      "[2023-07-09 16:23:12,465 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 114\n",
      "[2023-07-09 16:23:12,572 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 115\n",
      "[2023-07-09 16:23:12,661 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 116\n",
      "[2023-07-09 16:23:12,751 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 117\n",
      "[2023-07-09 16:23:12,847 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 118\n",
      "[2023-07-09 16:23:12,937 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 119\n",
      "[2023-07-09 16:23:13,025 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 120\n",
      "[2023-07-09 16:23:15,255 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 121\n",
      "[2023-07-09 16:23:15,358 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 122\n",
      "[2023-07-09 16:23:15,448 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 123\n",
      "[2023-07-09 16:23:15,541 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 124\n",
      "[2023-07-09 16:23:15,631 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 125\n",
      "[2023-07-09 16:23:15,726 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 126\n",
      "[2023-07-09 16:23:15,818 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 127\n",
      "[2023-07-09 16:23:15,914 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 128\n",
      "[2023-07-09 16:23:16,008 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 129\n",
      "[2023-07-09 16:23:16,094 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 130\n",
      "[2023-07-09 16:23:16,183 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 131\n",
      "[2023-07-09 16:23:16,274 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 132\n",
      "[2023-07-09 16:23:16,369 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 133\n",
      "[2023-07-09 16:23:16,461 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 134\n",
      "[2023-07-09 16:23:19,026 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 135\n",
      "[2023-07-09 16:23:19,175 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 136\n",
      "[2023-07-09 16:23:19,333 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 137\n",
      "[2023-07-09 16:23:19,499 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 138\n",
      "[2023-07-09 16:23:19,659 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 139\n",
      "[2023-07-09 16:23:19,818 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 140\n",
      "[2023-07-09 16:23:19,972 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 141\n",
      "[2023-07-09 16:23:20,131 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 142\n",
      "[2023-07-09 16:23:35,048 INFO] Step 650/ 1200; acc: 99.2; ppl:   3.3; xent: 1.2; lr: 0.00173; sents:   56631; bsz: 1955/3790/283; 4612/8940 tok/s;    935 sec;\n",
      "[2023-07-09 16:24:40,764 INFO] Step 700/ 1200; acc: 99.7; ppl:   3.2; xent: 1.2; lr: 0.00167; sents:   56032; bsz: 1926/3803/280; 5863/11575 tok/s;   1001 sec;\n",
      "[2023-07-09 16:24:40,767 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_700.pt\n",
      "[2023-07-09 16:25:52,280 INFO] Step 750/ 1200; acc: 99.8; ppl:   3.2; xent: 1.2; lr: 0.00161; sents:   56717; bsz: 1954/3798/284; 5465/10621 tok/s;   1072 sec;\n",
      "[2023-07-09 16:26:57,753 INFO] Step 800/ 1200; acc: 99.3; ppl:   3.3; xent: 1.2; lr: 0.00156; sents:   59533; bsz: 2023/3776/298; 6181/11535 tok/s;   1138 sec;\n",
      "[2023-07-09 16:26:58,947 INFO] valid stats calculation and sentences rebuilding\n",
      "                           took: 1.1926865577697754 s.\n",
      "[2023-07-09 16:26:58,948 INFO] Train perplexity: 5.03251\n",
      "[2023-07-09 16:26:58,948 INFO] Train accuracy: 91.8251\n",
      "[2023-07-09 16:26:58,948 INFO] Sentences processed: 920510\n",
      "[2023-07-09 16:26:58,948 INFO] Average bsz: 1971/3793/288\n",
      "[2023-07-09 16:26:58,949 INFO] Validation perplexity: 3.90416\n",
      "[2023-07-09 16:26:58,949 INFO] Validation accuracy: 96.2461\n",
      "[2023-07-09 16:26:58,949 INFO] Stalled patience: 3/4\n",
      "[2023-07-09 16:26:58,951 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_800.pt\n",
      "[2023-07-09 16:28:06,480 INFO] Step 850/ 1200; acc: 99.4; ppl:   3.3; xent: 1.2; lr: 0.00151; sents:   58878; bsz: 2013/3787/294; 5859/11020 tok/s;   1206 sec;\n",
      "[2023-07-09 16:28:19,364 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 143\n",
      "[2023-07-09 16:28:19,459 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 144\n",
      "[2023-07-09 16:28:19,547 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 145\n",
      "[2023-07-09 16:28:19,641 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 146\n",
      "[2023-07-09 16:28:19,731 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 147\n",
      "[2023-07-09 16:28:19,822 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 148\n",
      "[2023-07-09 16:28:21,898 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 149\n",
      "[2023-07-09 16:28:22,063 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 150\n",
      "[2023-07-09 16:28:22,220 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 151\n",
      "[2023-07-09 16:28:22,372 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 152\n",
      "[2023-07-09 16:28:22,535 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 153\n",
      "[2023-07-09 16:28:22,692 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 154\n",
      "[2023-07-09 16:28:22,848 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 155\n",
      "[2023-07-09 16:28:23,002 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 156\n",
      "[2023-07-09 16:28:23,163 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 157\n",
      "[2023-07-09 16:28:23,315 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 158\n",
      "[2023-07-09 16:28:23,466 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 159\n",
      "[2023-07-09 16:28:23,620 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 160\n",
      "[2023-07-09 16:28:26,403 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 161\n",
      "[2023-07-09 16:28:26,490 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 162\n",
      "[2023-07-09 16:28:26,579 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 163\n",
      "[2023-07-09 16:28:26,674 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 164\n",
      "[2023-07-09 16:28:26,764 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 165\n",
      "[2023-07-09 16:28:26,858 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 166\n",
      "[2023-07-09 16:28:26,954 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 167\n",
      "[2023-07-09 16:28:27,045 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 168\n",
      "[2023-07-09 16:28:27,144 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 169\n",
      "[2023-07-09 16:28:27,235 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 170\n",
      "[2023-07-09 16:28:27,327 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 171\n",
      "[2023-07-09 16:28:27,413 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 172\n",
      "[2023-07-09 16:28:27,502 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 173\n",
      "[2023-07-09 16:28:27,594 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 174\n",
      "[2023-07-09 16:28:27,683 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 175\n",
      "[2023-07-09 16:28:27,780 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 176\n",
      "[2023-07-09 16:28:30,528 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 177\n",
      "[2023-07-09 16:28:30,612 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 178\n",
      "[2023-07-09 16:29:32,271 INFO] Step 900/ 1200; acc: 99.6; ppl:   3.2; xent: 1.2; lr: 0.00147; sents:   58333; bsz: 1965/3784/292; 4582/8821 tok/s;   1292 sec;\n",
      "[2023-07-09 16:29:32,273 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_900.pt\n",
      "[2023-07-09 16:30:39,038 INFO] Step 950/ 1200; acc: 99.8; ppl:   3.2; xent: 1.2; lr: 0.00143; sents:   57007; bsz: 1959/3794/285; 5867/11365 tok/s;   1359 sec;\n",
      "[2023-07-09 16:31:44,116 INFO] Step 1000/ 1200; acc: 99.8; ppl:   3.2; xent: 1.2; lr: 0.00140; sents:   55715; bsz: 1934/3804/279; 5945/11690 tok/s;   1424 sec;\n",
      "[2023-07-09 16:31:44,118 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_1000.pt\n",
      "[2023-07-09 16:32:51,270 INFO] Step 1050/ 1200; acc: 99.6; ppl:   3.2; xent: 1.2; lr: 0.00136; sents:   57253; bsz: 1973/3795/286; 5877/11304 tok/s;   1491 sec;\n",
      "[2023-07-09 16:33:25,799 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 179\n",
      "[2023-07-09 16:33:25,953 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 180\n",
      "[2023-07-09 16:33:26,109 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 181\n",
      "[2023-07-09 16:33:26,267 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 182\n",
      "[2023-07-09 16:33:26,432 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 183\n",
      "[2023-07-09 16:33:26,593 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 184\n",
      "[2023-07-09 16:33:26,770 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 185\n",
      "[2023-07-09 16:33:26,945 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 186\n",
      "[2023-07-09 16:33:27,106 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 187\n",
      "[2023-07-09 16:33:27,271 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 188\n",
      "[2023-07-09 16:33:27,430 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 189\n",
      "[2023-07-09 16:33:27,589 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 190\n",
      "[2023-07-09 16:33:27,746 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 191\n",
      "[2023-07-09 16:33:27,913 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 192\n",
      "[2023-07-09 16:33:28,077 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 193\n",
      "[2023-07-09 16:33:30,749 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 194\n",
      "[2023-07-09 16:33:30,838 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 195\n",
      "[2023-07-09 16:33:30,940 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 196\n",
      "[2023-07-09 16:33:31,031 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 197\n",
      "[2023-07-09 16:33:31,123 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 198\n",
      "[2023-07-09 16:33:31,210 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 199\n",
      "[2023-07-09 16:33:31,315 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 200\n",
      "[2023-07-09 16:33:31,404 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 201\n",
      "[2023-07-09 16:33:31,491 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 202\n",
      "[2023-07-09 16:33:31,587 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 203\n",
      "[2023-07-09 16:33:31,679 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 204\n",
      "[2023-07-09 16:33:31,771 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 205\n",
      "[2023-07-09 16:33:31,861 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 206\n",
      "[2023-07-09 16:33:31,966 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 207\n",
      "[2023-07-09 16:33:32,054 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 208\n",
      "[2023-07-09 16:33:34,742 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 209\n",
      "[2023-07-09 16:33:34,833 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 210\n",
      "[2023-07-09 16:33:34,922 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 211\n",
      "[2023-07-09 16:33:35,020 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 212\n",
      "[2023-07-09 16:33:35,108 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 213\n",
      "[2023-07-09 16:34:16,416 INFO] Step 1100/ 1200; acc: 99.7; ppl:   3.2; xent: 1.2; lr: 0.00133; sents:   59798; bsz: 2032/3785/299; 4773/8891 tok/s;   1576 sec;\n",
      "[2023-07-09 16:34:16,418 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_1100.pt\n",
      "[2023-07-09 16:35:27,702 INFO] Step 1150/ 1200; acc: 99.8; ppl:   3.2; xent: 1.2; lr: 0.00130; sents:   58505; bsz: 1996/3787/293; 5599/10624 tok/s;   1648 sec;\n",
      "[2023-07-09 16:36:32,632 INFO] Step 1200/ 1200; acc: 99.9; ppl:   3.2; xent: 1.2; lr: 0.00128; sents:   56748; bsz: 1953/3801/284; 6015/11708 tok/s;   1713 sec;\n",
      "[2023-07-09 16:36:33,814 INFO] valid stats calculation and sentences rebuilding\n",
      "                           took: 1.1814734935760498 s.\n",
      "[2023-07-09 16:36:33,816 INFO] Train perplexity: 4.3333\n",
      "[2023-07-09 16:36:33,816 INFO] Train accuracy: 94.4487\n",
      "[2023-07-09 16:36:33,816 INFO] Sentences processed: 1.38275e+06\n",
      "[2023-07-09 16:36:33,816 INFO] Average bsz: 1974/3792/288\n",
      "[2023-07-09 16:36:33,816 INFO] Validation perplexity: 3.68206\n",
      "[2023-07-09 16:36:33,816 INFO] Validation accuracy: 97.4645\n",
      "[2023-07-09 16:36:33,816 INFO] Model is improving ppl: 4.12991 --> 3.68206.\n",
      "[2023-07-09 16:36:33,816 INFO] Model is improving acc: 96.69 --> 97.4645.\n",
      "[2023-07-09 16:36:33,818 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_1200.pt\n"
     ]
    }
   ],
   "source": [
    "# Train the NMT model using the 'onmt_train' command and provide the configuration file 'config.yaml'\n",
    "!onmt_train -config config.yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1688920598179,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "ro-21ODLnBNU",
    "outputId": "39a2d243-73c8-4eb9-f2b4-57fa04ee04a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_step_1000.pt  model_step_200.pt  model_step_600.pt  src.vocab\n",
      "model_step_100.pt   model_step_300.pt  model_step_700.pt  train.log\n",
      "model_step_1100.pt  model_step_400.pt  model_step_800.pt\n",
      "model_step_1200.pt  model_step_500.pt  model_step_900.pt\n"
     ]
    }
   ],
   "source": [
    "# List the contents of the 'model_root' directory where the NMT model and related files are saved\n",
    "!ls '{model_root}'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nqRou9WfsDbh"
   },
   "source": [
    "# Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 795079,
     "status": "ok",
     "timestamp": 1688921393257,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "tStHVtbNmipI",
    "outputId": "df18f2e5-9839-45f4-b66c-6d78426328ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-09 16:36:39,435 INFO] Loading checkpoint from /content/nmt/nmtmodel/model_step_1200.pt\n",
      "[2023-07-09 16:36:39,982 INFO] Loading data into the model\n",
      "[2023-07-09 16:49:52,704 INFO] PRED SCORE: -0.1017, PRED PPL: 1.11 NB SENTENCES: 5916\n"
     ]
    }
   ],
   "source": [
    "# Perform translation using the trained NMT model\n",
    "# Arguments:\n",
    "# --model: Path to the trained NMT model checkpoint file\n",
    "# --src: Path to the source input file containing sentences to be translated\n",
    "# --output: Path to the output file to save translated sentences\n",
    "# -beam_size: Beam size used during translation\n",
    "!onmt_translate --model '/content/nmt/nmtmodel/model_step_1200.pt' \\\n",
    "                --src /content/nmt/monument50/test.en \\\n",
    "                --output /content/nmt/monument50/trans_test.sparql \\\n",
    "                -beam_size 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1688921393258,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "UYszCfIbssof",
    "outputId": "711d219b-0557-430d-8866-f3aaeb9de3c1"
   },
   "outputs": [],
   "source": [
    "# Display the first 5 lines of the English test data file\n",
    "# Arguments:\n",
    "# -n 5: Display the first 5 lines\n",
    "# /content/nmt/monument50/test.en: Path to the test data file in English\n",
    "!head -n 5 /content/nmt/monument50/test.en\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 289,
     "status": "ok",
     "timestamp": 1688921393545,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "nnTRp6eas_p7",
    "outputId": "02b98987-ccf1-41c3-8b00-68b423c754e2"
   },
   "outputs": [],
   "source": [
    "# Display the first 5 lines of the translated output file\n",
    "# Arguments:\n",
    "# -n 5: Display the first 5 lines\n",
    "# /content/nmt/monument50/trans_test.sparql: Path to the translated output file\n",
    "!head -n 5 /content/nmt/monument50/trans_test.sparql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1688921393546,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "azi6x-EstHYN",
    "outputId": "93d8bab9-d3d3-43fb-f751-57598761c501"
   },
   "outputs": [],
   "source": [
    "# Display the first 5 lines of the reference target file\n",
    "# Arguments:\n",
    "# -n 5: Display the first 5 lines\n",
    "# /content/nmt/monument50/test.sparql: Path to the reference target file\n",
    "!head -n 5 /content/nmt/monument50/test.sparql\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vANuMTJUtfUb"
   },
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1688921393546,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "kj1AtrSDtjfq",
    "outputId": "2112a480-2d41-43d6-8d0a-9669caf24a82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/nmt\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 646,
     "status": "ok",
     "timestamp": 1688921394189,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "CBxRt66trVw5",
    "outputId": "299a534a-a757-4aec-d157-7938b1f34623"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference 1st sentence: select var_a where brack_open var_a rdf_type dbr_Cristo_del_Otero sep_dot var_a dbp_height var_b brack_close order by desc par_open var_b par_close  limit 1\n",
      "MTed 1st sentence: select var_a where brack_open dbr_Cristo_del_Otero dbo_abstract var_a brack_close\n",
      "Accuracy:  0.9038187840012769\n"
     ]
    }
   ],
   "source": [
    "# Copy the Compute-accuracy.py script from the Google Drive to the current directory\n",
    "!cp /content/drive/MyDrive/compute-accuracy.py ./\n",
    "\n",
    "# Evaluate the translation using accuracy\n",
    "# Arguments:\n",
    "# /content/nmt/monument50/test.sparql: Path to the reference target file\n",
    "# /content/nmt/monument50/trans_test.sparql: Path to the translated output file\n",
    "!python compute-accuracy.py /content/nmt/monument50/test.sparql /content/nmt/monument50/trans_test.sparql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7998,
     "status": "ok",
     "timestamp": 1688921402185,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "p2M4CDSltiuL",
    "outputId": "92076841-3d7d-48be-8a3f-292407962535"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference 1st sentence: select var_a where brack_open var_a rdf_type dbr_Cristo_del_Otero sep_dot var_a dbp_height var_b brack_close order by desc par_open var_b par_close  limit 1\n",
      "MTed 1st sentence: select var_a where brack_open dbr_Cristo_del_Otero dbo_abstract var_a brack_close\n",
      "BLEU:  95.57343218895528\n"
     ]
    }
   ],
   "source": [
    "# Install the sacrebleu library using pip\n",
    "!pip install sacrebleu > /dev/null\n",
    "\n",
    "# Copy the Compute-bleu.py script from Google Drive to the current directory\n",
    "!cp /content/drive/MyDrive/compute-bleu.py ./\n",
    "\n",
    "# Evaluate the translation using BLEU score\n",
    "# Arguments:\n",
    "# /content/nmt/monument50/test.sparql: Path to the reference target file\n",
    "# /content/nmt/monument50/trans_test.sparql: Path to the translated output file\n",
    "!python compute-bleu.py /content/nmt/monument50/test.sparql /content/nmt/monument50/trans_test.sparql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7251,
     "status": "ok",
     "timestamp": 1688921409430,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "YDcNrZm3MCO1",
    "outputId": "cb750f6e-b19a-4754-93f2-3793708f9b77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference 1st sentence: select var_a where brack_open var_a rdf_type dbr_Cristo_del_Otero sep_dot var_a dbp_height var_b brack_close order by desc par_open var_b par_close  limit 1\n",
      "MTed 1st sentence: select var_a where brack_open dbr_Cristo_del_Otero dbo_abstract var_a brack_close\n",
      "Rouge-L:  0.9821216708983418\n"
     ]
    }
   ],
   "source": [
    "# Install the Rouge library using pip\n",
    "!pip install rouge > /dev/null\n",
    "\n",
    "# Copy the compute-rouge-l.py script from Google Drive to the current directory\n",
    "!cp /content/drive/MyDrive/compute-rouge-l.py ./\n",
    "\n",
    "# Evaluate the translation using Rouge-L score\n",
    "# Arguments:\n",
    "# /content/nmt/monument50/test.sparql: Path to the reference target file\n",
    "# /content/nmt/monument50/trans_test.sparql: Path to the translated output file\n",
    "!python compute-rouge-l.py /content/nmt/monument50/test.sparql /content/nmt/monument50/trans_test.sparql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 68127,
     "status": "ok",
     "timestamp": 1688921511499,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "NoyUjuODj-kN"
   },
   "outputs": [],
   "source": [
    "# Copy the trained NMT model directory to Google Drive for backup\n",
    "# Source: /content/nmt/nmtmodel (trained NMT model)\n",
    "# Destination: /content/drive/MyDrive/NMT_models (Google Drive directory)\n",
    "!cp -r /content/nmt/nmtmodel /content/drive/MyDrive/NMT_models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8L_nKJQMr2nO"
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uu7lspbw1Gxw"
   },
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    ''' ''',\n",
    "    ''' '''\n",
    "]\n",
    "with open('questions.en', 'w') as fp:\n",
    "    t = [''.join(x) for x in sentences]\n",
    "    t = '\\n'.join(t)\n",
    "    fp.write(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! onmt_translate --model '/content/nmt/nmtmodel/model_step_1200.pt' --src questions.en --output pred.sparql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat pred.sparql"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyP9fEw2Dh4rnTyt7hJeaGR9",
   "gpuType": "T4",
   "mount_file_id": "11FdBYgCfg43w67gsMKX7eE8Wk3EOl0hp",
   "provenance": [
    {
     "file_id": "1qwBCXsrX0UD96jZU-P9vIhFRTnCZYO6m",
     "timestamp": 1686823688936
    },
    {
     "file_id": "1sYi4GQuLKBmhhiOJvNHDacHYPI39LsG-",
     "timestamp": 1686759059262
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
