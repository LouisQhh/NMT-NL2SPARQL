{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0w2wNk0167DQ"
   },
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 412,
     "status": "ok",
     "timestamp": 1688916655575,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "6ZH1UZrpjtPE",
    "outputId": "8004f542-900a-46c0-934d-4f30655c36b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/nmt\n"
     ]
    }
   ],
   "source": [
    "# Create a directory named 'nmt'\n",
    "!mkdir nmt\n",
    "\n",
    "# Change the current working directory to the 'nmt' directory\n",
    "%cd nmt\n",
    "\n",
    "# Inside the 'nmt' directory, create a subdirectory named 'nmtmodel'\n",
    "!mkdir nmtmodel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 125351,
     "status": "ok",
     "timestamp": 1688916798403,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "df6W9IIWmlQL",
    "outputId": "e49653fe-a045-4918-f30e-eb1ad1b96d4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchdata 0.6.1 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\n",
      "torchtext 0.15.2 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Install the specified versions of OpenNMT-py, torchvision, and torchaudio using pip\n",
    "! pip install OpenNMT-py torchvision==0.14.1 torchaudio==0.13.1 > /dev/null\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1688916798404,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "_3WnsZ-1nUSj",
    "outputId": "3545a02a-1d8b-4f87-f66f-def40556c9eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/nmt\n"
     ]
    }
   ],
   "source": [
    "# Print the current working directory\n",
    "!pwd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QypsRuOq7IiR"
   },
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1129,
     "status": "ok",
     "timestamp": 1688916799526,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "Jsc7THqZnYCI",
    "outputId": "856c4116-915e-4fce-dc0b-3ab6684e4a7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ./monument.zip\n",
      "   creating: ./monument/\n",
      "  inflating: ./__MACOSX/._monument   \n",
      "  inflating: ./monument/dev.en       \n",
      "  inflating: ./__MACOSX/monument/._dev.en  \n",
      "  inflating: ./monument/dev.sparql   \n",
      "  inflating: ./__MACOSX/monument/._dev.sparql  \n",
      "  inflating: ./monument/.DS_Store    \n",
      "  inflating: ./__MACOSX/monument/._.DS_Store  \n",
      "  inflating: ./monument/train.sparql  \n",
      "  inflating: ./__MACOSX/monument/._train.sparql  \n",
      "  inflating: ./monument/train.en     \n",
      "  inflating: ./__MACOSX/monument/._train.en  \n",
      "  inflating: ./monument/test.sparql  \n",
      "  inflating: ./__MACOSX/monument/._test.sparql  \n",
      "  inflating: ./monument/test.en      \n",
      "  inflating: ./__MACOSX/monument/._test.en  \n"
     ]
    }
   ],
   "source": [
    "# Copy the file \"monument.zip\" from \"/content/drive/MyDrive/\" to the current directory\n",
    "!cp /content/drive/MyDrive/monument.zip ./\n",
    "\n",
    "# Unzip the file \"monument.zip\" and extract its contents to the current directory\n",
    "# -d specifies the target directory for extraction\n",
    "!unzip ./monument.zip -d ./\n",
    "\n",
    "# Remove the original zip file \"monument.zip\" from the '/content/nmt/' directory\n",
    "!rm /content/nmt/monument.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1688905375112,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "dbGofKann5xB",
    "outputId": "9fe13660-ba2b-4bd3-d9c8-48c2d95abf98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__MACOSX  monument600-dataset  nmtmodel\n"
     ]
    }
   ],
   "source": [
    "# List the contents of the current directory\n",
    "!ls\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c-Nfw0l77P8e"
   },
   "source": [
    "# Create the Training Configuration File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1688916799527,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "9uBY92Mf8vE6"
   },
   "outputs": [],
   "source": [
    "# Define the path to the model root directory\n",
    "model_root = '/content/nmt/nmtmodel'\n",
    "\n",
    "# Create the model root directory and any necessary parent directories using 'mkdir -p'\n",
    "!mkdir -p '{model_root}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1688916799527,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "xAJ686rIvLRn"
   },
   "outputs": [],
   "source": [
    "# Define the content for the configuration file 'config.yaml'\n",
    "config = f'''# config.yaml\n",
    "## Where the samples will be written\n",
    "save_data: {model_root}\n",
    "\n",
    "## Where the vocab(s) will be written\n",
    "# Vocabulary files, generated by onmt_build_vocab\n",
    "src_vocab: {model_root}/src.vocab\n",
    "tgt_vocab: {model_root}/src.vocab\n",
    "\n",
    "# Vocabulary size - should be the same as in sentence piece\n",
    "src_vocab_size: 5000\n",
    "tgt_vocab_size: 5000\n",
    "share_vocab: true\n",
    "\n",
    "# Training files\n",
    "data:\n",
    "    train:\n",
    "        path_src: /content/nmt/monument/train.en\n",
    "        path_tgt: /content/nmt/monument/train.sparql\n",
    "    valid:\n",
    "        path_src: /content/nmt/monument/dev.en\n",
    "        path_tgt: /content/nmt/monument/dev.sparql\n",
    "\n",
    "# Where to save the checkpoints\n",
    "save_model: {model_root}/model\n",
    "log_file: {model_root}/train.log\n",
    "save_checkpoint_steps: 100\n",
    "train_steps: 1200\n",
    "valid_steps: 400\n",
    "\n",
    "# Stop training if it does not imporve after n validations\n",
    "early_stopping: 4\n",
    "\n",
    "# To save space, limit checkpoints to last n\n",
    "# keep_checkpoint: 3\n",
    "\n",
    "seed: 4242\n",
    "\n",
    "# Number of GPUs, and IDs of GPUs\n",
    "world_size: 1\n",
    "gpu_ranks: [0]\n",
    "\n",
    "# Batching\n",
    "# queue_size: 100\n",
    "bucket_size: 262144\n",
    "num_workers: 0  # Default: 2, set to 0 when RAM out of memory\n",
    "batch_type: \"tokens\"\n",
    "batch_size: 4096   # Tokens per batch, change when CUDA out of memory\n",
    "valid_batch_size: 2048\n",
    "# world_size: 1\n",
    "max_generator_batches: 2\n",
    "accum_count: [4]\n",
    "accum_steps: [0]\n",
    "\n",
    "# Optimization\n",
    "# model_dtype: \"fp16\"\n",
    "optim: \"adam\"\n",
    "# learning_rate: 2\n",
    "warmup_steps: 500\n",
    "decay_method: \"noam\"\n",
    "adam_beta1: 0.9\n",
    "adam_beta2: 0.98\n",
    "max_grad_norm: 0\n",
    "label_smoothing: 0.1\n",
    "param_init: 0\n",
    "param_init_glorot: true\n",
    "normalization: \"tokens\"\n",
    "\n",
    "# Model\n",
    "encoder_type: transformer\n",
    "decoder_type: transformer\n",
    "position_encoding: true\n",
    "enc_layers: 6\n",
    "dec_layers: 6\n",
    "heads: 8\n",
    "hidden_size: 512\n",
    "word_vec_size: 512\n",
    "transformer_ff: 2048\n",
    "# dropout_steps: [0]\n",
    "dropout: [0.1]\n",
    "attention_dropout: [0.1]\n",
    "'''\n",
    "\n",
    "# Write the configuration content to the 'config.yaml' file\n",
    "with open(\"config.yaml\", \"w+\") as config_yaml:\n",
    "  config_yaml.write(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z1ZGev3N7ao3"
   },
   "source": [
    "# Build Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2627,
     "status": "ok",
     "timestamp": 1688916802149,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "F4jDz0Dr7sne",
    "outputId": "16b18d69-20a2-4dd9-9ae6-949a68d4507f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus train's weight should be given. We default it to 1 for you.\n",
      "[2023-07-09 15:33:20,706 INFO] Counter vocab from -1 samples.\n",
      "[2023-07-09 15:33:20,706 INFO] n_sample=-1: Build vocab on full datasets.\n",
      "[2023-07-09 15:33:20,987 INFO] Counters src: 2569\n",
      "[2023-07-09 15:33:20,987 INFO] Counters tgt: 2058\n",
      "[2023-07-09 15:33:20,988 INFO] Counters after share:4609\n"
     ]
    }
   ],
   "source": [
    "# Import the 'os' module for interacting with the operating system\n",
    "import os\n",
    "\n",
    "# Check if the source vocabulary file 'src.vocab' doesn't exist in the model root directory\n",
    "if not os.path.exists(os.path.join(model_root, 'src.vocab')):\n",
    "    # Build the source vocabulary using the onmt_build_vocab command with the specified configuration file\n",
    "    # --n_sample -1: Sample the entire training dataset\n",
    "    # The '|| true' at the end ensures that the command continues even if it encounters an error\n",
    "    !onmt_build_vocab -config config.yaml --n_sample -1 || true\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V312rtxK7pd7"
   },
   "source": [
    "# Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1789,
     "status": "ok",
     "timestamp": 1688916803935,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "tJ4dYNPtvQ5Q",
    "outputId": "874e9a5b-3ad5-4425-fcba-e638bc0e35a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jul  9 15:33:21 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   49C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n",
      "\n",
      "\n",
      "$*****************************************************************************$\n",
      "GPU:\n",
      "GPU 0: Tesla T4 (UUID: GPU-f447c7a1-4adb-07a7-8bf6-e932df536b94)\n",
      "$*****************************************************************************$\n",
      "\n",
      "\n",
      "$*****************************************************************************$\n",
      "True\n",
      "Tesla T4\n",
      "Free GPU memory: 14998.8125 out of: 15101.8125\n",
      "$*****************************************************************************$\n"
     ]
    }
   ],
   "source": [
    "# Display GPU information using the nvidia-smi command\n",
    "!nvidia-smi\n",
    "\n",
    "# Print a separator line for clarity\n",
    "print('\\n\\n$*****************************************************************************$')\n",
    "\n",
    "# Print \"GPU:\" to indicate GPU-related information\n",
    "print('GPU:')\n",
    "\n",
    "# Display a list of GPUs using the nvidia-smi command with the -L flag\n",
    "!nvidia-smi -L\n",
    "\n",
    "# Print a separator line for clarity\n",
    "print('$*****************************************************************************$')\n",
    "\n",
    "# Print a separator line for clarity\n",
    "print('\\n\\n$*****************************************************************************$')\n",
    "\n",
    "# Check if the GPU is visible and available for PyTorch\n",
    "import torch\n",
    "\n",
    "# Check if CUDA (GPU support for PyTorch) is available\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "# Get the name of the GPU device at index 0\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "# Get GPU memory information using torch.cuda.mem_get_info()\n",
    "gpu_memory = torch.cuda.mem_get_info(0)\n",
    "print(\"Free GPU memory:\", gpu_memory[0]/1024**2, \"out of:\", gpu_memory[1]/1024**2)\n",
    "\n",
    "# Print a separator line for clarity\n",
    "print('$*****************************************************************************$')\n",
    "\n",
    "# Display Linux distribution information using the lsb_release command\n",
    "!lsb_release -a\n",
    "\n",
    "# Print a separator line for clarity\n",
    "print('$*****************************************************************************$')\n",
    "\n",
    "# Display the Linux kernel version using the uname -r command\n",
    "!uname -r\n",
    "\n",
    "# Print a separator line for clarity\n",
    "print('$*****************************************************************************$')\n",
    "\n",
    "# Display the CUDA compiler version using the nvcc --version command\n",
    "!nvcc --version\n",
    "\n",
    "# Print a separator line for clarity\n",
    "print('$*****************************************************************************$')\n",
    "\n",
    "# Display the version of PyTorch using the torch.__version__ attribute\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "\n",
    "# Print a separator line for clarity\n",
    "print('$*****************************************************************************$')\n",
    "\n",
    "# Display CPU information by searching for the \"model name\" in /proc/cpuinfo\n",
    "!cat /proc/cpuinfo | grep model\\ name\n",
    "\n",
    "# Print a separator line for clarity\n",
    "print('$*****************************************************************************$')\n",
    "\n",
    "# Display total memory information using the meminfo file in /proc\n",
    "!cat /proc/meminfo | grep MemTotal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hmaMw_sc7gvP"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1756782,
     "status": "ok",
     "timestamp": 1688918560713,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "5iMmswvHvta_",
    "outputId": "d224fe0a-757d-4f72-b4cb-493ad16efe65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-09 15:33:24,830 INFO] Missing transforms field for train data, set to default: [].\n",
      "[2023-07-09 15:33:24,830 WARNING] Corpus train's weight should be given. We default it to 1 for you.\n",
      "[2023-07-09 15:33:24,830 INFO] Missing transforms field for valid data, set to default: [].\n",
      "[2023-07-09 15:33:24,830 INFO] Parsed 2 corpora from -data.\n",
      "[2023-07-09 15:33:24,831 INFO] Get special vocabs from Transforms: {'src': [], 'tgt': []}.\n",
      "[2023-07-09 15:33:24,856 INFO] The first 10 tokens of the vocabs are:['<unk>', '<blank>', '<s>', '</s>', 'var_a', 'where', 'brack_open', 'brack_close', 'select', 'is']\n",
      "[2023-07-09 15:33:24,856 INFO] The decoder start token is: <s>\n",
      "[2023-07-09 15:33:24,856 INFO] Building model...\n",
      "[2023-07-09 15:33:25,627 INFO] Switching model to float32 for amp/apex_amp\n",
      "[2023-07-09 15:33:25,627 INFO] Non quantized layer compute is fp32\n",
      "[2023-07-09 15:33:26,607 INFO] NMTModel(\n",
      "  (encoder): TransformerEncoder(\n",
      "    (embeddings): Embeddings(\n",
      "      (make_embedding): Sequential(\n",
      "        (emb_luts): Elementwise(\n",
      "          (0): Embedding(4616, 512, padding_idx=1)\n",
      "        )\n",
      "        (pe): PositionalEncoding()\n",
      "      )\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): ModuleList(\n",
      "      (0): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (2): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (3): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (4): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (5): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "  )\n",
      "  (decoder): TransformerDecoder(\n",
      "    (embeddings): Embeddings(\n",
      "      (make_embedding): Sequential(\n",
      "        (emb_luts): Elementwise(\n",
      "          (0): Embedding(4616, 512, padding_idx=1)\n",
      "        )\n",
      "        (pe): PositionalEncoding()\n",
      "      )\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "    (transformer_layers): ModuleList(\n",
      "      (0): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (1): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (2): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (3): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (4): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (5): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (generator): Linear(in_features=512, out_features=4616, bias=True)\n",
      ")\n",
      "[2023-07-09 15:33:26,688 INFO] encoder: 21251072\n",
      "[2023-07-09 15:33:26,688 INFO] decoder: 29916680\n",
      "[2023-07-09 15:33:26,688 INFO] * number of parameters: 51167752\n",
      "[2023-07-09 15:33:26,689 INFO] Trainable parameters = {'torch.float32': 51167752, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
      "[2023-07-09 15:33:26,689 INFO] Non trainable parameters = {'torch.float32': 0, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
      "[2023-07-09 15:33:26,689 INFO]  * src vocab size = 4616\n",
      "[2023-07-09 15:33:26,689 INFO]  * tgt vocab size = 4616\n",
      "[2023-07-09 15:33:26,691 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 1\n",
      "[2023-07-09 15:33:26,692 INFO] Starting training on GPU: [0]\n",
      "[2023-07-09 15:33:26,692 INFO] Start training loop and validate every 400 steps...\n",
      "[2023-07-09 15:33:26,692 INFO] Scoring with: TransformPipe()\n",
      "[2023-07-09 15:33:26,949 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 2\n",
      "[2023-07-09 15:33:27,250 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 3\n",
      "[2023-07-09 15:33:27,428 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 4\n",
      "[2023-07-09 15:33:27,772 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 5\n",
      "[2023-07-09 15:33:28,329 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 6\n",
      "[2023-07-09 15:33:29,000 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 7\n",
      "[2023-07-09 15:33:29,351 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 8\n",
      "[2023-07-09 15:33:30,715 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 9\n",
      "[2023-07-09 15:33:31,656 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 10\n",
      "[2023-07-09 15:33:33,136 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 11\n",
      "[2023-07-09 15:33:33,448 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 12\n",
      "[2023-07-09 15:33:33,741 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 13\n",
      "[2023-07-09 15:33:34,747 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 14\n",
      "[2023-07-09 15:33:35,042 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 15\n",
      "[2023-07-09 15:33:35,251 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 16\n",
      "[2023-07-09 15:33:35,455 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 17\n",
      "[2023-07-09 15:33:36,394 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 18\n",
      "[2023-07-09 15:34:49,818 INFO] Step 50/ 1200; acc: 26.3; ppl: 282.7; xent: 5.6; lr: 0.00020; sents:   56850; bsz: 1943/3788/284; 4675/9114 tok/s;     83 sec;\n",
      "[2023-07-09 15:35:58,498 INFO] Step 100/ 1200; acc: 73.0; ppl:  12.5; xent: 2.5; lr: 0.00040; sents:   56940; bsz: 1949/3800/285; 5674/11065 tok/s;    152 sec;\n",
      "[2023-07-09 15:37:06,569 INFO] Step 150/ 1200; acc: 87.3; ppl:   6.3; xent: 1.8; lr: 0.00060; sents:   54473; bsz: 1916/3812/272; 5629/11200 tok/s;    220 sec;\n",
      "[2023-07-09 15:38:14,356 INFO] Step 200/ 1200; acc: 90.0; ppl:   5.5; xent: 1.7; lr: 0.00079; sents:   54815; bsz: 1899/3808/274; 5604/11236 tok/s;    288 sec;\n",
      "[2023-07-09 15:38:46,176 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 19\n",
      "[2023-07-09 15:38:46,392 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 20\n",
      "[2023-07-09 15:38:46,577 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 21\n",
      "[2023-07-09 15:38:46,770 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 22\n",
      "[2023-07-09 15:38:46,963 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 23\n",
      "[2023-07-09 15:38:47,148 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 24\n",
      "[2023-07-09 15:38:47,343 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 25\n",
      "[2023-07-09 15:38:49,589 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 26\n",
      "[2023-07-09 15:38:49,780 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 27\n",
      "[2023-07-09 15:38:49,970 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 28\n",
      "[2023-07-09 15:38:50,157 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 29\n",
      "[2023-07-09 15:38:50,349 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 30\n",
      "[2023-07-09 15:38:50,533 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 31\n",
      "[2023-07-09 15:38:50,731 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 32\n",
      "[2023-07-09 15:38:53,738 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 33\n",
      "[2023-07-09 15:38:54,056 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 34\n",
      "[2023-07-09 15:38:54,366 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 35\n",
      "[2023-07-09 15:38:54,670 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 36\n",
      "[2023-07-09 15:39:41,835 INFO] Step 250/ 1200; acc: 91.8; ppl:   5.0; xent: 1.6; lr: 0.00099; sents:   60469; bsz: 2021/3782/302; 4620/8648 tok/s;    375 sec;\n",
      "[2023-07-09 15:40:49,018 INFO] Step 300/ 1200; acc: 95.1; ppl:   4.3; xent: 1.5; lr: 0.00119; sents:   53611; bsz: 1873/3813/268; 5575/11351 tok/s;    442 sec;\n",
      "[2023-07-09 15:40:49,020 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_300.pt\n",
      "[2023-07-09 15:41:59,176 INFO] Step 350/ 1200; acc: 95.9; ppl:   4.1; xent: 1.4; lr: 0.00139; sents:   55022; bsz: 1920/3809/275; 5473/10859 tok/s;    512 sec;\n",
      "[2023-07-09 15:43:06,786 INFO] Step 400/ 1200; acc: 97.9; ppl:   3.7; xent: 1.3; lr: 0.00159; sents:   56225; bsz: 1932/3801/281; 5714/11244 tok/s;    580 sec;\n",
      "[2023-07-09 15:43:06,866 INFO] valid stats calculation and sentences rebuilding\n",
      "                           took: 0.0782163143157959 s.\n",
      "[2023-07-09 15:43:06,868 INFO] Train perplexity: 8.90857\n",
      "[2023-07-09 15:43:06,868 INFO] Train accuracy: 82.1826\n",
      "[2023-07-09 15:43:06,868 INFO] Sentences processed: 448405\n",
      "[2023-07-09 15:43:06,868 INFO] Average bsz: 1932/3802/280\n",
      "[2023-07-09 15:43:06,868 INFO] Validation perplexity: 3.53443\n",
      "[2023-07-09 15:43:06,868 INFO] Validation accuracy: 98.9544\n",
      "[2023-07-09 15:43:06,868 INFO] Model is improving ppl: inf --> 3.53443.\n",
      "[2023-07-09 15:43:06,868 INFO] Model is improving acc: -inf --> 98.9544.\n",
      "[2023-07-09 15:44:11,269 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 37\n",
      "[2023-07-09 15:44:11,570 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 38\n",
      "[2023-07-09 15:44:11,871 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 39\n",
      "[2023-07-09 15:44:14,021 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 40\n",
      "[2023-07-09 15:44:14,197 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 41\n",
      "[2023-07-09 15:44:14,371 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 42\n",
      "[2023-07-09 15:44:14,548 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 43\n",
      "[2023-07-09 15:44:14,719 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 44\n",
      "[2023-07-09 15:44:14,888 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 45\n",
      "[2023-07-09 15:44:17,187 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 46\n",
      "[2023-07-09 15:44:17,354 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 47\n",
      "[2023-07-09 15:44:17,538 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 48\n",
      "[2023-07-09 15:44:17,705 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 49\n",
      "[2023-07-09 15:44:17,877 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 50\n",
      "[2023-07-09 15:44:18,049 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 51\n",
      "[2023-07-09 15:44:18,221 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 52\n",
      "[2023-07-09 15:44:18,390 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 53\n",
      "[2023-07-09 15:44:21,047 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 54\n",
      "[2023-07-09 15:44:33,796 INFO] Step 450/ 1200; acc: 99.4; ppl:   3.4; xent: 1.2; lr: 0.00178; sents:   57928; bsz: 1979/3786/290; 4550/8703 tok/s;    667 sec;\n",
      "[2023-07-09 15:45:42,337 INFO] Step 500/ 1200; acc: 98.5; ppl:   3.5; xent: 1.3; lr: 0.00197; sents:   57305; bsz: 1946/3798/287; 5677/11082 tok/s;    736 sec;\n",
      "[2023-07-09 15:46:50,015 INFO] Step 550/ 1200; acc: 98.9; ppl:   3.5; xent: 1.3; lr: 0.00188; sents:   56814; bsz: 1957/3799/284; 5782/11227 tok/s;    803 sec;\n",
      "[2023-07-09 15:47:57,546 INFO] Step 600/ 1200; acc: 98.9; ppl:   3.4; xent: 1.2; lr: 0.00180; sents:   55678; bsz: 1925/3795/278; 5701/11240 tok/s;    871 sec;\n",
      "[2023-07-09 15:47:57,551 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_600.pt\n",
      "[2023-07-09 15:49:12,811 INFO] Step 650/ 1200; acc: 99.1; ppl:   3.4; xent: 1.2; lr: 0.00173; sents:   56737; bsz: 1954/3800/284; 5193/10097 tok/s;    946 sec;\n",
      "[2023-07-09 15:49:39,631 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 55\n",
      "[2023-07-09 15:49:39,816 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 56\n",
      "[2023-07-09 15:49:39,996 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 57\n",
      "[2023-07-09 15:49:40,174 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 58\n",
      "[2023-07-09 15:49:40,355 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 59\n",
      "[2023-07-09 15:49:40,600 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 60\n",
      "[2023-07-09 15:49:40,918 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 61\n",
      "[2023-07-09 15:49:43,765 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 62\n",
      "[2023-07-09 15:49:44,160 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 63\n",
      "[2023-07-09 15:49:44,549 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 64\n",
      "[2023-07-09 15:49:44,920 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 65\n",
      "[2023-07-09 15:49:45,269 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 66\n",
      "[2023-07-09 15:49:45,480 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 67\n",
      "[2023-07-09 15:49:45,650 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 68\n",
      "[2023-07-09 15:49:45,819 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 69\n",
      "[2023-07-09 15:49:48,607 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 70\n",
      "[2023-07-09 15:49:48,775 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 71\n",
      "[2023-07-09 15:49:48,952 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 72\n",
      "[2023-07-09 15:50:39,080 INFO] Step 700/ 1200; acc: 99.4; ppl:   3.4; xent: 1.2; lr: 0.00167; sents:   53930; bsz: 1899/3815/270; 4402/8844 tok/s;   1032 sec;\n",
      "[2023-07-09 15:51:45,507 INFO] Step 750/ 1200; acc: 99.5; ppl:   3.3; xent: 1.2; lr: 0.00161; sents:   54210; bsz: 1878/3812/271; 5653/11477 tok/s;   1099 sec;\n",
      "[2023-07-09 15:52:53,857 INFO] Step 800/ 1200; acc: 99.7; ppl:   3.3; xent: 1.2; lr: 0.00156; sents:   57850; bsz: 1982/3796/289; 5800/11109 tok/s;   1167 sec;\n",
      "[2023-07-09 15:52:53,935 INFO] valid stats calculation and sentences rebuilding\n",
      "                           took: 0.07702279090881348 s.\n",
      "[2023-07-09 15:52:53,936 INFO] Train perplexity: 5.51162\n",
      "[2023-07-09 15:52:53,937 INFO] Train accuracy: 90.6794\n",
      "[2023-07-09 15:52:53,937 INFO] Sentences processed: 898857\n",
      "[2023-07-09 15:52:53,937 INFO] Average bsz: 1936/3801/281\n",
      "[2023-07-09 15:52:53,937 INFO] Validation perplexity: 3.36475\n",
      "[2023-07-09 15:52:53,937 INFO] Validation accuracy: 99.4772\n",
      "[2023-07-09 15:52:53,937 INFO] Model is improving ppl: 3.53443 --> 3.36475.\n",
      "[2023-07-09 15:52:53,937 INFO] Model is improving acc: 98.9544 --> 99.4772.\n",
      "[2023-07-09 15:54:02,016 INFO] Step 850/ 1200; acc: 99.6; ppl:   3.3; xent: 1.2; lr: 0.00151; sents:   58361; bsz: 1997/3780/292; 5860/11093 tok/s;   1235 sec;\n",
      "[2023-07-09 15:55:01,148 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 73\n",
      "[2023-07-09 15:55:01,447 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 74\n",
      "[2023-07-09 15:55:01,744 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 75\n",
      "[2023-07-09 15:55:02,059 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 76\n",
      "[2023-07-09 15:55:04,713 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 77\n",
      "[2023-07-09 15:55:05,023 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 78\n",
      "[2023-07-09 15:55:05,337 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 79\n",
      "[2023-07-09 15:55:05,634 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 80\n",
      "[2023-07-09 15:55:05,929 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 81\n",
      "[2023-07-09 15:55:06,122 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 82\n",
      "[2023-07-09 15:55:06,300 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 83\n",
      "[2023-07-09 15:55:08,789 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 84\n",
      "[2023-07-09 15:55:08,960 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 85\n",
      "[2023-07-09 15:55:09,144 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 86\n",
      "[2023-07-09 15:55:09,321 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 87\n",
      "[2023-07-09 15:55:09,501 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 88\n",
      "[2023-07-09 15:55:09,680 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 89\n",
      "[2023-07-09 15:55:09,857 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 90\n",
      "[2023-07-09 15:55:29,137 INFO] Step 900/ 1200; acc: 99.1; ppl:   3.4; xent: 1.2; lr: 0.00147; sents:   55575; bsz: 1896/3806/278; 4353/8736 tok/s;   1322 sec;\n",
      "[2023-07-09 15:55:29,139 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_900.pt\n",
      "[2023-07-09 15:56:39,478 INFO] Step 950/ 1200; acc: 99.6; ppl:   3.3; xent: 1.2; lr: 0.00143; sents:   57348; bsz: 1944/3797/287; 5528/10796 tok/s;   1393 sec;\n",
      "[2023-07-09 15:57:46,692 INFO] Step 1000/ 1200; acc: 99.5; ppl:   3.3; xent: 1.2; lr: 0.00140; sents:   54239; bsz: 1904/3812/271; 5666/11342 tok/s;   1460 sec;\n",
      "[2023-07-09 15:58:54,123 INFO] Step 1050/ 1200; acc: 99.6; ppl:   3.3; xent: 1.2; lr: 0.00136; sents:   55960; bsz: 1939/3797/280; 5751/11261 tok/s;   1527 sec;\n",
      "[2023-07-09 16:00:01,679 INFO] Step 1100/ 1200; acc: 99.7; ppl:   3.3; xent: 1.2; lr: 0.00133; sents:   58259; bsz: 1969/3793/291; 5831/11228 tok/s;   1595 sec;\n",
      "[2023-07-09 16:00:24,596 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 91\n",
      "[2023-07-09 16:00:24,914 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 92\n",
      "[2023-07-09 16:00:25,207 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 93\n",
      "[2023-07-09 16:00:25,394 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 94\n",
      "[2023-07-09 16:00:25,575 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 95\n",
      "[2023-07-09 16:00:25,751 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 96\n",
      "[2023-07-09 16:00:25,937 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 97\n",
      "[2023-07-09 16:00:26,118 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 98\n",
      "[2023-07-09 16:00:26,312 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 99\n",
      "[2023-07-09 16:00:28,883 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 100\n",
      "[2023-07-09 16:00:29,062 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 101\n",
      "[2023-07-09 16:00:29,243 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 102\n",
      "[2023-07-09 16:00:29,425 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 103\n",
      "[2023-07-09 16:00:29,609 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 104\n",
      "[2023-07-09 16:00:29,783 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 105\n",
      "[2023-07-09 16:00:29,964 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 106\n",
      "[2023-07-09 16:00:32,852 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 107\n",
      "[2023-07-09 16:00:33,029 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 108\n",
      "[2023-07-09 16:01:27,763 INFO] Step 1150/ 1200; acc: 99.7; ppl:   3.3; xent: 1.2; lr: 0.00130; sents:   56355; bsz: 1951/3798/282; 4534/8823 tok/s;   1681 sec;\n",
      "[2023-07-09 16:02:34,990 INFO] Step 1200/ 1200; acc: 99.7; ppl:   3.3; xent: 1.2; lr: 0.00128; sents:   55517; bsz: 1924/3804/278; 5724/11318 tok/s;   1748 sec;\n",
      "[2023-07-09 16:02:35,070 INFO] valid stats calculation and sentences rebuilding\n",
      "                           took: 0.07903909683227539 s.\n",
      "[2023-07-09 16:02:35,071 INFO] Train perplexity: 4.65218\n",
      "[2023-07-09 16:02:35,071 INFO] Train accuracy: 93.6387\n",
      "[2023-07-09 16:02:35,071 INFO] Sentences processed: 1.35047e+06\n",
      "[2023-07-09 16:02:35,071 INFO] Average bsz: 1937/3800/281\n",
      "[2023-07-09 16:02:35,071 INFO] Validation perplexity: 3.36284\n",
      "[2023-07-09 16:02:35,071 INFO] Validation accuracy: 99.5519\n",
      "[2023-07-09 16:02:35,071 INFO] Model is improving ppl: 3.36475 --> 3.36284.\n",
      "[2023-07-09 16:02:35,071 INFO] Model is improving acc: 99.4772 --> 99.5519.\n",
      "[2023-07-09 16:02:35,073 INFO] Saving checkpoint /content/nmt/nmtmodel/model_step_1200.pt\n"
     ]
    }
   ],
   "source": [
    "# Train the neural machine translation (NMT) model using the specified configuration file\n",
    "!onmt_train -config config.yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1688918560713,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "ro-21ODLnBNU",
    "outputId": "712c7c36-967a-4324-cfaa-d6757477dede"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_step_1200.pt  model_step_600.pt  src.vocab\n",
      "model_step_300.pt   model_step_900.pt  train.log\n"
     ]
    }
   ],
   "source": [
    "# List the contents of the directory specified by 'model_root'\n",
    "!ls '{model_root}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nqRou9WfsDbh"
   },
   "source": [
    "# Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12988,
     "status": "ok",
     "timestamp": 1688918573699,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "tStHVtbNmipI",
    "outputId": "89d0341f-2bdb-42a1-a82f-a26aa4391865"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-09 16:02:41,282 INFO] Loading checkpoint from /content/nmt/nmtmodel/model_step_1200.pt\n",
      "[2023-07-09 16:02:41,839 INFO] Loading data into the model\n",
      "[2023-07-09 16:02:52,859 INFO] PRED SCORE: -0.0955, PRED PPL: 1.10 NB SENTENCES: 100\n"
     ]
    }
   ],
   "source": [
    "# Use the trained NMT model to perform translation on the test data\n",
    "# --model: Path to the trained model checkpoint\n",
    "# --src: Path to the source (input) file for translation\n",
    "# --output: Path to save the translated output\n",
    "# -beam_size: Beam size for beam search decoding\n",
    "!onmt_translate --model '/content/nmt/nmtmodel/model_step_1200.pt' --src /content/nmt/monument/test.en --output /content/nmt/monument/trans_test.sparql -beam_size 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1688918573699,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "UYszCfIbssof",
    "outputId": "66e947c6-1edc-41e5-fb12-aeafa6751306"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "which is longer los angeles police department memorial for fallen officers or national war memorial\n",
      "how many monument does byk talar have\n",
      "location of mint clock tower\n",
      "how many place does foshan have\n",
      "is ramagrama stupa a monument\n"
     ]
    }
   ],
   "source": [
    "# Display the first 5 lines of the 'test.en' file using the 'head' command\n",
    "!head -n 5 /content/nmt/monument/test.en\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 510,
     "status": "ok",
     "timestamp": 1688918574207,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "nnTRp6eas_p7",
    "outputId": "a3e012d2-7a0e-4ca6-fc08-cf0eb03a01ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select var_a where brack_open var_a dbp_length var_b sep_dot FILTER par_open var_a = dbr_Los_Angeles_Police_Department_Memorial_for_Fallen_Officers || var_a = dbr_National_War_Memorial_ par_open Canada par_close brack_close order by var_b limit 1\n",
      "select count par_open wildcard par_close where brack_open var_a rdf_type dbo_Monument sep_dot var_a dbo_location dbr_Byk_Talar brack_close group by var_a\n",
      "select var_a where brack_open dbr_Mint_Clock_Tower,_Chennai dbo_location var_a brack_close\n",
      "select count par_open wildcard par_close where brack_open var_a rdf_type dbo_Place sep_dot var_a dbo_location dbr_Foshan brack_close group by var_a\n",
      "ask where brack_open dbr_Ramagrama_stupa rdf_type dbo_Monument brack_close\n"
     ]
    }
   ],
   "source": [
    "# Display the first 5 lines of the 'trans_test.sparql' file using the 'head' command\n",
    "!head -n 5 /content/nmt/monument/trans_test.sparql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1688918574207,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "azi6x-EstHYN",
    "outputId": "27d9639e-2174-4682-b323-cff61007c990"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select var_a where brack_open var_a dbp_length var_b sep_dot FILTER par_open var_a = dbr_Los_Angeles_Police_Department_Memorial_for_Fallen_Officers || var_a = dbr_National_War_Memorial_ par_open Canada par_close  par_close  brack_close order by var_b limit 1\n",
      "select count par_open wildcard par_close  where brack_open var_a rdf_type dbo_Monument sep_dot var_a dbo_location dbr_Byk_Talar brack_close group by var_a\n",
      "select var_a where brack_open dbr_Mint_Clock_Tower,_Chennai dbo_location var_a brack_close\n",
      "select count par_open wildcard par_close  where brack_open var_a rdf_type dbo_Place sep_dot var_a dbo_location dbr_Foshan brack_close group by var_a\n",
      "ask where brack_open dbr_Ramagrama_stupa rdf_type dbo_Monument brack_close\n"
     ]
    }
   ],
   "source": [
    "# Display the first 5 lines of the 'test.sparql' file using the 'head' command\n",
    "!head -n 5 /content/nmt/monument/test.sparql\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vANuMTJUtfUb"
   },
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1688918574207,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "kj1AtrSDtjfq",
    "outputId": "cc490983-7b5e-4f6d-fc85-cd64f57a9856"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/nmt\n"
     ]
    }
   ],
   "source": [
    "# Print the current working directory (current path)\n",
    "!pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1050,
     "status": "ok",
     "timestamp": 1688918575256,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "CBxRt66trVw5",
    "outputId": "ebb8365f-c99e-4af1-9ed4-14c1402aa07b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference 1st sentence: select var_a where brack_open var_a dbp_length var_b sep_dot FILTER par_open var_a = dbr_Los_Angeles_Police_Department_Memorial_for_Fallen_Officers || var_a = dbr_National_War_Memorial_ par_open Canada par_close  par_close  brack_close order by var_b limit 1\n",
      "MTed 1st sentence: select var_a where brack_open var_a dbp_length var_b sep_dot FILTER par_open var_a = dbr_Los_Angeles_Police_Department_Memorial_for_Fallen_Officers || var_a = dbr_National_War_Memorial_ par_open Canada par_close brack_close order by var_b limit 1\n",
      "Accuracy:  0.9547657512116317\n"
     ]
    }
   ],
   "source": [
    "# Copy the 'compute-accuracy.py' script from the Google Drive to the current directory\n",
    "!cp /content/drive/MyDrive/compute-accuracy.py ./\n",
    "\n",
    "# Evaluate the translation quality using accuracy\n",
    "# - The script 'compute-accuracy.py' is used to compare the reference translations with the generated translations and compute accuracy.\n",
    "# - It takes the paths of the reference and generated translation files as command-line arguments.\n",
    "!python compute-accuracy.py /content/nmt/monument/test.sparql /content/nmt/monument/trans_test.sparql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5353,
     "status": "ok",
     "timestamp": 1688918580606,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "p2M4CDSltiuL",
    "outputId": "9cd68b4a-0ed2-47ce-feea-7e7d2a96a3ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference 1st sentence: select var_a where brack_open var_a dbp_length var_b sep_dot FILTER par_open var_a = dbr_Los_Angeles_Police_Department_Memorial_for_Fallen_Officers || var_a = dbr_National_War_Memorial_ par_open Canada par_close  par_close  brack_close order by var_b limit 1\n",
      "MTed 1st sentence: select var_a where brack_open var_a dbp_length var_b sep_dot FILTER par_open var_a = dbr_Los_Angeles_Police_Department_Memorial_for_Fallen_Officers || var_a = dbr_National_War_Memorial_ par_open Canada par_close brack_close order by var_b limit 1\n",
      "BLEU:  98.09234898730233\n"
     ]
    }
   ],
   "source": [
    "# Install the 'sacrebleu' library using pip (with output redirection to /dev/null to suppress output)\n",
    "!pip install sacrebleu > /dev/null\n",
    "\n",
    "# Copy the 'compute-bleu.py' script from Google Drive to the current directory\n",
    "!cp /content/drive/MyDrive/compute-bleu.py ./\n",
    "\n",
    "# Evaluate the translation quality using BLEU\n",
    "# - The script 'compute-bleu.py' is used to compute the BLEU score by comparing the reference translations with the generated translations.\n",
    "# - It takes the paths of the reference and generated translation files as command-line arguments.\n",
    "!python compute-bleu.py /content/nmt/monument/test.sparql /content/nmt/monument/trans_test.sparql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4789,
     "status": "ok",
     "timestamp": 1688918585391,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "YDcNrZm3MCO1",
    "outputId": "7346bd71-7cc2-4553-8fde-33d446a4072b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference 1st sentence: select var_a where brack_open var_a dbp_length var_b sep_dot FILTER par_open var_a = dbr_Los_Angeles_Police_Department_Memorial_for_Fallen_Officers || var_a = dbr_National_War_Memorial_ par_open Canada par_close  par_close  brack_close order by var_b limit 1\n",
      "MTed 1st sentence: select var_a where brack_open var_a dbp_length var_b sep_dot FILTER par_open var_a = dbr_Los_Angeles_Police_Department_Memorial_for_Fallen_Officers || var_a = dbr_National_War_Memorial_ par_open Canada par_close brack_close order by var_b limit 1\n",
      "Rouge-L:  0.9907949980610772\n"
     ]
    }
   ],
   "source": [
    "# Install the 'rouge' library using pip (with output redirection to /dev/null to suppress output)\n",
    "!pip install rouge > /dev/null\n",
    "\n",
    "# Copy the 'compute-rouge-l.py' script from Google Drive to the current directory\n",
    "!cp /content/drive/MyDrive/compute-rouge-l.py ./\n",
    "\n",
    "# Evaluate the translation quality using Rouge-L\n",
    "# - The script 'compute-rouge-l.py' is used to compute the Rouge-L score by comparing the reference translations with the generated translations.\n",
    "# - It takes the paths of the reference and generated translation files as command-line arguments.\n",
    "!python compute-rouge-l.py /content/nmt/monument/test.sparql /content/nmt/monument/trans_test.sparql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 14664,
     "status": "ok",
     "timestamp": 1688918627790,
     "user": {
      "displayName": "Honghao Qiu",
      "userId": "12770867871229673910"
     },
     "user_tz": -60
    },
    "id": "X0X5VSHBV-kA"
   },
   "outputs": [],
   "source": [
    "# Copy the trained NMT model directory 'nmtmodel' to a specific directory in Google Drive\n",
    "!cp -r /content/nmt/nmtmodel /content/drive/MyDrive/NMT_models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8L_nKJQMr2nO"
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uu7lspbw1Gxw"
   },
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    ''' ''',\n",
    "    ''' '''\n",
    "]\n",
    "with open('questions.en', 'w') as fp:\n",
    "    t = [''.join(x) for x in sentences]\n",
    "    t = '\\n'.join(t)\n",
    "    fp.write(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! onmt_translate --model '/content/nmt/nmtmodel/model_step_1200.pt' --src questions.en --output pred.sparql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat pred.sparql"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPgg9VGxJh/dsyQZYiZ7bZ9",
   "gpuType": "T4",
   "mount_file_id": "1I5Adb5Vt3cCW8_xWKJz_CTepRFax1Snq",
   "provenance": [
    {
     "file_id": "1qwBCXsrX0UD96jZU-P9vIhFRTnCZYO6m",
     "timestamp": 1686823688936
    },
    {
     "file_id": "1sYi4GQuLKBmhhiOJvNHDacHYPI39LsG-",
     "timestamp": 1686759059262
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
